# E2E Test Failures Triage: Disk Space Exhaustion

**Status**: ðŸ”´ **CRITICAL - All E2E Tests Failing Due to Disk Space**
**Team**: CI/CD Infrastructure
**Date**: January 3, 2026 13:37 PST
**GitHub Actions Run**: https://github.com/jordigilh/kubernaut/actions/runs/20677852270

---

## ðŸ“Š **Failure Summary**

| Service | Status | Root Cause | Error Location |
|---------|--------|-----------|----------------|
| **AI Analysis** | âŒ FAILED | Disk space exhaustion | Image build |
| **Gateway** | âŒ FAILED | Disk space + cluster creation | Image load |
| **Notification** | âŒ FAILED | Pod startup timeout (resource starvation) | Deployment |
| **Workflow Execution** | âŒ FAILED | Disk space exhaustion | Image build |
| **HolmesGPT API** | âŒ FAILED | Dependency installation issue | Install step |
| Signal Processing | âœ… PASSED | - | - |
| Data Storage | âœ… PASSED | - | - |
| Remediation Orchestrator | âœ… PASSED | - | - |

**Overall Result**: **5 of 8 E2E test suites failed (62.5% failure rate)**

---

## ðŸ” **Root Cause Analysis**

### **PRIMARY ROOT CAUSE: Disk Space Exhaustion**

**Evidence**:
1. **AI Analysis E2E** (Job ID: 59368130779):
   ```
   Error: writing blob: write /tmp/kind-image-2236231141.tar: no space left on device
   ```

2. **Workflow Execution E2E** (Job ID: 59368130787):
   ```
   Error: committing container for step: copying layers and metadata:
   writing blob: storing blob to file "/var/tmp/container_images_storage1144186040/1":
   write /var/tmp/container_images_storage1144186040/1: no space left on device
   ```

3. **Gateway E2E** (Job ID: 59368130781):
   ```
   ERROR: no nodes found for cluster "gateway-e2e"
   âŒ DataStorage image failed: DS image load failed: failed to load image into Kind: exit status 1
   âŒ Gateway image failed: Gateway image build/load failed: shared build script failed: exit status 1
   ```

4. **Notification E2E** (Job ID: 59368130786):
   ```
   error: timed out waiting for the condition on pods/notification-controller-8d9bd69dc-xjk68
   ```
   - **Analysis**: Pod likely failed to pull/start image due to disk space constraints

---

## ðŸŽ¯ **Detailed Failure Analysis**

### **1. AI Analysis E2E Failure**

**Job ID**: 59368130779
**Duration**: 285.768 seconds (~4.8 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` at `suite_test.go:127`

**Timeline**:
- âœ… Cluster creation started
- âœ… Parallel image builds started
- âŒ Image tar export failed: **no space left on device**
- âŒ Cluster setup aborted

**Critical Error**:
```
Error: writing blob: write /tmp/kind-image-2236231141.tar: no space left on device
```

**Impact**: 0 of 36 test specs ran (suite aborted during setup)

---

### **2. Gateway E2E Failure**

**Job ID**: 59368130781
**Duration**: 190.504 seconds (~3.2 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` at `gateway_e2e_suite_test.go:116`

**Timeline**:
- âœ… Image builds started
- âŒ DataStorage image load failed
- âŒ Gateway image build/load failed
- âŒ Cluster creation succeeded but no nodes found (orphaned cluster)

**Critical Errors**:
```
ERROR: no nodes found for cluster "gateway-e2e"
âŒ DataStorage image failed: DS image load failed: failed to load image into Kind: exit status 1
âŒ Gateway image failed: Gateway image build/load failed: shared build script failed: exit status 1
```

**Analysis**: Image build/load failures cascaded into cluster state inconsistency

---

### **3. Notification E2E Failure**

**Job ID**: 59368130786
**Duration**: 270.193 seconds (~4.5 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` at `notification_e2e_suite_test.go:167`

**Timeline**:
- âœ… Cluster created
- âœ… Images likely loaded (no explicit disk error)
- âŒ Notification controller pod timed out waiting to become ready

**Critical Error**:
```
error: timed out waiting for the condition on pods/notification-controller-8d9bd69dc-xjk68
```

**Analysis**:
- Pod likely failed to pull image or start due to resource constraints
- Disk space exhaustion may have prevented container runtime operations
- Timeout suggests pod stuck in `Pending` or `CrashLoopBackOff`

---

### **4. Workflow Execution E2E Failure**

**Job ID**: 59368130787
**Duration**: 335.685 seconds (~5.6 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` during image build

**Timeline**:
- âœ… Build started
- âŒ Container image commit failed: **no space left on device**

**Critical Error**:
```
Error: committing container for step: copying layers and metadata for container:
writing blob: storing blob to file "/var/tmp/container_images_storage1144186040/1":
write /var/tmp/container_images_storage1144186040/1: no space left on device
```

**Analysis**: Disk space exhausted during final container image layering

---

### **5. HolmesGPT API E2E Failure**

**Job ID**: 59368130825
**Duration**: Failed during "Install Python dependencies" step
**Failure Point**: Before E2E test suite even started

**Critical Error**:
```
ERROR: Directory '../dependencies/holmesgpt/' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.
```

**Analysis**:
- This is a **DIFFERENT ROOT CAUSE** (not disk space related)
- The `dependencies/holmesgpt` submodule is not properly checked out
- Python pip cannot find the HolmesGPT package metadata

**Related Issue**: Submodule checkout problem in CI workflow

---

## ðŸ“ˆ **Success Pattern Analysis**

**3 Services Passed**: Signal Processing, Data Storage, Remediation Orchestrator

**Common Success Factors**:
1. **Earlier Execution**: These jobs started/completed before disk space was exhausted
2. **Simpler Builds**: Potentially smaller image sizes or fewer dependencies
3. **Resource Efficiency**: Less aggressive parallel builds

---

## ðŸ› ï¸ **Immediate Actions Required**

### **Priority 1: Disk Space Management (CRITICAL)**

#### **Option A: Aggressive Cleanup Between Jobs**

Add cleanup steps to E2E workflow template:

```yaml
- name: Free Disk Space
  run: |
    echo "ðŸ—‘ï¸ Freeing disk space before E2E tests..."

    # Remove unnecessary tools
    sudo rm -rf /usr/share/dotnet
    sudo rm -rf /usr/local/lib/android
    sudo rm -rf /opt/ghc
    sudo rm -rf /opt/hostedtoolcache/CodeQL

    # Docker cleanup
    docker system prune -a -f --volumes

    # Show available space
    df -h
```

**Estimated Space Freed**: ~30-40 GB

#### **Option B: Sequential E2E Execution**

Change E2E test strategy from `fail-fast: false` (parallel) to sequential:

```yaml
strategy:
  max-parallel: 1  # Run one E2E test at a time
  fail-fast: false
```

**Trade-off**: Slower CI runs but more reliable

#### **Option C: Split E2E Tests Across Multiple Workflows**

Create separate workflow files for heavy E2E services:
- `e2e-heavy.yml`: AIAnalysis, WorkflowExecution, HolmesGPT
- `e2e-light.yml`: Gateway, Notification, others

**Benefit**: Separate runners = separate disk space

---

### **Priority 2: HolmesGPT Submodule Fix (BLOCKING)**

Fix submodule checkout in E2E workflow:

```yaml
- name: Checkout code
  uses: actions/checkout@v4
  with:
    submodules: recursive  # âœ… Ensure recursive checkout
    token: ${{ secrets.GITHUB_TOKEN }}
```

**Verification**:
```bash
# In CI workflow
- name: Verify HolmesGPT submodule
  run: |
    ls -la dependencies/holmesgpt/
    test -f dependencies/holmesgpt/setup.py || test -f dependencies/holmesgpt/pyproject.toml
```

---

### **Priority 3: Image Build Optimization**

#### **Reduce Build Parallelism**

Current approach builds **8 images in parallel**, consuming massive disk space.

**Recommended**: Build serially or in smaller batches:

```yaml
# In test infrastructure
build_images:
  parallel_limit: 2  # Max 2 concurrent builds instead of 8
```

#### **Enable BuildKit Inline Cache**

```dockerfile
# In Dockerfiles
# syntax=docker/dockerfile:1
```

```yaml
# In build steps
- name: Build images with cache
  run: |
    export DOCKER_BUILDKIT=1
    export BUILDKIT_INLINE_CACHE=1
    make build-images
```

---

## ðŸ“Š **Disk Space Analysis**

### **GitHub Actions Runner Specs**
- **OS**: Ubuntu 22.04
- **Total Disk**: ~14 GB available initially
- **Typical Usage**:
  - OS + Pre-installed tools: ~60 GB
  - After checkout: ~65 GB
  - After Go modules download: ~70 GB
  - After 8 parallel image builds: **14 GB â†’ 0 GB** âŒ

### **Estimated Space Requirements Per Service**
- **Data Storage**: ~2-3 GB (PostgreSQL + Redis + Go binary)
- **Gateway**: ~1.5-2 GB (Go binary + dependencies)
- **AIAnalysis**: ~1.5-2 GB (Go binary + Rego policies)
- **WorkflowExecution**: ~2-3 GB (Tekton + Go binary)
- **HolmesGPT API**: ~3-4 GB (Python + dependencies + model files)
- **Notification**: ~1-2 GB (Go binary)
- **Signal Processing**: ~1.5-2 GB (Go binary)
- **Remediation Orchestrator**: ~1-2 GB (Go binary)

**Total Parallel Build Space**: ~15-20 GB (exceeds available 14 GB)

---

## ðŸŽ¯ **Recommended Solution**

### **Immediate Fix (Can Deploy Today)**

**1. Add aggressive disk cleanup step to E2E workflow template:**

```yaml
# In .github/workflows/e2e-test-template.yml
steps:
  - name: Checkout code
    uses: actions/checkout@v4
    with:
      submodules: recursive

  # ADD THIS STEP
  - name: Free Disk Space
    run: |
      echo "ðŸ“Š Disk space before cleanup:"
      df -h

      echo "ðŸ—‘ï¸ Removing unnecessary tools..."
      sudo rm -rf /usr/share/dotnet
      sudo rm -rf /usr/local/lib/android
      sudo rm -rf /opt/ghc
      sudo rm -rf /opt/hostedtoolcache/CodeQL

      echo "ðŸ³ Docker cleanup..."
      docker system prune -a -f --volumes || true

      echo "ðŸ“Š Disk space after cleanup:"
      df -h

  - name: Install Latest Kind
    # ... rest of workflow
```

**2. Fix HolmesGPT submodule checkout:**

```yaml
- name: Checkout code
  uses: actions/checkout@v4
  with:
    submodules: recursive  # âœ… Changed from 'true' to 'recursive'
```

**3. Reduce E2E parallel execution:**

```yaml
# In .github/workflows/ci-pipeline.yml
e2e-tests:
  strategy:
    max-parallel: 2  # Limit to 2 concurrent E2E jobs
    fail-fast: false
```

---

### **Long-Term Fix (Next Sprint)**

**1. Migrate to self-hosted runners with more disk space**
- GitHub-hosted: 14 GB available
- Self-hosted: Can configure 50-100 GB SSD

**2. Implement layer caching with external registry**
- Push base layers to GitHub Container Registry
- Pull cached layers instead of rebuilding

**3. Split heavy E2E tests into separate workflows**
- Run on schedule or manual trigger
- Preserve fast feedback for lightweight services

---

## ðŸš€ **Success Criteria**

After implementing fixes, verify:

1. âœ… All 8 E2E test suites pass in CI
2. âœ… Disk space remains >10% free throughout E2E execution
3. âœ… HolmesGPT submodule properly checked out
4. âœ… No "no space left on device" errors
5. âœ… E2E execution time remains <30 minutes per service

---

## ðŸ“ **Related Issues**

- **DD-TEST-007**: E2E coverage instrumentation
- **ADR-003**: Kind cluster as primary integration environment
- **CI/CD Pipeline**: 3-stage pipeline with parallel E2E execution

---

## ðŸ“Š **Metrics**

- **Total CI Run Time**: 30+ minutes
- **Disk Space Exhaustion Point**: ~15-20 minutes into E2E builds
- **Affected Services**: 5 of 8 (62.5%)
- **Estimated Fix Time**: 2-4 hours (immediate fix)
- **Estimated Cost Impact**: ~$5-10 in wasted CI minutes per run

---

**Document Status**: âœ… Active Triage
**Last Updated**: 2026-01-03 13:37 PST
**Owner**: CI/CD Infrastructure Team
**Confidence**: 95%
**Next Action**: Implement disk cleanup + submodule fix + parallel limit

