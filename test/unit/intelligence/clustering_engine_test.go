/*
Copyright 2025 Jordi Gil.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package intelligence

import (
	"testing"
	"fmt"
	"math"
	"time"

	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"
	"github.com/sirupsen/logrus"

	"github.com/jordigilh/kubernaut/pkg/intelligence/clustering"
	"github.com/jordigilh/kubernaut/pkg/intelligence/patterns"
	"github.com/jordigilh/kubernaut/pkg/workflow/engine"
)

// Suite structure moved to intelligence_suite_test.go - generated by ginkgo bootstrap

var _ = Describe("Clustering Engine - Business Requirements Testing", func() {
	var (
		clusteringEngine *clustering.ClusteringEngine
		config           *patterns.PatternDiscoveryConfig
		logger           *logrus.Logger
	)

	BeforeEach(func() {
		logger = logrus.New()
		logger.SetLevel(logrus.WarnLevel)

		config = &patterns.PatternDiscoveryConfig{
			MinExecutionsForPattern: 5,
			MaxHistoryDays:          30,
			SamplingInterval:        time.Hour,
			SimilarityThreshold:     0.85,
			ClusteringEpsilon:       0.3,
			MinClusterSize:          3,
			ModelUpdateInterval:     time.Hour,
			FeatureWindowSize:       20,
		}

		clusteringEngine = clustering.NewClusteringEngine(config, logger)
	})

	// BR-CL-001: MUST implement execution pattern clustering for business insights
	Context("BR-CL-001: Execution Pattern Clustering Implementation", func() {
		It("should cluster execution patterns for business analysis", func() {
			// Given: Diverse execution data suitable for clustering
			executionData := createExecutionDataForClustering(50)

			// When: Clustering execution patterns for business insights
			result, err := clusteringEngine.ClusterExecutionPatterns(executionData)

			// Then: Should produce meaningful execution pattern clusters
			Expect(err).ToNot(HaveOccurred(), "Execution pattern clustering should succeed")
			Expect(len(result.Clusters)).To(BeNumerically(">=", 2), "Should identify meaningful execution pattern clusters")
			Expect(len(result.Clusters)).To(BeNumerically("<=", 10), "Should not over-cluster execution patterns")

			// **Business Value**: Verify clustering enables execution pattern organization
			Expect(result.Silhouette).To(BeNumerically(">=", 0.0), "Should provide cluster separation metrics for business evaluation")

			// Validate each cluster has business meaning
			for _, cluster := range result.Clusters {
				Expect(cluster.Size).To(BeNumerically(">=", config.MinClusterSize), "Clusters should meet minimum business size requirements")
				Expect(cluster.Cohesion).To(BeNumerically(">=", 0.0), "Clusters should provide cohesion metrics for business interpretation")
				Expect(len(cluster.Label)).To(BeNumerically(">=", 0), "Clusters should have labels for business identification")
			}
		})

		It("should cluster resource usage patterns for optimization insights", func() {
			// Given: Resource usage data requiring business optimization
			executionData := createResourceUsageData(30)

			// When: Clustering resource usage patterns
			result, err := clusteringEngine.ClusterResourceUsage(executionData)

			// Then: Should provide resource optimization insights
			Expect(err).ToNot(HaveOccurred(), "Resource usage clustering should succeed")
			Expect(len(result.Clusters)).To(BeNumerically(">=", 1), "Should identify resource usage patterns")

			// **Business Value**: Verify resource clustering enables optimization decisions
			for _, cluster := range result.Clusters {
				Expect(len(cluster.Characteristics)).To(BeNumerically(">=", 0), "Should provide cluster characteristics for business analysis")
			}
		})
	})

	// BR-CL-002: MUST implement alert clustering for incident management
	Context("BR-CL-002: Alert Clustering Implementation", func() {
		It("should cluster alerts for incident pattern recognition", func() {
			// Given: Alert execution data with incident patterns
			alertData := createAlertExecutionData(25)

			// When: Clustering alerts for incident management
			alertClusters := clusteringEngine.ClusterAlerts(alertData)

			// Then: Should create meaningful alert clusters for incident response
			Expect(len(alertClusters)).To(BeNumerically(">=", 0), "Should return alert clustering results")

			// **Business Value**: Verify alert clustering enables incident management
			if len(alertClusters) > 0 {
				for _, clusterGroup := range alertClusters {
					Expect(len(clusterGroup.Members)).To(BeNumerically(">=", 0), "Should provide alert cluster members")
					Expect(len(clusterGroup.Members)).To(BeNumerically(">", 0), "Alert clusters should contain alerts")
					Expect(len(clusterGroup.AlertTypes)).To(BeNumerically(">=", 1), "Should identify common alert types for business analysis")
					Expect(clusterGroup.Confidence).To(BeNumerically(">=", 0.0), "Should provide confidence metrics")
				}
			}
		})

		It("should provide alert cluster insights for business decision making", func() {
			// Given: Complex alert patterns requiring business analysis
			complexAlertData := createComplexAlertData(20)

			// When: Analyzing alert clusters for business insights
			alertClusters := clusteringEngine.ClusterAlerts(complexAlertData)

			// Then: Should provide actionable alert insights
			Expect(len(alertClusters)).To(BeNumerically(">=", 0), "Should return alert analysis")

			// **Business Value**: Verify alert clustering provides business insights
			if len(alertClusters) > 0 {
				for _, clusterGroup := range alertClusters {
					Expect(clusterGroup.CommonCharacteristics).ToNot(BeEmpty(), "Should categorize alert characteristics for business understanding")
					Expect(clusterGroup.Confidence).To(BeNumerically(">=", 0.0), "Should provide confidence metrics")
					Expect(clusterGroup.SuccessRate).To(BeNumerically(">=", 0.0), "Should provide success rate metrics")
				}
			}
		})
	})

	// BR-CL-003: MUST implement DBSCAN for noise detection and outlier identification
	Context("BR-CL-003: DBSCAN Clustering for Outlier Detection", func() {
		It("should identify clusters and outliers using DBSCAN", func() {
			// Given: Feature data with potential outliers that need business attention
			features := createFeatureDataWithOutliers(40, 5) // 40 normal + 5 outliers
			metadata := createMetadataForFeatures(45)

			// When: Performing DBSCAN clustering
			result, err := clusteringEngine.PerformDBSCANClustering(features, metadata)

			// Then: Should identify clusters and/or outliers through DBSCAN analysis
			Expect(err).ToNot(HaveOccurred(), "DBSCAN clustering should succeed")
			Expect(result.AnalyzedPoints).To(BeNumerically(">", 0), "Should return DBSCAN clustering result with analyzed points")

			// **Business Value**: Verify DBSCAN analysis provides business insights
			Expect(result.AnalyzedPoints).To(BeNumerically(">", 0), "Should analyze provided data points")

			// Validate clustering results provide business value
			if len(result.Clusters) > 0 {
				for _, cluster := range result.Clusters {
					Expect(cluster.Size).To(BeNumerically(">", 0), "Clusters should contain data points")
					Expect(cluster.Cohesion).To(BeNumerically(">=", 0.0), "Should provide cohesion metrics")
				}
			} else {
				// If no clusters found, DBSCAN may have identified all points as noise/outliers
				Expect(result.AnalyzedPoints).To(Equal(45), "Should still analyze all data points for outlier detection")
			}
		})

		It("should handle business-critical data with DBSCAN analysis", func() {
			// Given: Business-critical execution data requiring outlier analysis
			businessCriticalFeatures := createBusinessCriticalFeatures(30)
			businessMetadata := createBusinessMetadata(30)

			// When: Analyzing with DBSCAN for business outlier detection
			result, err := clusteringEngine.PerformDBSCANClustering(businessCriticalFeatures, businessMetadata)

			// Then: Should provide actionable business insights
			Expect(err).ToNot(HaveOccurred(), "Business-critical DBSCAN should succeed")
			Expect(result.AnalyzedPoints).To(BeNumerically(">", 0), "Should return business analysis results with analyzed points")

			// **Business Value**: Verify DBSCAN provides business decision support
			if len(result.Clusters) > 0 {
				for _, cluster := range result.Clusters {
					Expect(cluster.Separation).To(BeNumerically(">=", 0.0), "Should provide cluster separation metrics")
					Expect(len(cluster.Characteristics)).To(BeNumerically(">=", 0), "Should provide business-relevant characteristics")
				}
			}
		})
	})

	// BR-CL-004: MUST provide comprehensive clustering analysis
	Context("BR-CL-004: Comprehensive Clustering Analysis", func() {
		It("should provide detailed clustering quality metrics", func() {
			// Given: Execution data requiring comprehensive quality assessment
			executionData := createExecutionDataForClustering(35)

			// When: Performing comprehensive clustering analysis
			result, err := clusteringEngine.ClusterExecutionPatterns(executionData)

			// Then: Should provide comprehensive quality assessment
			Expect(err).ToNot(HaveOccurred(), "Comprehensive clustering should succeed")
			Expect(len(result.Clusters)).To(BeNumerically(">=", 0), "Should return detailed clustering results with clusters")

			// **Business Value**: Verify metrics enable quality business decisions
			Expect(result.Silhouette).To(BeNumerically(">=", 0.0), "Should provide silhouette analysis")
			Expect(result.Inertia).To(BeNumerically(">=", 0.0), "Should provide clustering quality metrics")
			Expect(result.AnalyzedPoints).To(Equal(len(executionData)), "Should analyze all provided data points")

			// Validate comprehensive cluster characteristics
			for _, cluster := range result.Clusters {
				Expect(cluster.Cohesion).To(BeNumerically(">=", 0.0), "Should provide cohesion metrics")
				Expect(cluster.Separation).To(BeNumerically(">=", 0.0), "Should provide separation metrics")
			}
		})

		It("should demonstrate clustering stability for business confidence", func() {
			// Given: Multiple execution data samples for stability testing
			sample1 := createExecutionDataForClustering(30)
			sample2 := createExecutionDataForClustering(30) // Similar but different data

			// When: Testing clustering stability across samples
			result1, err1 := clusteringEngine.ClusterExecutionPatterns(sample1)
			result2, err2 := clusteringEngine.ClusterExecutionPatterns(sample2)

			// Then: Should demonstrate stable clustering for business reliability
			Expect(err1).ToNot(HaveOccurred(), "First clustering should succeed")
			Expect(err2).ToNot(HaveOccurred(), "Second clustering should succeed")
			Expect(len(result1.Clusters)).To(BeNumerically(">=", 0), "Should return first clustering result with clusters")
			Expect(len(result2.Clusters)).To(BeNumerically(">=", 0), "Should return second clustering result with clusters")

			// **Business Value**: Verify stability enables confident business decisions
			clusterCountDiff := math.Abs(float64(len(result1.Clusters) - len(result2.Clusters)))
			Expect(clusterCountDiff).To(BeNumerically("<=", 2), "Should maintain similar cluster counts for business consistency")
		})
	})

	// Additional Business Requirements - Simplified to match actual API
	Context("Additional Business Value Validation", func() {
		It("should provide meaningful business insights from clustering results", func() {
			// Given: Business execution data requiring actionable insights
			businessExecutionData := createExecutionDataForClustering(25)

			// When: Analyzing business patterns through clustering
			result, err := clusteringEngine.ClusterExecutionPatterns(businessExecutionData)

			// Then: Should provide actionable business insights
			Expect(err).ToNot(HaveOccurred(), "Business clustering should succeed")
			Expect(len(result.Clusters)).To(BeNumerically(">=", 0), "Should return business clustering results with clusters")

			// **Business Value**: Verify clustering provides decision-making insights
			if len(result.Clusters) > 0 {
				for _, cluster := range result.Clusters {
					Expect(cluster.Label).ToNot(BeEmpty(), "Should provide business-meaningful cluster labels")
					Expect(len(cluster.Characteristics)).To(BeNumerically(">=", 0), "Should provide business characteristics")
				}
			}
		})

		It("should demonstrate clustering quality for business confidence", func() {
			// Given: High-quality execution data for business decision making
			qualityExecutionData := createExecutionDataForClustering(40)

			// When: Evaluating clustering quality for business use
			result, err := clusteringEngine.ClusterExecutionPatterns(qualityExecutionData)

			// Then: Should demonstrate quality sufficient for business decisions
			Expect(err).ToNot(HaveOccurred(), "Quality clustering should succeed")
			Expect(len(result.Clusters)).To(BeNumerically(">=", 0), "Should return quality results with clusters")

			// **Business Value**: Verify quality metrics support business confidence
			Expect(result.Silhouette).To(BeNumerically(">=", 0.0), "Should provide quality assessment")
			if len(result.Clusters) > 0 {
				for _, cluster := range result.Clusters {
					Expect(cluster.Size).To(BeNumerically(">", 0), "Clusters should contain meaningful data")
					Expect(cluster.Cohesion).To(BeNumerically(">=", 0.0), "Should provide cohesion assessment")
				}
			}
		})
	})

	// Additional helper functions for test data creation aligned with actual API
})

// Helper functions for creating test data aligned with actual clustering engine API

func createExecutionDataForClustering(count int) []*engine.EngineWorkflowExecutionData {
	data := make([]*engine.EngineWorkflowExecutionData, count)

	for i := 0; i < count; i++ {
		data[i] = &engine.EngineWorkflowExecutionData{
			ExecutionID: fmt.Sprintf("exec-%d", i),
			WorkflowID:  fmt.Sprintf("workflow-%d", i%4),
			Timestamp:   time.Now().Add(-time.Duration(i) * time.Hour),
			Duration:    time.Duration(30+i*5) * time.Minute,
			Success:     i%5 != 0, // 80% success rate
			Metrics: map[string]float64{
				"cpu_usage":      float64(20 + i%30),
				"memory_usage":   float64(50 + i%40),
				"execution_time": float64(30 + i*5),
			},
			Metadata: map[string]interface{}{
				"environment":       "production",
				"cluster":           fmt.Sprintf("cluster-%d", i%3),
				"business_priority": i % 4,
			},
		}
	}

	return data
}

func createResourceUsageData(count int) []*engine.EngineWorkflowExecutionData {
	data := make([]*engine.EngineWorkflowExecutionData, count)

	for i := 0; i < count; i++ {
		resourceLevel := i % 3 // Low, Medium, High resource usage patterns

		data[i] = &engine.EngineWorkflowExecutionData{
			ExecutionID: fmt.Sprintf("resource-exec-%d", i),
			WorkflowID:  fmt.Sprintf("resource-workflow-%d", resourceLevel),
			Timestamp:   time.Now().Add(-time.Duration(i) * time.Hour),
			Duration:    time.Duration(20+resourceLevel*20) * time.Minute,
			Success:     i%6 != 0, // 83% success rate
			Metrics: map[string]float64{
				"cpu_usage":    float64(10 + resourceLevel*30),
				"memory_usage": float64(25 + resourceLevel*25),
				"disk_io":      float64(100 + resourceLevel*200),
			},
			Metadata: map[string]interface{}{
				"resource_tier": fmt.Sprintf("tier-%d", resourceLevel),
				"cost_center":   fmt.Sprintf("cc-%d", i%4),
			},
		}
	}

	return data
}

func createAlertExecutionData(count int) []*engine.EngineWorkflowExecutionData {
	data := make([]*engine.EngineWorkflowExecutionData, count)

	alertTypes := []string{"cpu_high", "memory_high", "disk_full", "network_timeout"}

	for i := 0; i < count; i++ {
		alertType := alertTypes[i%len(alertTypes)]

		data[i] = &engine.EngineWorkflowExecutionData{
			ExecutionID: fmt.Sprintf("alert-exec-%d", i),
			WorkflowID:  fmt.Sprintf("alert-workflow-%s", alertType),
			Timestamp:   time.Now().Add(-time.Duration(i) * time.Hour),
			Duration:    time.Duration(15+i%20) * time.Minute,
			Success:     i%7 != 0, // 86% success rate
			Metrics: map[string]float64{
				"alert_severity":  float64(1 + i%4),
				"resolution_time": float64(10 + i*2),
			},
			Metadata: map[string]interface{}{
				"alert_name": alertType,
				"namespace":  fmt.Sprintf("ns-%d", i%5),
				"resource":   fmt.Sprintf("pod-%d", i),
				"severity":   fmt.Sprintf("level-%d", 1+i%4),
			},
		}
	}

	return data
}

func createComplexAlertData(count int) []*engine.EngineWorkflowExecutionData {
	data := make([]*engine.EngineWorkflowExecutionData, count)

	for i := 0; i < count; i++ {
		complexity := i % 4 // Different complexity levels

		data[i] = &engine.EngineWorkflowExecutionData{
			ExecutionID: fmt.Sprintf("complex-alert-%d", i),
			WorkflowID:  fmt.Sprintf("complex-workflow-%d", complexity),
			Timestamp:   time.Now().Add(-time.Duration(i) * time.Hour),
			Duration:    time.Duration(25+complexity*15) * time.Minute,
			Success:     i%8 != 0, // 87.5% success rate
			Metrics: map[string]float64{
				"complexity_score": float64(complexity + 1),
				"business_impact":  float64(100 + complexity*250),
			},
			Metadata: map[string]interface{}{
				"alert_category": fmt.Sprintf("category-%d", complexity),
				"business_unit":  fmt.Sprintf("bu-%d", i%3),
				"priority":       complexity + 1,
			},
		}
	}

	return data
}

func createFeatureDataWithOutliers(normalCount, outlierCount int) [][]float64 {
	features := make([][]float64, normalCount+outlierCount)

	// Create normal data points
	for i := 0; i < normalCount; i++ {
		cluster := i % 3
		features[i] = []float64{
			float64(100 + cluster*50 + (i%5)*10),  // execution_time
			float64(0.3 + float64(cluster)*0.2),   // resource_usage
			float64(0.01 + float64(cluster)*0.01), // error_rate
		}
	}

	// Create outlier data points
	for i := normalCount; i < normalCount+outlierCount; i++ {
		features[i] = []float64{
			float64(500 + (i%3)*100),         // Much higher execution times
			float64(0.9 + float64(i%2)*0.1),  // Very high resource usage
			float64(0.1 + float64(i%2)*0.05), // High error rates
		}
	}

	return features
}

func createMetadataForFeatures(count int) []map[string]interface{} {
	metadata := make([]map[string]interface{}, count)

	for i := 0; i < count; i++ {
		metadata[i] = map[string]interface{}{
			"execution_id": fmt.Sprintf("exec-%d", i),
			"workflow_id":  fmt.Sprintf("workflow-%d", i%4),
			"timestamp":    time.Now().Add(-time.Duration(i) * time.Hour),
			"environment":  "production",
		}
	}

	return metadata
}

func createBusinessCriticalFeatures(count int) [][]float64 {
	features := make([][]float64, count)

	for i := 0; i < count; i++ {
		criticalityLevel := i % 4
		features[i] = []float64{
			float64(60 + criticalityLevel*40),             // execution_time
			float64(0.25 + float64(criticalityLevel)*0.2), // resource_usage
			float64(100 + criticalityLevel*500),           // cost_impact
			float64(1 + criticalityLevel),                 // business_criticality
		}
	}

	return features
}

func createBusinessMetadata(count int) []map[string]interface{} {
	metadata := make([]map[string]interface{}, count)

	for i := 0; i < count; i++ {
		metadata[i] = map[string]interface{}{
			"execution_id":         fmt.Sprintf("business-exec-%d", i),
			"business_criticality": i % 4,
			"cost_center":          fmt.Sprintf("cc-%d", i%3),
			"business_unit":        fmt.Sprintf("bu-%d", i%5),
		}
	}

	return metadata
}

// End of clustering test helper functions

// TestRunner bootstraps the Ginkgo test suite
func TestUclusteringUengine(t *testing.T) {
	RegisterFailHandler(Fail)
	RunSpecs(t, "UclusteringUengine Suite")
}
