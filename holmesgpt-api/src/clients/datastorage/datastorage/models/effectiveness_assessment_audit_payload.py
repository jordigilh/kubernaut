# coding: utf-8

"""
    Data Storage Service API

    Data Storage Service provides REST API access to audit trail persistence.  **Business Requirements**: - BR-STORAGE-001 to BR-STORAGE-020: Audit write API - BR-STORAGE-021: Incident query API (READ) - BR-STORAGE-024: RFC 7807 error responses - BR-AUDIT-006: Legal hold capability (SOC2 Gap #8)  **Design Decisions**: - ADR-031: OpenAPI 3.0+ specification for all stateless REST APIs - ADR-032: Data Access Layer Isolation (only Data Storage connects to PostgreSQL) - DD-009: Dead Letter Queue fallback on database errors - DD-AUTH-004: OAuth-proxy sidecar for authentication/authorization - DD-AUTH-005: Client authentication pattern (ServiceAccount tokens)  **Architecture**: This service is the **ONLY** service that directly accesses PostgreSQL. All other services (Context API, Effectiveness Monitor, etc.) access data through this REST API Gateway.  **Authentication & Authorization (Production/E2E)**: All requests to DataStorage are protected by an OAuth-proxy sidecar:  1. **Client Authentication**: Services authenticate with Kubernetes ServiceAccount tokens    - Token mounted at: `/var/run/secrets/kubernetes.io/serviceaccount/token`    - Clients inject: `Authorization: Bearer <token>` header    - See DD-AUTH-005 for client implementation patterns  2. **OAuth-Proxy Validation**: The sidecar validates requests    - Validates JWT token signature and expiration    - Performs Subject Access Review (SAR) to check RBAC permissions    - Injects `X-Auth-Request-User` header with authenticated user identity    - Returns HTTP 401 if token invalid, HTTP 403 if SAR fails  3. **Handler Enforcement**: DataStorage handlers extract user identity    - Legal hold operations REQUIRE `X-Auth-Request-User` header    - HTTP 401 returned if header missing (authentication failed)    - User identity stored in audit events for SOC2 compliance  **Routing Flow**: ``` Client → data-storage-service:8080 (Service)        ↓      oauth-proxy:8080 (validates token + SAR)        ↓      DataStorage:8081 (X-Auth-Request-User header) ```  **Integration Tests**: Integration tests run without oauth-proxy. Use `testutil.NewMockUserTransport()` to inject mock `X-Auth-Request-User` headers directly.  **SOC2 Compliance**: - All legal hold operations attributed to authenticated users - Audit trail captures placed_by/released_by from X-Auth-Request-User - Unauthorized access blocked at oauth-proxy layer (defense-in-depth) 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import Any, ClassVar, Dict, List, Optional, Union
from pydantic import BaseModel, StrictBool, StrictFloat, StrictInt, StrictStr, field_validator
from pydantic import Field
from datastorage.models.effectiveness_assessment_audit_payload_alert_resolution import EffectivenessAssessmentAuditPayloadAlertResolution
from datastorage.models.effectiveness_assessment_audit_payload_health_checks import EffectivenessAssessmentAuditPayloadHealthChecks
from datastorage.models.effectiveness_assessment_audit_payload_metric_deltas import EffectivenessAssessmentAuditPayloadMetricDeltas
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class EffectivenessAssessmentAuditPayload(BaseModel):
    """
    Type-safe audit event payload for Effectiveness Monitor controller. Covers component-level events (health, alert, metrics, hash), the scheduling event (assessment.scheduled), and the lifecycle completion event (assessment.completed). Per ADR-EM-001: Each component assessment emits its own audit event. 
    """ # noqa: E501
    event_type: StrictStr = Field(description="Event type for discriminator (matches parent event_type)")
    correlation_id: StrictStr = Field(description="Correlation ID (EA spec.correlationID, matches parent RR name)")
    namespace: StrictStr = Field(description="Kubernetes namespace of the EffectivenessAssessment")
    ea_name: Optional[StrictStr] = Field(default=None, description="Name of the EffectivenessAssessment CRD")
    component: StrictStr = Field(description="Assessment component that produced this event")
    assessed: Optional[StrictBool] = Field(default=None, description="Whether the component was successfully assessed")
    score: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Component score (0.0-1.0), null if not assessed")
    details: Optional[StrictStr] = Field(default=None, description="Human-readable details about the assessment result")
    reason: Optional[StrictStr] = Field(default=None, description="Assessment completion reason (only for assessment.completed events)")
    alert_name: Optional[StrictStr] = Field(default=None, description="Name of the original alert that triggered the remediation pipeline. Extracted from EA spec target resource context. Only present for assessment.completed events. ")
    components_assessed: Optional[List[StrictStr]] = Field(default=None, description="List of component names that were assessed (e.g. [\"health\",\"hash\",\"alert\",\"metrics\"]). Only present for assessment.completed events. ")
    completed_at: Optional[datetime] = Field(default=None, description="Timestamp when the assessment completed (EA status.completedAt). Only present for assessment.completed events. ")
    assessment_duration_seconds: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Seconds from RemediationRequest creation to assessment completion. Computed as (completedAt - remediationCreatedAt). Null if remediationCreatedAt is not set. Only present for assessment.completed events. Distinct from alert_resolution.resolution_time_seconds which measures alert-level resolution. ")
    validity_deadline: Optional[datetime] = Field(default=None, description="Computed validity deadline (only for assessment.scheduled events). EA.creationTimestamp + validityWindow from EM config. ")
    prometheus_check_after: Optional[datetime] = Field(default=None, description="Computed earliest time for Prometheus check (only for assessment.scheduled events). EA.creationTimestamp + stabilizationWindow. ")
    alertmanager_check_after: Optional[datetime] = Field(default=None, description="Computed earliest time for AlertManager check (only for assessment.scheduled events). EA.creationTimestamp + stabilizationWindow. ")
    validity_window: Optional[StrictStr] = Field(default=None, description="Validity window duration from EM config (only for assessment.scheduled events). Included for operational observability. ")
    stabilization_window: Optional[StrictStr] = Field(default=None, description="Stabilization window duration from EA spec (only for assessment.scheduled events). Included for operational observability. ")
    pre_remediation_spec_hash: Optional[StrictStr] = Field(default=None, description="Canonical SHA-256 hash of the target resource's .spec BEFORE remediation. Retrieved from DataStorage audit trail (remediation.workflow_created event). Format: \"sha256:<hex>\". Only present for effectiveness.hash.computed events. ")
    post_remediation_spec_hash: Optional[StrictStr] = Field(default=None, description="Canonical SHA-256 hash of the target resource's .spec AFTER remediation. Computed by EM during assessment using DD-EM-002 canonical hash algorithm. Format: \"sha256:<hex>\". Only present for effectiveness.hash.computed events. ")
    hash_match: Optional[StrictBool] = Field(default=None, description="Whether the pre and post remediation spec hashes match. true = no change detected (remediation may have been reverted or had no effect). false = spec changed (expected for successful remediations). Only present for effectiveness.hash.computed events. ")
    health_checks: Optional[EffectivenessAssessmentAuditPayloadHealthChecks] = None
    metric_deltas: Optional[EffectivenessAssessmentAuditPayloadMetricDeltas] = None
    alert_resolution: Optional[EffectivenessAssessmentAuditPayloadAlertResolution] = None
    __properties: ClassVar[List[str]] = ["event_type", "correlation_id", "namespace", "ea_name", "component", "assessed", "score", "details", "reason", "alert_name", "components_assessed", "completed_at", "assessment_duration_seconds", "validity_deadline", "prometheus_check_after", "alertmanager_check_after", "validity_window", "stabilization_window", "pre_remediation_spec_hash", "post_remediation_spec_hash", "hash_match", "health_checks", "metric_deltas", "alert_resolution"]

    @field_validator('event_type')
    def event_type_validate_enum(cls, value):
        """Validates the enum"""
        if value not in ('effectiveness.health.assessed', 'effectiveness.hash.computed', 'effectiveness.alert.assessed', 'effectiveness.metrics.assessed', 'effectiveness.assessment.scheduled', 'effectiveness.assessment.completed'):
            raise ValueError("must be one of enum values ('effectiveness.health.assessed', 'effectiveness.hash.computed', 'effectiveness.alert.assessed', 'effectiveness.metrics.assessed', 'effectiveness.assessment.scheduled', 'effectiveness.assessment.completed')")
        return value

    @field_validator('component')
    def component_validate_enum(cls, value):
        """Validates the enum"""
        if value not in ('health', 'alert', 'metrics', 'hash', 'scheduled', 'completed'):
            raise ValueError("must be one of enum values ('health', 'alert', 'metrics', 'hash', 'scheduled', 'completed')")
        return value

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of EffectivenessAssessmentAuditPayload from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of health_checks
        if self.health_checks:
            _dict['health_checks'] = self.health_checks.to_dict()
        # override the default output from pydantic by calling `to_dict()` of metric_deltas
        if self.metric_deltas:
            _dict['metric_deltas'] = self.metric_deltas.to_dict()
        # override the default output from pydantic by calling `to_dict()` of alert_resolution
        if self.alert_resolution:
            _dict['alert_resolution'] = self.alert_resolution.to_dict()
        # set to None if score (nullable) is None
        # and model_fields_set contains the field
        if self.score is None and "score" in self.model_fields_set:
            _dict['score'] = None

        # set to None if assessment_duration_seconds (nullable) is None
        # and model_fields_set contains the field
        if self.assessment_duration_seconds is None and "assessment_duration_seconds" in self.model_fields_set:
            _dict['assessment_duration_seconds'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of EffectivenessAssessmentAuditPayload from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "event_type": obj.get("event_type"),
            "correlation_id": obj.get("correlation_id"),
            "namespace": obj.get("namespace"),
            "ea_name": obj.get("ea_name"),
            "component": obj.get("component"),
            "assessed": obj.get("assessed"),
            "score": obj.get("score"),
            "details": obj.get("details"),
            "reason": obj.get("reason"),
            "alert_name": obj.get("alert_name"),
            "components_assessed": obj.get("components_assessed"),
            "completed_at": obj.get("completed_at"),
            "assessment_duration_seconds": obj.get("assessment_duration_seconds"),
            "validity_deadline": obj.get("validity_deadline"),
            "prometheus_check_after": obj.get("prometheus_check_after"),
            "alertmanager_check_after": obj.get("alertmanager_check_after"),
            "validity_window": obj.get("validity_window"),
            "stabilization_window": obj.get("stabilization_window"),
            "pre_remediation_spec_hash": obj.get("pre_remediation_spec_hash"),
            "post_remediation_spec_hash": obj.get("post_remediation_spec_hash"),
            "hash_match": obj.get("hash_match"),
            "health_checks": EffectivenessAssessmentAuditPayloadHealthChecks.from_dict(obj.get("health_checks")) if obj.get("health_checks") is not None else None,
            "metric_deltas": EffectivenessAssessmentAuditPayloadMetricDeltas.from_dict(obj.get("metric_deltas")) if obj.get("metric_deltas") is not None else None,
            "alert_resolution": EffectivenessAssessmentAuditPayloadAlertResolution.from_dict(obj.get("alert_resolution")) if obj.get("alert_resolution") is not None else None
        })
        return _obj


