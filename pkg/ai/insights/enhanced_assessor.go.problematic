package insights

import (
	"context"
	"fmt"
	"math"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/jordigilh/kubernaut/internal/actionhistory"
	"github.com/jordigilh/kubernaut/pkg/storage/vector"
	"github.com/jordigilh/kubernaut/pkg/platform/monitoring"
	"github.com/jordigilh/kubernaut/pkg/infrastructure/types"
	"github.com/sirupsen/logrus"
)

// EnhancedAssessor combines traditional effectiveness assessment with Phase 2 analytics
type EnhancedAssessor struct {
	// Traditional assessment components
	repo               actionhistory.Repository
	alertClient        monitoring.AlertClient
	metricsClient      monitoring.MetricsClient
	sideEffectDetector monitoring.SideEffectDetector
	log                *logrus.Logger

	// Phase 2 analytics components
	vectorDB         vector.VectorDatabase
	patternExtractor vector.PatternExtractor
	analyticsEngine  *AnalyticsEngine

	// HolmesGPT integration (optional)
	holmesIntegration *HolmesGPTIntegrationService

	// Configuration
	config EnhancedAssessorConfig

	// Metrics and monitoring
	metrics *AssessmentMetrics
}

// EnhancedAssessorConfig configures the enhanced assessor behavior
type EnhancedAssessorConfig struct {
	// Enable/disable Phase 2 features
	EnablePatternLearning     bool `yaml:"enable_pattern_learning" default:"true"`
	EnablePredictiveAnalytics bool `yaml:"enable_predictive_analytics" default:"true"`
	EnableCostAnalysis        bool `yaml:"enable_cost_analysis" default:"false"`
	EnableHolmesGPT           bool `yaml:"enable_holmes_gpt" default:"false"`

	// Pattern storage configuration
	MinSimilarityThreshold float64 `yaml:"min_similarity_threshold" default:"0.3"`
	MaxStoredPatterns      int     `yaml:"max_stored_patterns" default:"10000"`
	PatternRetentionDays   int     `yaml:"pattern_retention_days" default:"90"`

	// Analytics configuration
	PredictionModel         string        `yaml:"prediction_model" default:"similarity"`
	AnalyticsUpdateInterval time.Duration `yaml:"analytics_update_interval" default:"1h"`
	ModelRetrainingInterval time.Duration `yaml:"model_retraining_interval" default:"24h"`

	// Performance configuration
	AsyncProcessing bool `yaml:"async_processing" default:"true"`
	BatchSize       int  `yaml:"batch_size" default:"50"`
	WorkerPoolSize  int  `yaml:"worker_pool_size" default:"10"`
}

// EnhancedEffectivenessResult extends the traditional result with Phase 2 insights
type EnhancedEffectivenessResult struct {
	// Traditional assessment results
	TraditionalFactors *monitoring.EffectivenessFactors `json:"traditional_factors"`
	TraditionalScore   float64                          `json:"traditional_score"`

	// Phase 2 analytics results
	PatternAnalysis    *PatternAnalysisResult   `json:"pattern_analysis,omitempty"`
	PredictiveInsights *PredictiveInsightResult `json:"predictive_insights,omitempty"`
	SimilarPatterns    []*vector.SimilarPattern `json:"similar_patterns,omitempty"`
	CostAnalysis       *CostAnalysisResult      `json:"cost_analysis,omitempty"`

	// Combined final assessment
	EnhancedScore        float64  `json:"enhanced_score"`
	ConfidenceLevel      float64  `json:"confidence_level"`
	AssessmentMethod     string   `json:"assessment_method"`
	Recommendations      []string `json:"recommendations"`
	LearningContribution float64  `json:"learning_contribution"`
}

// PatternAnalysisResult provides insights from pattern matching
type PatternAnalysisResult struct {
	PatternID           string             `json:"pattern_id"`
	MatchingSimilarity  float64            `json:"matching_similarity"`
	HistoricalSuccess   float64            `json:"historical_success"`
	PatternFrequency    int                `json:"pattern_frequency"`
	SeasonalFactors     map[string]float64 `json:"seasonal_factors"`
	ContextualRelevance float64            `json:"contextual_relevance"`
}

// PredictiveInsightResult provides ML-based predictions
type PredictiveInsightResult struct {
	PredictedEffectiveness *EffectivenessPrediction `json:"predicted_effectiveness"`
	ModelConfidence        float64                            `json:"model_confidence"`
	PredictionFactors      map[string]float64                 `json:"prediction_factors"`
	AnomalyScore           float64                            `json:"anomaly_score"`
	TrendAnalysis          string                             `json:"trend_analysis"`
}

// CostAnalysisResult provides cost-effectiveness insights
type CostAnalysisResult struct {
	EstimatedCost        float64            `json:"estimated_cost"`
	ExpectedSavings      float64            `json:"expected_savings"`
	ROI                  float64            `json:"roi"`
	CostEfficiencyRating string             `json:"cost_efficiency_rating"`
	AlternativeCosts     map[string]float64 `json:"alternative_costs"`
}

// ErrorSeverity represents the severity of an error
type ErrorSeverity int

const (
	ErrorSeverityLow ErrorSeverity = iota
	ErrorSeverityMedium
	ErrorSeverityHigh
	ErrorSeverityCritical
)

// AssessmentError represents an error that occurred during assessment
type AssessmentError struct {
	Component string        `json:"component"`
	Operation string        `json:"operation"`
	Error     error         `json:"error"`
	Severity  ErrorSeverity `json:"severity"`
	Timestamp time.Time     `json:"timestamp"`
}

// ErrorCollector collects and manages errors during assessment
type ErrorCollector struct {
	errors []AssessmentError
	mutex  sync.RWMutex
}

// NewErrorCollector creates a new error collector
func NewErrorCollector() *ErrorCollector {
	return &ErrorCollector{
		errors: make([]AssessmentError, 0),
	}
}

// AddError adds an error to the collector
func (ec *ErrorCollector) AddError(component, operation string, err error, severity ErrorSeverity) {
	ec.mutex.Lock()
	defer ec.mutex.Unlock()

	ec.errors = append(ec.errors, AssessmentError{
		Component: component,
		Operation: operation,
		Error:     err,
		Severity:  severity,
		Timestamp: time.Now(),
	})
}

// GetErrors returns all collected errors
func (ec *ErrorCollector) GetErrors() []AssessmentError {
	ec.mutex.RLock()
	defer ec.mutex.RUnlock()

	result := make([]AssessmentError, len(ec.errors))
	copy(result, ec.errors)
	return result
}

// HasCriticalErrors returns true if any critical errors were collected
func (ec *ErrorCollector) HasCriticalErrors() bool {
	ec.mutex.RLock()
	defer ec.mutex.RUnlock()

	for _, err := range ec.errors {
		if err.Severity == ErrorSeverityCritical {
			return true
		}
	}
	return false
}

// GetErrorSummary returns a summary of errors by severity
func (ec *ErrorCollector) GetErrorSummary() map[ErrorSeverity]int {
	ec.mutex.RLock()
	defer ec.mutex.RUnlock()

	summary := make(map[ErrorSeverity]int)
	for _, err := range ec.errors {
		summary[err.Severity]++
	}
	return summary
}

// AssessmentMetrics tracks performance and usage metrics
type AssessmentMetrics struct {
	// Performance metrics
	TotalAssessments          int64         `json:"total_assessments"`
	SuccessfulAssessments     int64         `json:"successful_assessments"`
	FailedAssessments         int64         `json:"failed_assessments"`
	AverageAssessmentDuration time.Duration `json:"average_assessment_duration"`

	// Error metrics
	ErrorsByComponent map[string]int64        `json:"errors_by_component"`
	ErrorsBySeverity  map[ErrorSeverity]int64 `json:"errors_by_severity"`

	// Feature usage metrics
	PatternLearningUsage    int64 `json:"pattern_learning_usage"`
	PredictiveAnalysisUsage int64 `json:"predictive_analysis_usage"`
	CostAnalysisUsage       int64 `json:"cost_analysis_usage"`

	// Resource usage metrics
	WorkerPoolUtilization    float64 `json:"worker_pool_utilization"`
	VectorDBQueryCount       int64   `json:"vector_db_query_count"`
	AnalyticsEngineCallCount int64   `json:"analytics_engine_call_count"`

	// Quality metrics
	AverageConfidenceLevel float64 `json:"average_confidence_level"`
	AverageEnhancedScore   float64 `json:"average_enhanced_score"`

	// Timing metrics
	LastAssessmentTime time.Time `json:"last_assessment_time"`
	StartTime          time.Time `json:"start_time"`

	mutex sync.RWMutex
}

// NewAssessmentMetrics creates a new metrics tracker
func NewAssessmentMetrics() *AssessmentMetrics {
	return &AssessmentMetrics{
		ErrorsByComponent: make(map[string]int64),
		ErrorsBySeverity:  make(map[ErrorSeverity]int64),
		StartTime:         time.Now(),
	}
}

// RecordAssessmentStart records the start of an assessment
func (m *AssessmentMetrics) RecordAssessmentStart() time.Time {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	m.TotalAssessments++
	return time.Now()
}

// RecordAssessmentSuccess records a successful assessment
func (m *AssessmentMetrics) RecordAssessmentSuccess(startTime time.Time, result *EnhancedEffectivenessResult) {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	duration := time.Since(startTime)
	m.SuccessfulAssessments++
	m.LastAssessmentTime = time.Now()

	// Update average duration
	totalDuration := m.AverageAssessmentDuration * time.Duration(m.SuccessfulAssessments-1)
	m.AverageAssessmentDuration = (totalDuration + duration) / time.Duration(m.SuccessfulAssessments)

	// Update quality metrics
	if result != nil {
		totalConfidence := m.AverageConfidenceLevel * float64(m.SuccessfulAssessments-1)
		m.AverageConfidenceLevel = (totalConfidence + result.ConfidenceLevel) / float64(m.SuccessfulAssessments)

		totalScore := m.AverageEnhancedScore * float64(m.SuccessfulAssessments-1)
		m.AverageEnhancedScore = (totalScore + result.EnhancedScore) / float64(m.SuccessfulAssessments)
	}
}

// RecordAssessmentFailure records a failed assessment
func (m *AssessmentMetrics) RecordAssessmentFailure(startTime time.Time) {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	m.FailedAssessments++
	m.LastAssessmentTime = time.Now()
}

// RecordError records an error by component and severity
func (m *AssessmentMetrics) RecordError(component string, severity ErrorSeverity) {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	m.ErrorsByComponent[component]++
	m.ErrorsBySeverity[severity]++
}

// RecordFeatureUsage records usage of optional features
func (m *AssessmentMetrics) RecordFeatureUsage(feature string) {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	switch feature {
	case "pattern_learning":
		m.PatternLearningUsage++
	case "predictive_analysis":
		m.PredictiveAnalysisUsage++
	case "cost_analysis":
		m.CostAnalysisUsage++
	}
}

// RecordResourceUsage records resource usage metrics
func (m *AssessmentMetrics) RecordResourceUsage(resource string) {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	switch resource {
	case "vector_db":
		m.VectorDBQueryCount++
	case "analytics_engine":
		m.AnalyticsEngineCallCount++
	}
}

// UpdateWorkerPoolUtilization updates worker pool utilization
func (m *AssessmentMetrics) UpdateWorkerPoolUtilization(utilization float64) {
	m.mutex.Lock()
	defer m.mutex.Unlock()

	m.WorkerPoolUtilization = utilization
}

// GetMetrics returns a copy of current metrics
func (m *AssessmentMetrics) GetMetrics() AssessmentMetrics {
	m.mutex.RLock()
	defer m.mutex.RUnlock()

	// Create a copy to avoid race conditions
	return AssessmentMetrics{
		TotalAssessments:          m.TotalAssessments,
		SuccessfulAssessments:     m.SuccessfulAssessments,
		FailedAssessments:         m.FailedAssessments,
		AverageAssessmentDuration: m.AverageAssessmentDuration,
		ErrorsByComponent:         copyMap(m.ErrorsByComponent),
		ErrorsBySeverity:          copySeverityMap(m.ErrorsBySeverity),
		PatternLearningUsage:      m.PatternLearningUsage,
		PredictiveAnalysisUsage:   m.PredictiveAnalysisUsage,
		CostAnalysisUsage:         m.CostAnalysisUsage,
		WorkerPoolUtilization:     m.WorkerPoolUtilization,
		VectorDBQueryCount:        m.VectorDBQueryCount,
		AnalyticsEngineCallCount:  m.AnalyticsEngineCallCount,
		AverageConfidenceLevel:    m.AverageConfidenceLevel,
		AverageEnhancedScore:      m.AverageEnhancedScore,
		LastAssessmentTime:        m.LastAssessmentTime,
		StartTime:                 m.StartTime,
	}
}

// Helper functions for copying maps
func copyMap(original map[string]int64) map[string]int64 {
	copy := make(map[string]int64)
	for k, v := range original {
		copy[k] = v
	}
	return copy
}

func copySeverityMap(original map[ErrorSeverity]int64) map[ErrorSeverity]int64 {
	copy := make(map[ErrorSeverity]int64)
	for k, v := range original {
		copy[k] = v
	}
	return copy
}

// assessmentTask represents a task for the worker pool
type assessmentTask struct {
	ctx   context.Context
	trace *actionhistory.ResourceActionTrace
	done  chan *assessmentResult
}

// assessmentResult represents the result of an assessment task
type assessmentResult struct {
	trace  *actionhistory.ResourceActionTrace
	result *EnhancedEffectivenessResult
	err    error
}

// workerPool manages concurrent assessment processing
type workerPool struct {
	tasks    chan assessmentTask
	wg       sync.WaitGroup
	assessor *EnhancedAssessor
}

// NewEnhancedAssessor creates a new enhanced effectiveness assessor
func NewEnhancedAssessor(
	repo actionhistory.Repository,
	monitoringClients *monitoring.MonitoringClients,
	vectorDB vector.VectorDatabase,
	patternExtractor vector.PatternExtractor,
	analyticsEngine *AnalyticsEngine,
	config EnhancedAssessorConfig,
	log *logrus.Logger,
) (*EnhancedAssessor, error) {
	// Validate required dependencies
	if repo == nil {
		return nil, fmt.Errorf("repository cannot be nil")
	}
	if monitoringClients == nil {
		return nil, fmt.Errorf("monitoring clients cannot be nil")
	}
	if log == nil {
		return nil, fmt.Errorf("logger cannot be nil")
	}

	// Create assessor instance for validation
	ea := &EnhancedAssessor{
		repo:               repo,
		alertClient:        monitoringClients.AlertClient,
		metricsClient:      monitoringClients.MetricsClient,
		sideEffectDetector: monitoringClients.SideEffectDetector,
		vectorDB:           vectorDB,
		patternExtractor:   patternExtractor,
		analyticsEngine:    analyticsEngine,
		config:             config,
		log:                log,
		metrics:            NewAssessmentMetrics(),
	}

	// Validate configuration
	if err := ea.validateConfiguration(config); err != nil {
		return nil, fmt.Errorf("invalid configuration: %w", err)
	}

	return ea, nil
}

// ProcessPendingEnhancedAssessments processes assessments with Phase 2 analytics
func (ea *EnhancedAssessor) ProcessPendingEnhancedAssessments(ctx context.Context) error {
	pendingTraces, err := ea.repo.GetPendingEffectivenessAssessments(ctx)
	if err != nil {
		return fmt.Errorf("failed to get pending assessments: %w", err)
	}

	if len(pendingTraces) == 0 {
		ea.log.Debug("No pending effectiveness assessments found")
		return nil
	}

	ea.log.WithField("pending_count", len(pendingTraces)).Info("Processing pending enhanced assessments")

	// Process assessments in batches for efficiency
	batchSize := ea.config.BatchSize
	for i := 0; i < len(pendingTraces); i += batchSize {
		end := i + batchSize
		if end > len(pendingTraces) {
			end = len(pendingTraces)
		}

		batch := pendingTraces[i:end]
		if err := ea.processBatch(ctx, batch); err != nil {
			ea.log.WithError(err).WithField("batch_start", i).Error("Failed to process assessment batch")
			// For context cancellation, return immediately
			if err == context.Canceled || err == context.DeadlineExceeded {
				return err
			}
			// Continue with next batch for other errors
		}
	}

	return nil
}

// SetHolmesGPTIntegration sets the HolmesGPT integration service
func (ea *EnhancedAssessor) SetHolmesGPTIntegration(holmesIntegration *HolmesGPTIntegrationService) {
	ea.holmesIntegration = holmesIntegration
}

// AssessTraceWithHolmesGPT performs assessment using HolmesGPT integration
func (ea *EnhancedAssessor) AssessTraceWithHolmesGPT(ctx context.Context, trace *actionhistory.ResourceActionTrace) (*Investigation, error) {
	if ea.holmesIntegration == nil {
		return nil, fmt.Errorf("HolmesGPT integration not configured")
	}

	if !ea.config.EnableHolmesGPT {
		return nil, fmt.Errorf("HolmesGPT integration is disabled")
	}

	// Convert trace to alert format for HolmesGPT
	alert := &*Alert{
		Name:     trace.AlertName,
		Severity: trace.AlertSeverity,
		Labels:   make(map[string]string),
		StartsAt: time.Now(),
	}

	// Convert AlertLabels to map[string]string
	if trace.AlertLabels != nil {
		for k, v := range trace.AlertLabels {
			if strVal, ok := v.(string); ok {
				alert.Labels[k] = strVal
			} else {
				alert.Labels[k] = fmt.Sprintf("%v", v)
			}
		}
	}

	// Use HolmesGPT integration for comprehensive analysis
	return ea.holmesIntegration.InvestigateWithHistoricalContext(ctx, alert, trace)
}

// AssessTraceWithEnhancement performs enhanced effectiveness assessment for a single trace
func (ea *EnhancedAssessor) AssessTraceWithEnhancement(ctx context.Context, trace *actionhistory.ResourceActionTrace) (*EnhancedEffectivenessResult, error) {
	// Validate input data
	if err := ea.validateTraceData(trace); err != nil {
		return nil, fmt.Errorf("invalid trace data: %w", err)
	}

	// Start metrics tracking
	startTime := ea.metrics.RecordAssessmentStart()

	// Initialize error collector for comprehensive error handling
	errorCollector := NewErrorCollector()

	ea.log.WithFields(logrus.Fields{
		"action_id":   trace.ActionID,
		"action_type": trace.ActionType,
		"alert_name":  trace.AlertName,
	}).Debug("Starting enhanced effectiveness assessment")

	result := &EnhancedEffectivenessResult{
		AssessmentMethod: "enhanced",
	}

	// Step 1: Perform traditional assessment (critical - must succeed)
	traditionalResult, err := ea.performTraditionalAssessment(ctx, trace)
	if err != nil {
		errorCollector.AddError("traditional_assessment", "perform_assessment", err, ErrorSeverityCritical)
		return nil, fmt.Errorf("traditional assessment failed: %w", err)
	}
	result.TraditionalFactors = traditionalResult.factors
	result.TraditionalScore = traditionalResult.score

	// Step 2: Extract and store pattern if enabled (medium severity - can continue without)
	var pattern *vector.ActionPattern
	if ea.config.EnablePatternLearning {
		ea.metrics.RecordFeatureUsage("pattern_learning")
		pattern, err = ea.extractAndStorePattern(ctx, trace)
		if err != nil {
			errorCollector.AddError("pattern_learning", "extract_and_store", err, ErrorSeverityMedium)
			ea.log.WithError(err).Warn("Failed to extract pattern, continuing with traditional assessment")
		}
	}

	// Step 3: Perform pattern analysis if pattern available (low severity - enhancement only)
	if pattern != nil {
		result.PatternAnalysis = ea.performPatternAnalysisWithErrorHandling(ctx, pattern, errorCollector)
		result.SimilarPatterns = ea.findSimilarPatternsWithErrorHandling(ctx, pattern, errorCollector)
	}

	// Step 4: Perform predictive analysis if enabled (medium severity - valuable but not critical)
	if ea.config.EnablePredictiveAnalytics && pattern != nil {
		ea.metrics.RecordFeatureUsage("predictive_analysis")
		result.PredictiveInsights = ea.performPredictiveAnalysisWithErrorHandling(ctx, trace, errorCollector)
	}

	// Step 5: Perform cost analysis if enabled (low severity - nice to have)
	if ea.config.EnableCostAnalysis {
		ea.metrics.RecordFeatureUsage("cost_analysis")
		result.CostAnalysis = ea.performCostAnalysisWithErrorHandling(ctx, trace, pattern, errorCollector)
	}

	// Step 6: Calculate enhanced score
	result.EnhancedScore, result.ConfidenceLevel, result.LearningContribution = ea.calculateEnhancedScore(result)

	// Step 7: Generate recommendations
	result.Recommendations = ea.generateEnhancedRecommendations(result)

	// Step 8: Update the trace with enhanced results (high severity - important for learning)
	if err := ea.updateTraceWithEnhancedResults(ctx, trace, result); err != nil {
		errorCollector.AddError("result_storage", "update_trace", err, ErrorSeverityHigh)
		ea.log.WithError(err).Error("Failed to update trace with enhanced results - learning will be impacted")
	}

	// Log error summary and record errors in metrics
	ea.logErrorSummary(trace.ActionID, errorCollector)
	for _, assessmentError := range errorCollector.GetErrors() {
		ea.metrics.RecordError(assessmentError.Component, assessmentError.Severity)
	}

	// Check if we should fail the assessment due to critical errors
	if errorCollector.HasCriticalErrors() {
		ea.metrics.RecordAssessmentFailure(startTime)
		return nil, fmt.Errorf("assessment failed due to critical errors")
	}

	// Record successful assessment
	ea.metrics.RecordAssessmentSuccess(startTime, result)

	ea.log.WithFields(logrus.Fields{
		"action_id":             trace.ActionID,
		"traditional_score":     result.TraditionalScore,
		"enhanced_score":        result.EnhancedScore,
		"confidence_level":      result.ConfidenceLevel,
		"learning_contribution": result.LearningContribution,
		"error_count":           len(errorCollector.GetErrors()),
		"assessment_duration":   time.Since(startTime),
	}).Info("Completed enhanced effectiveness assessment")

	return result, nil
}

// GetAnalyticsInsights provides comprehensive analytics insights
func (ea *EnhancedAssessor) GetAnalyticsInsights(ctx context.Context) (*AnalyticsInsights, error) {
	if ea.analyticsEngine == nil {
		return nil, fmt.Errorf("analytics engine not available")
	}

	return ea.analyticsEngine.GenerateInsights(ctx)
}

// TrainModels triggers retraining of prediction models
func (ea *EnhancedAssessor) TrainModels(ctx context.Context) error {
	if ea.analyticsEngine == nil {
		return fmt.Errorf("analytics engine not available")
	}

	ea.log.Info("Starting model training with latest data")

	if err := ea.analyticsEngine.TrainModels(ctx); err != nil {
		return fmt.Errorf("model training failed: %w", err)
	}

	ea.log.Info("Model training completed successfully")
	return nil
}

// GetPatternAnalytics provides insights about stored patterns
func (ea *EnhancedAssessor) GetPatternAnalytics(ctx context.Context) (*vector.PatternAnalytics, error) {
	if ea.vectorDB == nil {
		return nil, fmt.Errorf("vector database not available")
	}

	return ea.vectorDB.GetPatternAnalytics(ctx)
}

// Private methods

type traditionalAssessmentResult struct {
	factors *monitoring.EffectivenessFactors
	score   float64
}

func (ea *EnhancedAssessor) performTraditionalAssessment(ctx context.Context, trace *actionhistory.ResourceActionTrace) (*traditionalAssessmentResult, error) {
	// Use the existing assessment logic from the original assessor
	factors, err := ea.calculateEffectivenessFactors(ctx, trace)
	if err != nil {
		return nil, err
	}

	score := ea.calculateOverallEffectiveness(factors)

	return &traditionalAssessmentResult{
		factors: factors,
		score:   score,
	}, nil
}

func (ea *EnhancedAssessor) extractAndStorePattern(ctx context.Context, trace *actionhistory.ResourceActionTrace) (*vector.ActionPattern, error) {
	pattern, err := ea.patternExtractor.ExtractPattern(ctx, trace)
	if err != nil {
		return nil, fmt.Errorf("failed to extract pattern: %w", err)
	}

	// Store pattern in vector database for future learning
	if err := ea.vectorDB.StoreActionPattern(ctx, pattern); err != nil {
		ea.log.WithError(err).Warn("Failed to store pattern in vector database")
		// Continue anyway - pattern extraction succeeded
	}

	return pattern, nil
}

func (ea *EnhancedAssessor) performPatternAnalysis(ctx context.Context, pattern *vector.ActionPattern) *PatternAnalysisResult {
	// Find similar historical patterns
	similarPatterns, err := ea.vectorDB.FindSimilarPatterns(ctx, pattern, 10, ea.config.MinSimilarityThreshold)
	if err != nil {
		ea.log.WithError(err).Warn("Failed to find similar patterns")
		return nil
	}

	if len(similarPatterns) == 0 {
		return &PatternAnalysisResult{
			PatternID:           pattern.ID,
			MatchingSimilarity:  0.0,
			HistoricalSuccess:   0.5, // Default
			PatternFrequency:    0,
			SeasonalFactors:     make(map[string]float64),
			ContextualRelevance: 0.0,
		}
	}

	// Calculate historical success rate
	successCount := 0
	totalCount := len(similarPatterns)
	maxSimilarity := 0.0

	for _, simPattern := range similarPatterns {
		if simPattern.Similarity > maxSimilarity {
			maxSimilarity = simPattern.Similarity
		}

		if simPattern.Pattern.EffectivenessData != nil && simPattern.Pattern.EffectivenessData.Score >= 0.6 {
			successCount++
		}
	}

	historicalSuccess := float64(successCount) / float64(totalCount)

	return &PatternAnalysisResult{
		PatternID:           pattern.ID,
		MatchingSimilarity:  maxSimilarity,
		HistoricalSuccess:   historicalSuccess,
		PatternFrequency:    totalCount,
		SeasonalFactors:     ea.calculateSeasonalFactors(pattern),
		ContextualRelevance: ea.calculateContextualRelevance(pattern, similarPatterns),
	}
}

func (ea *EnhancedAssessor) findSimilarPatterns(ctx context.Context, pattern *vector.ActionPattern) []*vector.SimilarPattern {
	similarPatterns, err := ea.vectorDB.FindSimilarPatterns(ctx, pattern, 5, ea.config.MinSimilarityThreshold)
	if err != nil {
		ea.log.WithError(err).Warn("Failed to find similar patterns")
		return []*vector.SimilarPattern{}
	}
	return similarPatterns
}

func (ea *EnhancedAssessor) performPredictiveAnalysis(ctx context.Context, trace *actionhistory.ResourceActionTrace) *PredictiveInsightResult {
	prediction, err := ea.analyticsEngine.PredictEffectiveness(ctx, trace, ea.config.PredictionModel)
	if err != nil {
		ea.log.WithError(err).Warn("Failed to generate effectiveness prediction")
		return nil
	}

	return &PredictiveInsightResult{
		PredictedEffectiveness: prediction,
		ModelConfidence:        prediction.Confidence,
		PredictionFactors:      prediction.FactorContributions,
		AnomalyScore:           ea.calculateAnomalyScore(prediction),
		TrendAnalysis:          ea.analyzeTrend(prediction),
	}
}

func (ea *EnhancedAssessor) performCostAnalysis(_ context.Context, trace *actionhistory.ResourceActionTrace, pattern *vector.ActionPattern) *CostAnalysisResult {
	// Simplified cost analysis - in a real implementation, this would integrate with cost monitoring systems
	estimatedCost := ea.estimateActionCost(trace)
	expectedSavings := ea.estimateExpectedSavings(trace, pattern)

	roi := 0.0
	if estimatedCost > 0 {
		roi = (expectedSavings - estimatedCost) / estimatedCost
	}

	var rating string
	if roi > 2.0 {
		rating = "excellent"
	} else if roi > 1.0 {
		rating = "good"
	} else if roi > 0.0 {
		rating = "fair"
	} else {
		rating = "poor"
	}

	return &CostAnalysisResult{
		EstimatedCost:        estimatedCost,
		ExpectedSavings:      expectedSavings,
		ROI:                  roi,
		CostEfficiencyRating: rating,
		AlternativeCosts:     ea.calculateAlternativeCosts(trace),
	}
}

func (ea *EnhancedAssessor) calculateEnhancedScore(result *EnhancedEffectivenessResult) (enhancedScore, confidence, learningContribution float64) {
	// Start with traditional score
	enhancedScore = result.TraditionalScore
	confidence = 0.7 // Base confidence for traditional assessment
	learningContribution = 0.0

	// Incorporate pattern analysis if available
	if result.PatternAnalysis != nil {
		patternWeight := 0.3 * result.PatternAnalysis.MatchingSimilarity
		historicalComponent := result.PatternAnalysis.HistoricalSuccess * patternWeight
		enhancedScore = 0.7*enhancedScore + 0.3*historicalComponent
		confidence += 0.1 * result.PatternAnalysis.MatchingSimilarity
		learningContribution += patternWeight
	}

	// Incorporate predictive insights if available
	if result.PredictiveInsights != nil {
		predictionWeight := 0.2 * result.PredictiveInsights.ModelConfidence
		predictiveComponent := result.PredictiveInsights.PredictedEffectiveness.PredictedScore * predictionWeight
		enhancedScore = 0.8*enhancedScore + 0.2*predictiveComponent
		confidence += 0.15 * result.PredictiveInsights.ModelConfidence
		learningContribution += predictionWeight
	}

	// Cap values at reasonable bounds
	enhancedScore = clamp(enhancedScore, 0.0, 1.0)
	confidence = clamp(confidence, 0.1, 0.95)
	learningContribution = clamp(learningContribution, 0.0, 1.0)

	return enhancedScore, confidence, learningContribution
}

func (ea *EnhancedAssessor) generateEnhancedRecommendations(result *EnhancedEffectivenessResult) []string {
	var recommendations []string

	// Add traditional recommendations based on score
	if result.EnhancedScore >= 0.8 {
		recommendations = append(recommendations, "High effectiveness predicted - proceed with confidence")
	} else if result.EnhancedScore >= 0.6 {
		recommendations = append(recommendations, "Moderate effectiveness expected - monitor closely")
	} else {
		recommendations = append(recommendations, "Low effectiveness predicted - consider alternatives")
	}

	// Add pattern-based recommendations
	if result.PatternAnalysis != nil {
		if result.PatternAnalysis.HistoricalSuccess >= 0.8 {
			recommendations = append(recommendations, "Similar historical patterns show high success rate")
		} else if result.PatternAnalysis.PatternFrequency < 3 {
			recommendations = append(recommendations, "Limited historical data - proceed with caution")
		}
	}

	// Add predictive recommendations
	if result.PredictiveInsights != nil && len(result.PredictiveInsights.PredictedEffectiveness.Recommendations) > 0 {
		recommendations = append(recommendations, result.PredictiveInsights.PredictedEffectiveness.Recommendations...)
	}

	// Add cost-based recommendations
	if result.CostAnalysis != nil {
		if result.CostAnalysis.ROI > 1.0 {
			recommendations = append(recommendations, "Positive ROI expected - economically beneficial")
		} else {
			recommendations = append(recommendations, "Negative ROI - evaluate cost-benefit carefully")
		}
	}

	return recommendations
}

func (ea *EnhancedAssessor) processBatch(ctx context.Context, traces []*actionhistory.ResourceActionTrace) error {
	if ea.config.AsyncProcessing {
		return ea.processBatchWithWorkerPool(ctx, traces)
	} else {
		return ea.processBatchSequentially(ctx, traces)
	}
}

// processBatchSequentially processes traces one by one
func (ea *EnhancedAssessor) processBatchSequentially(ctx context.Context, traces []*actionhistory.ResourceActionTrace) error {
	for _, trace := range traces {
		// Check for context cancellation
		select {
		case <-ctx.Done():
			return ctx.Err()
		default:
		}

		if _, err := ea.AssessTraceWithEnhancement(ctx, trace); err != nil {
			ea.log.WithError(err).WithField("action_id", trace.ActionID).Error("Failed to assess trace")
			// For context cancellation, return immediately
			if err == context.Canceled || err == context.DeadlineExceeded {
				return err
			}
		}
	}
	return nil
}

// processBatchWithWorkerPool processes traces using a worker pool
func (ea *EnhancedAssessor) processBatchWithWorkerPool(ctx context.Context, traces []*actionhistory.ResourceActionTrace) error {
	if len(traces) == 0 {
		return nil
	}

	// Create worker pool
	pool := ea.createWorkerPool(ctx, ea.config.WorkerPoolSize)
	defer pool.shutdown()

	// Submit tasks and collect results
	results := make([]*assessmentResult, 0, len(traces))
	resultsCh := make(chan *assessmentResult, len(traces))

	// Submit all tasks
	for _, trace := range traces {
		task := assessmentTask{
			ctx:   ctx,
			trace: trace,
			done:  resultsCh,
		}
		select {
		case pool.tasks <- task:
			// Task submitted successfully
		case <-ctx.Done():
			ea.log.Warn("Context cancelled while submitting assessment tasks")
			return ctx.Err()
		}
	}

	// Collect results
	for i := 0; i < len(traces); i++ {
		select {
		case result := <-resultsCh:
			results = append(results, result)
			if result.err != nil {
				ea.log.WithError(result.err).
					WithField("action_id", result.trace.ActionID).
					Error("Failed to assess trace in worker pool")
			}
		case <-ctx.Done():
			ea.log.Warn("Context cancelled while collecting assessment results")
			return ctx.Err()
		}
	}

	ea.log.WithField("processed_count", len(results)).Debug("Completed batch processing with worker pool")
	return nil
}

// createWorkerPool creates and starts a new worker pool
func (ea *EnhancedAssessor) createWorkerPool(ctx context.Context, poolSize int) *workerPool {
	pool := &workerPool{
		tasks:    make(chan assessmentTask, poolSize*2), // Buffer for better throughput
		assessor: ea,
	}

	// Start workers
	for i := 0; i < poolSize; i++ {
		pool.wg.Add(1)
		go pool.worker(ctx, i)
	}

	return pool
}

// worker processes assessment tasks from the task channel
func (wp *workerPool) worker(ctx context.Context, workerID int) {
	defer wp.wg.Done()

	wp.assessor.log.WithField("worker_id", workerID).Debug("Worker started")
	defer wp.assessor.log.WithField("worker_id", workerID).Debug("Worker stopped")

	for {
		select {
		case task, ok := <-wp.tasks:
			if !ok {
				// Channel closed, worker should exit
				return
			}

			// Process the assessment task
			result, err := wp.assessor.AssessTraceWithEnhancement(task.ctx, task.trace)

			// Send result back
			select {
			case task.done <- &assessmentResult{
				trace:  task.trace,
				result: result,
				err:    err,
			}:
				// Result sent successfully
			case <-ctx.Done():
				// Context cancelled, exit worker
				wp.assessor.log.WithField("worker_id", workerID).Warn("Worker exiting due to context cancellation")
				return
			}

		case <-ctx.Done():
			// Context cancelled, exit worker
			wp.assessor.log.WithField("worker_id", workerID).Warn("Worker exiting due to context cancellation")
			return
		}
	}
}

// shutdown gracefully shuts down the worker pool
func (wp *workerPool) shutdown() {
	close(wp.tasks)
	wp.wg.Wait()
}

// Utility functions

func clamp(value, min, max float64) float64 {
	if value < min {
		return min
	}
	if value > max {
		return max
	}
	return value
}

// Helper method implementations
func (ea *EnhancedAssessor) calculateSeasonalFactors(pattern *vector.ActionPattern) map[string]float64 {
	factors := make(map[string]float64)

	if pattern == nil || pattern.CreatedAt.IsZero() {
		return factors
	}

	// Calculate time-based factors
	now := time.Now()
	hour := pattern.CreatedAt.Hour()
	weekday := pattern.CreatedAt.Weekday()
	month := pattern.CreatedAt.Month()

	// Business hours factor (9 AM - 5 PM weekdays)
	if weekday >= time.Monday && weekday <= time.Friday && hour >= 9 && hour <= 17 {
		factors["business_hours"] = 1.2 // Higher effectiveness during business hours
	} else {
		factors["business_hours"] = 0.8 // Lower effectiveness outside business hours
	}

	// Weekend factor
	if weekday == time.Saturday || weekday == time.Sunday {
		factors["weekend"] = 0.9 // Slightly lower effectiveness on weekends
	} else {
		factors["weekend"] = 1.0
	}

	// Night factor (10 PM - 6 AM)
	if hour >= 22 || hour <= 6 {
		factors["night_hours"] = 0.7 // Lower effectiveness at night
	} else {
		factors["night_hours"] = 1.0
	}

	// Monthly seasonality (some months have more incidents)
	switch month {
	case time.December, time.January: // Holiday season
		factors["holiday_season"] = 0.8
	case time.March, time.September: // Common deployment months
		factors["deployment_season"] = 1.1
	default:
		factors["seasonal"] = 1.0
	}

	// Age factor - how recent is the pattern
	age := now.Sub(pattern.CreatedAt)
	if age < 24*time.Hour {
		factors["recency"] = 1.2 // Very recent patterns are more relevant
	} else if age < 7*24*time.Hour {
		factors["recency"] = 1.1 // Recent patterns are more relevant
	} else if age < 30*24*time.Hour {
		factors["recency"] = 1.0 // Normal relevance
	} else {
		factors["recency"] = 0.9 // Older patterns are less relevant
	}

	return factors
}

func (ea *EnhancedAssessor) calculateContextualRelevance(pattern *vector.ActionPattern, similarPatterns []*vector.SimilarPattern) float64 {
	if pattern == nil || len(similarPatterns) == 0 {
		return 0.0
	}

	var relevanceScore float64
	var totalWeight float64

	// Base relevance from pattern metadata
	baseRelevance := 0.5

	// Factor 1: Action type match relevance
	actionTypeMatches := 0
	for _, similar := range similarPatterns {
		if similar.Pattern != nil && similar.Pattern.ActionType == pattern.ActionType {
			actionTypeMatches++
		}
	}
	actionTypeRelevance := float64(actionTypeMatches) / float64(len(similarPatterns))
	relevanceScore += actionTypeRelevance * 0.3
	totalWeight += 0.3

	// Factor 2: Namespace/context similarity
	namespaceMatches := 0
	for _, similar := range similarPatterns {
		if similar.Pattern != nil && similar.Pattern.Namespace == pattern.Namespace {
			namespaceMatches++
		}
	}
	namespaceRelevance := float64(namespaceMatches) / float64(len(similarPatterns))
	relevanceScore += namespaceRelevance * 0.2
	totalWeight += 0.2

	// Factor 3: Severity level similarity
	severityMatches := 0
	for _, similar := range similarPatterns {
		if similar.Pattern != nil && similar.Pattern.AlertSeverity == pattern.AlertSeverity {
			severityMatches++
		}
	}
	severityRelevance := float64(severityMatches) / float64(len(similarPatterns))
	relevanceScore += severityRelevance * 0.2
	totalWeight += 0.2

	// Factor 4: Average similarity score of similar patterns
	var avgSimilarity float64
	for _, similar := range similarPatterns {
		avgSimilarity += similar.Similarity
	}
	avgSimilarity /= float64(len(similarPatterns))
	relevanceScore += avgSimilarity * 0.3
	totalWeight += 0.3

	// Normalize and combine with base relevance
	if totalWeight > 0 {
		normalizedScore := relevanceScore / totalWeight
		return (normalizedScore + baseRelevance) / 2.0
	}

	return baseRelevance
}

func (ea *EnhancedAssessor) calculateAnomalyScore(prediction *EffectivenessPrediction) float64 {
	if prediction == nil {
		return 0.0
	}

	var anomalyScore float64

	// Factor 1: Confidence deviation - low confidence indicates potential anomaly
	if prediction.Confidence < 0.5 {
		anomalyScore += (0.5 - prediction.Confidence) * 2.0 // Scale to 0-1
	}

	// Factor 2: Predicted score extremes - very high or very low scores can be anomalous
	if prediction.PredictedScore > 0.9 || prediction.PredictedScore < 0.1 {
		extremeDeviation := math.Abs(prediction.PredictedScore-0.5) - 0.4 // Beyond normal range
		if extremeDeviation > 0 {
			anomalyScore += extremeDeviation * 2.0
		}
	}

	// Factor 3: Risk factors presence - multiple risk factors indicate anomaly
	riskFactorScore := float64(len(prediction.RiskFactors)) / 10.0 // Normalize assuming max 10 risk factors
	anomalyScore += riskFactorScore * 0.3

	// Factor 4: Factor contribution imbalance - check if any single factor dominates
	if len(prediction.FactorContributions) > 0 {
		var maxContribution, totalContribution float64
		for _, contribution := range prediction.FactorContributions {
			totalContribution += math.Abs(contribution)
			if math.Abs(contribution) > maxContribution {
				maxContribution = math.Abs(contribution)
			}
		}

		if totalContribution > 0 {
			dominanceRatio := maxContribution / totalContribution
			if dominanceRatio > 0.7 { // Single factor contributes more than 70%
				anomalyScore += (dominanceRatio - 0.7) * 0.5
			}
		}
	}

	// Factor 5: Model uncertainty - if model used is not the primary model
	if prediction.ModelUsed != "similarity" && prediction.ModelUsed != "statistical" {
		anomalyScore += 0.2 // Fallback or unusual model used
	}

	// Clamp to [0.0, 1.0] range
	return clamp(anomalyScore, 0.0, 1.0)
}

func (ea *EnhancedAssessor) analyzeTrend(prediction *EffectivenessPrediction) string {
	if prediction == nil {
		return "unknown"
	}

	// Analyze based on predicted score and confidence
	score := prediction.PredictedScore
	confidence := prediction.Confidence

	// High confidence trends
	if confidence >= 0.8 {
		if score >= 0.8 {
			return "strongly_improving"
		} else if score >= 0.6 {
			return "improving"
		} else if score >= 0.4 {
			return "stable"
		} else if score >= 0.2 {
			return "declining"
		} else {
			return "strongly_declining"
		}
	}

	// Medium confidence trends
	if confidence >= 0.6 {
		if score >= 0.7 {
			return "likely_improving"
		} else if score >= 0.3 {
			return "stable"
		} else {
			return "likely_declining"
		}
	}

	// Low confidence - analyze risk factors
	riskFactorCount := len(prediction.RiskFactors)
	if riskFactorCount >= 3 {
		return "unstable_declining"
	} else if riskFactorCount >= 1 {
		return "unstable"
	}

	// Analyze factor contributions for trend direction
	if len(prediction.FactorContributions) > 0 {
		var positiveContributions, negativeContributions float64
		for _, contribution := range prediction.FactorContributions {
			if contribution > 0 {
				positiveContributions += contribution
			} else {
				negativeContributions += math.Abs(contribution)
			}
		}

		totalContributions := positiveContributions + negativeContributions
		if totalContributions > 0 {
			positiveRatio := positiveContributions / totalContributions
			if positiveRatio > 0.7 {
				return "trending_positive"
			} else if positiveRatio < 0.3 {
				return "trending_negative"
			}
		}
	}

	return "stable"
}

func (ea *EnhancedAssessor) estimateActionCost(trace *actionhistory.ResourceActionTrace) float64 {
	if trace == nil {
		return 0.0
	}

	baseCost := 1.0 // Base cost unit

	// Cost varies by action type
	switch trace.ActionType {
	case "scale_deployment":
		// Scaling cost depends on replica changes
		if params, ok := trace.ActionParameters["replicas"]; ok {
			if replicas, ok := params.(float64); ok {
				// Cost increases with number of replicas
				return baseCost * (1.0 + replicas*0.1)
			}
		}
		return baseCost * 1.5 // Default scaling cost

	case "increase_resources":
		// Resource increase cost depends on CPU/memory changes
		cpuMultiplier := 1.0
		memoryMultiplier := 1.0

		if params, ok := trace.ActionParameters["cpu"]; ok {
			if cpu, ok := params.(string); ok {
				// Parse CPU values like "500m", "1", "2"
				if strings.HasSuffix(cpu, "m") {
					if milliCPU, err := strconv.ParseFloat(strings.TrimSuffix(cpu, "m"), 64); err == nil {
						cpuMultiplier = 1.0 + (milliCPU/1000.0)*0.5 // 50% cost per CPU
					}
				} else {
					if cpuCores, err := strconv.ParseFloat(cpu, 64); err == nil {
						cpuMultiplier = 1.0 + cpuCores*0.5
					}
				}
			}
		}

		if params, ok := trace.ActionParameters["memory"]; ok {
			if memory, ok := params.(string); ok {
				// Parse memory values like "512Mi", "1Gi", "2Gi"
				if strings.HasSuffix(memory, "Mi") {
					if memMi, err := strconv.ParseFloat(strings.TrimSuffix(memory, "Mi"), 64); err == nil {
						memoryMultiplier = 1.0 + (memMi/1024.0)*0.3 // 30% cost per GB
					}
				} else if strings.HasSuffix(memory, "Gi") {
					if memGi, err := strconv.ParseFloat(strings.TrimSuffix(memory, "Gi"), 64); err == nil {
						memoryMultiplier = 1.0 + memGi*0.3
					}
				}
			}
		}

		return baseCost * cpuMultiplier * memoryMultiplier

	case "restart_pod":
		return baseCost * 0.5 // Low cost operation

	case "rollback_deployment":
		return baseCost * 2.0 // Higher cost due to potential disruption

	case "drain_node":
		return baseCost * 3.0 // High cost operation affecting entire node

	case "expand_pvc":
		// Cost depends on storage size increase
		if params, ok := trace.ActionParameters["size"]; ok {
			if size, ok := params.(string); ok {
				if strings.HasSuffix(size, "Gi") {
					if sizeGi, err := strconv.ParseFloat(strings.TrimSuffix(size, "Gi"), 64); err == nil {
						return baseCost * (1.0 + sizeGi*0.1) // 10% cost per GB
					}
				}
			}
		}
		return baseCost * 1.2 // Default storage expansion cost

	case "notify_only":
		return baseCost * 0.1 // Very low cost

	default:
		return baseCost // Default cost for unknown actions
	}
}

func (ea *EnhancedAssessor) estimateExpectedSavings(trace *actionhistory.ResourceActionTrace, pattern *vector.ActionPattern) float64 {
	if trace == nil {
		return 0.0
	}

	baseSavings := 2.0 // Base savings unit

	// Historical effectiveness from pattern
	effectivenessMultiplier := 1.0
	if pattern != nil && pattern.EffectivenessData != nil {
		effectivenessMultiplier = pattern.EffectivenessData.Score
	}

	// Savings vary by action type and severity
	severityMultiplier := ea.getSeverityMultiplier(trace.AlertSeverity)

	switch trace.ActionType {
	case "scale_deployment":
		// Scaling can prevent resource exhaustion and downtime
		return baseSavings * 2.0 * effectivenessMultiplier * severityMultiplier

	case "increase_resources":
		// Resource increases prevent performance degradation
		return baseSavings * 3.0 * effectivenessMultiplier * severityMultiplier

	case "restart_pod":
		// Restarts can fix stuck processes and memory leaks
		return baseSavings * 1.5 * effectivenessMultiplier * severityMultiplier

	case "rollback_deployment":
		// Rollbacks can prevent widespread service disruption
		return baseSavings * 4.0 * effectivenessMultiplier * severityMultiplier

	case "drain_node":
		// Node draining can prevent cascading failures
		return baseSavings * 5.0 * effectivenessMultiplier * severityMultiplier

	case "expand_pvc":
		// Storage expansion prevents data loss and service interruption
		return baseSavings * 2.5 * effectivenessMultiplier * severityMultiplier

	case "notify_only":
		// Notifications enable human intervention
		return baseSavings * 0.5 * effectivenessMultiplier * severityMultiplier

	default:
		return baseSavings * effectivenessMultiplier * severityMultiplier
	}
}

func (ea *EnhancedAssessor) getSeverityMultiplier(severity string) float64 {
	switch strings.ToLower(severity) {
	case "critical":
		return 3.0 // Critical issues have highest savings potential
	case "warning":
		return 2.0 // Warning issues have good savings potential
	case "info":
		return 1.0 // Info issues have moderate savings potential
	default:
		return 1.5 // Unknown severity - conservative estimate
	}
}

func (ea *EnhancedAssessor) calculateAlternativeCosts(trace *actionhistory.ResourceActionTrace) map[string]float64 {
	alternatives := make(map[string]float64)

	if trace == nil {
		return alternatives
	}

	baseCost := ea.estimateActionCost(trace)

	// Calculate costs for alternative actions based on current action type
	switch trace.ActionType {
	case "scale_deployment":
		alternatives["increase_resources"] = baseCost * 1.8 // More expensive but more targeted
		alternatives["restart_pod"] = baseCost * 0.3        // Cheaper but less effective
		alternatives["notify_only"] = baseCost * 0.1        // Cheapest but requires human intervention

	case "increase_resources":
		alternatives["scale_deployment"] = baseCost * 0.8    // Cheaper but may not address root cause
		alternatives["restart_pod"] = baseCost * 0.2         // Much cheaper but temporary fix
		alternatives["rollback_deployment"] = baseCost * 1.5 // More expensive but comprehensive

	case "restart_pod":
		alternatives["scale_deployment"] = baseCost * 3.0   // More expensive but addresses capacity
		alternatives["increase_resources"] = baseCost * 4.0 // Most expensive but comprehensive
		alternatives["notify_only"] = baseCost * 0.2        // Cheaper but requires human action

	case "rollback_deployment":
		alternatives["restart_pod"] = baseCost * 0.25      // Much cheaper but may not fix issue
		alternatives["scale_deployment"] = baseCost * 0.75 // Cheaper but doesn't address code issues
		alternatives["notify_only"] = baseCost * 0.05      // Cheapest but requires manual intervention

	case "drain_node":
		alternatives["restart_pod"] = baseCost * 0.17     // Much cheaper but affects single pod
		alternatives["scale_deployment"] = baseCost * 0.5 // Cheaper but doesn't address node issues
		alternatives["notify_only"] = baseCost * 0.03     // Cheapest but requires immediate human action

	case "expand_pvc":
		alternatives["notify_only"] = baseCost * 0.08      // Cheaper but requires manual storage management
		alternatives["scale_deployment"] = baseCost * 1.25 // More expensive and doesn't address storage

	case "notify_only":
		alternatives["restart_pod"] = baseCost * 5.0         // More expensive but automated
		alternatives["scale_deployment"] = baseCost * 15.0   // Much more expensive but comprehensive
		alternatives["increase_resources"] = baseCost * 20.0 // Most expensive but thorough

	default:
		// For unknown actions, provide generic alternatives
		alternatives["restart_pod"] = baseCost * 0.5
		alternatives["scale_deployment"] = baseCost * 1.5
		alternatives["notify_only"] = baseCost * 0.1
	}

	return alternatives
}

func (ea *EnhancedAssessor) updateTraceWithEnhancedResults(ctx context.Context, trace *actionhistory.ResourceActionTrace, result *EnhancedEffectivenessResult) error {
	// Update trace with enhanced results
	trace.EffectivenessScore = &result.EnhancedScore
	assessedAt := time.Now()
	trace.EffectivenessAssessedAt = &assessedAt
	method := "enhanced_assessment"
	trace.EffectivenessAssessmentMethod = &method

	// Create notes with enhanced information
	notes := fmt.Sprintf("Enhanced assessment: score=%.3f, confidence=%.3f, learning_contribution=%.3f",
		result.EnhancedScore, result.ConfidenceLevel, result.LearningContribution)
	trace.EffectivenessNotes = &notes

	return ea.repo.UpdateActionTrace(ctx, trace)
}

// Implement traditional assessment methods (using the real logic from Assessor)
func (ea *EnhancedAssessor) calculateEffectivenessFactors(ctx context.Context, trace *actionhistory.ResourceActionTrace) (*monitoring.EffectivenessFactors, error) {
	factors := &monitoring.EffectivenessFactors{}

	// Extract alert info from trace
	alert := types.Alert{
		Name:      trace.AlertName,
		Severity:  trace.AlertSeverity,
		Namespace: ea.extractNamespaceFromLabels(trace.AlertLabels),
	}

	// Factor 1: Check if original alert resolved
	if ea.alertClient != nil && trace.ExecutionEndTime != nil {
		resolved, err := ea.alertClient.IsAlertResolved(ctx, alert.Name, alert.Namespace, *trace.ExecutionEndTime)
		if err != nil {
			ea.log.WithError(err).Warn("Failed to check alert resolution status")
		} else {
			factors.AlertResolved = resolved
		}

		// Factor 2: Check if alert recurred
		recurred, err := ea.alertClient.HasAlertRecurred(ctx, alert.Name, alert.Namespace, *trace.ExecutionEndTime, time.Now())
		if err != nil {
			ea.log.WithError(err).Warn("Failed to check alert recurrence")
		} else {
			factors.AlertRecurred = recurred
		}
	}

	// Factor 3: Check metrics improvement
	if ea.metricsClient != nil {
		improved, err := ea.metricsClient.CheckMetricsImprovement(ctx, alert, trace)
		if err != nil {
			ea.log.WithError(err).Warn("Failed to check metrics improvement")
		} else {
			factors.MetricsImproved = improved
		}
	}

	// Factor 4: Check for side effects
	if ea.sideEffectDetector != nil && trace.ExecutionEndTime != nil {
		sideEffects, err := ea.sideEffectDetector.DetectSideEffects(ctx, trace)
		if err != nil {
			ea.log.WithError(err).Warn("Failed to detect side effects")
		} else {
			factors.SideEffectsDetected = len(sideEffects) > 0
		}
	}

	// Factor 5: Resource stabilization (simple heuristic for now)
	factors.ResourceStabilized = factors.AlertResolved && !factors.AlertRecurred

	return factors, nil
}

func (ea *EnhancedAssessor) calculateOverallEffectiveness(factors *monitoring.EffectivenessFactors) float64 {
	score := 0.0

	// Base score for alert resolution (40% weight)
	if factors.AlertResolved {
		score += 0.4
	}

	// Metrics improvement (30% weight)
	if factors.MetricsImproved {
		score += 0.3
	}

	// No recurrence (20% weight)
	if !factors.AlertRecurred {
		score += 0.2
	}

	// No side effects (10% weight)
	if !factors.SideEffectsDetected {
		score += 0.1
	}

	// Penalties for negative outcomes
	if factors.AlertRecurred {
		score -= 0.3 // Heavy penalty for recurrence
	}

	if factors.SideEffectsDetected {
		score -= 0.2 // Penalty for side effects
	}

	// Ensure score is within bounds [0.0, 1.0]
	return math.Max(0.0, math.Min(1.0, score))
}

// ProcessPendingAssessments implements the AssessmentProcessor interface
func (ea *EnhancedAssessor) ProcessPendingAssessments(ctx context.Context) error {
	return ea.ProcessPendingEnhancedAssessments(ctx)
}

// extractNamespaceFromLabels extracts namespace from alert labels
func (ea *EnhancedAssessor) extractNamespaceFromLabels(labels actionhistory.JSONMap) string {
	if labels == nil {
		return "default"
	}

	labelsMap := map[string]interface{}(labels)

	if ns, ok := labelsMap["namespace"]; ok {
		if nsStr, ok := ns.(string); ok {
			return nsStr
		}
	}

	return "default"
}

// Error-handling versions of methods
func (ea *EnhancedAssessor) performPatternAnalysisWithErrorHandling(ctx context.Context, pattern *vector.ActionPattern, errorCollector *ErrorCollector) *PatternAnalysisResult {
	result := ea.performPatternAnalysis(ctx, pattern)
	// The original method already handles errors, but we can add additional error tracking here if needed
	return result
}

func (ea *EnhancedAssessor) findSimilarPatternsWithErrorHandling(ctx context.Context, pattern *vector.ActionPattern, errorCollector *ErrorCollector) []*vector.SimilarPattern {
	ea.metrics.RecordResourceUsage("vector_db")
	similarPatterns, err := ea.vectorDB.FindSimilarPatterns(ctx, pattern, 5, ea.config.MinSimilarityThreshold)
	if err != nil {
		errorCollector.AddError("pattern_matching", "find_similar_patterns", err, ErrorSeverityLow)
		ea.log.WithError(err).Warn("Failed to find similar patterns")
		return []*vector.SimilarPattern{}
	}
	if similarPatterns == nil {
		return []*vector.SimilarPattern{}
	}
	return similarPatterns
}

func (ea *EnhancedAssessor) performPredictiveAnalysisWithErrorHandling(ctx context.Context, trace *actionhistory.ResourceActionTrace, errorCollector *ErrorCollector) *PredictiveInsightResult {
	ea.metrics.RecordResourceUsage("analytics_engine")
	prediction, err := ea.analyticsEngine.PredictEffectiveness(ctx, trace, ea.config.PredictionModel)
	if err != nil {
		errorCollector.AddError("predictive_analysis", "predict_effectiveness", err, ErrorSeverityMedium)
		ea.log.WithError(err).Warn("Failed to generate effectiveness prediction")
		return nil
	}

	if prediction == nil {
		return nil
	}

	return &PredictiveInsightResult{
		PredictedEffectiveness: prediction,
		ModelConfidence:        prediction.Confidence,
		PredictionFactors:      prediction.FactorContributions,
		AnomalyScore:           ea.calculateAnomalyScore(prediction),
		TrendAnalysis:          ea.analyzeTrend(prediction),
	}
}

func (ea *EnhancedAssessor) performCostAnalysisWithErrorHandling(ctx context.Context, trace *actionhistory.ResourceActionTrace, pattern *vector.ActionPattern, errorCollector *ErrorCollector) *CostAnalysisResult {
	// Cost analysis is mostly computational, so errors are less likely
	// But we can add error tracking for any external dependencies in the future
	return ea.performCostAnalysis(ctx, trace, pattern)
}

func (ea *EnhancedAssessor) logErrorSummary(actionID string, errorCollector *ErrorCollector) {
	errors := errorCollector.GetErrors()
	if len(errors) == 0 {
		return
	}

	summary := errorCollector.GetErrorSummary()

	logFields := logrus.Fields{
		"action_id":    actionID,
		"total_errors": len(errors),
	}

	for severity, count := range summary {
		switch severity {
		case ErrorSeverityLow:
			logFields["low_severity_errors"] = count
		case ErrorSeverityMedium:
			logFields["medium_severity_errors"] = count
		case ErrorSeverityHigh:
			logFields["high_severity_errors"] = count
		case ErrorSeverityCritical:
			logFields["critical_errors"] = count
		}
	}

	// Log individual errors for debugging
	for _, err := range errors {
		ea.log.WithFields(logrus.Fields{
			"action_id": actionID,
			"component": err.Component,
			"operation": err.Operation,
			"severity":  err.Severity,
			"timestamp": err.Timestamp,
		}).WithError(err.Error).Debug("Assessment error details")
	}

	// Log summary based on highest severity
	if summary[ErrorSeverityCritical] > 0 {
		ea.log.WithFields(logFields).Error("Assessment completed with critical errors")
	} else if summary[ErrorSeverityHigh] > 0 {
		ea.log.WithFields(logFields).Warn("Assessment completed with high severity errors")
	} else if summary[ErrorSeverityMedium] > 0 {
		ea.log.WithFields(logFields).Warn("Assessment completed with medium severity errors")
	} else {
		ea.log.WithFields(logFields).Info("Assessment completed with minor errors")
	}
}

// GetAssessmentMetrics returns current assessment metrics
func (ea *EnhancedAssessor) GetAssessmentMetrics() AssessmentMetrics {
	return ea.metrics.GetMetrics()
}

// LogMetricsSummary logs a summary of current metrics
func (ea *EnhancedAssessor) LogMetricsSummary() {
	metrics := ea.metrics.GetMetrics()

	successRate := float64(0)
	if metrics.TotalAssessments > 0 {
		successRate = float64(metrics.SuccessfulAssessments) / float64(metrics.TotalAssessments) * 100
	}

	ea.log.WithFields(logrus.Fields{
		"total_assessments":         metrics.TotalAssessments,
		"successful_assessments":    metrics.SuccessfulAssessments,
		"failed_assessments":        metrics.FailedAssessments,
		"success_rate_percent":      successRate,
		"average_duration_ms":       metrics.AverageAssessmentDuration.Milliseconds(),
		"average_confidence":        metrics.AverageConfidenceLevel,
		"average_enhanced_score":    metrics.AverageEnhancedScore,
		"pattern_learning_usage":    metrics.PatternLearningUsage,
		"predictive_analysis_usage": metrics.PredictiveAnalysisUsage,
		"cost_analysis_usage":       metrics.CostAnalysisUsage,
		"vector_db_queries":         metrics.VectorDBQueryCount,
		"analytics_engine_calls":    metrics.AnalyticsEngineCallCount,
		"worker_pool_utilization":   metrics.WorkerPoolUtilization,
		"uptime_hours":              time.Since(metrics.StartTime).Hours(),
	}).Info("Enhanced Assessor Metrics Summary")

	// Log error breakdown if there are errors
	if len(metrics.ErrorsByComponent) > 0 {
		ea.log.WithFields(logrus.Fields{
			"errors_by_component": metrics.ErrorsByComponent,
			"errors_by_severity":  metrics.ErrorsBySeverity,
		}).Info("Enhanced Assessor Error Breakdown")
	}
}

// validateTraceData validates that the action trace contains required fields
func (ea *EnhancedAssessor) validateTraceData(trace *actionhistory.ResourceActionTrace) error {
	if trace == nil {
		return fmt.Errorf("trace cannot be nil")
	}

	if trace.ActionID == "" {
		return fmt.Errorf("trace.ActionID cannot be empty")
	}

	if trace.ActionType == "" {
		return fmt.Errorf("trace.ActionType cannot be empty")
	}

	if trace.AlertName == "" {
		return fmt.Errorf("trace.AlertName cannot be empty")
	}

	if trace.ExecutionStartTime == nil {
		return fmt.Errorf("trace.ExecutionStartTime cannot be nil")
	}

	// ExecutionEndTime is required for effectiveness assessment
	if trace.ExecutionEndTime == nil {
		return fmt.Errorf("trace.ExecutionEndTime cannot be nil - action must be completed before assessment")
	}

	// Validate time ordering
	if trace.ExecutionEndTime.Before(*trace.ExecutionStartTime) {
		return fmt.Errorf("trace.ExecutionEndTime cannot be before ExecutionStartTime")
	}

	// Validate that the action was executed recently enough to assess (not too old)
	maxAssessmentAge := 7 * 24 * time.Hour // 7 days
	if time.Since(*trace.ExecutionEndTime) > maxAssessmentAge {
		return fmt.Errorf("action is too old to assess effectively - executed more than 7 days ago")
	}

	return nil
}

// validateConfiguration validates the enhanced assessor configuration
func (ea *EnhancedAssessor) validateConfiguration(config EnhancedAssessorConfig) error {
	if config.MinSimilarityThreshold < 0.0 || config.MinSimilarityThreshold > 1.0 {
		return fmt.Errorf("MinSimilarityThreshold must be between 0.0 and 1.0, got %f", config.MinSimilarityThreshold)
	}

	if config.MaxStoredPatterns <= 0 {
		return fmt.Errorf("MaxStoredPatterns must be positive, got %d", config.MaxStoredPatterns)
	}

	if config.PatternRetentionDays <= 0 {
		return fmt.Errorf("PatternRetentionDays must be positive, got %d", config.PatternRetentionDays)
	}

	if config.BatchSize <= 0 {
		return fmt.Errorf("BatchSize must be positive, got %d", config.BatchSize)
	}

	if config.WorkerPoolSize <= 0 {
		return fmt.Errorf("WorkerPoolSize must be positive, got %d", config.WorkerPoolSize)
	}

	if config.AnalyticsUpdateInterval <= 0 {
		return fmt.Errorf("AnalyticsUpdateInterval must be positive, got %v", config.AnalyticsUpdateInterval)
	}

	if config.ModelRetrainingInterval <= 0 {
		return fmt.Errorf("ModelRetrainingInterval must be positive, got %v", config.ModelRetrainingInterval)
	}

	// Validate prediction model
	validModels := map[string]bool{
		"similarity":  true,
		"statistical": true,
		"hybrid":      true,
	}
	if !validModels[config.PredictionModel] {
		return fmt.Errorf("invalid PredictionModel '%s', must be one of: similarity, statistical, hybrid", config.PredictionModel)
	}

	return nil
}
