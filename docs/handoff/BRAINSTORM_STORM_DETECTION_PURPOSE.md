# Brainstorm: What IS Storm Detection For?

**Date**: December 13, 2025
**Status**: ðŸ¤” **OPEN QUESTION** - Business value unclear
**Priority**: FOUNDATIONAL - May reveal architectural gaps or unnecessary complexity

---

## ðŸŽ¯ The Core Question

After determining that storm context has **minimal value for LLM RCA** (3-6%), we must ask:

**"What is the actual business purpose of storm detection in Gateway?"**

---

## ðŸ“Š Current State Analysis

### What Storm Detection Currently Does

```go
// pkg/gateway/server.go
isThresholdReached := occurrenceCount >= s.stormThreshold  // Default: 5

if isThresholdReached {
    s.metricsInstance.AlertStormsDetectedTotal.WithLabelValues("rate", signal.AlertName).Inc()
}

// Async status update
go func() {
    if err := s.statusUpdater.UpdateStormAggregationStatus(ctx, rrCopy, isThresholdReached); err != nil {
        s.logger.Info("Failed to update storm aggregation status (async, DD-GATEWAY-013)",
            "error", err,
            "fingerprint", signal.Fingerprint)
    }
}()
```

**Actions Taken**:
1. âœ… Increments Prometheus metric `AlertStormsDetectedTotal`
2. âœ… Updates `RemediationRequest.status.stormAggregation.isStorm = true`
3. âŒ **NOTHING ELSE** - No routing changes, no backpressure, no circuit breaking

---

### Business Requirements for Storm Detection

From `docs/services/stateless/gateway-service/BUSINESS_REQUIREMENTS.md`:

#### **BR-GATEWAY-008: Storm Detection**
> Gateway must detect alert storms (>10 alerts/minute) and aggregate them

**Implementation**: `pkg/gateway/processing/storm_detector.go`
**Status**: âœ… Implemented (but aggregation unclear)

#### **BR-GATEWAY-009: Concurrent Storm Detection**
> Gateway must handle concurrent alert bursts without race conditions

**Implementation**: Concurrent-safe storm detection
**Status**: âœ… Implemented

#### **BR-GATEWAY-010: Storm State Recovery**
> Gateway must recover storm state from Redis after restart

**Implementation**: Storm state in K8s CRD status (not Redis)
**Status**: âœ… Implemented (via DD-GATEWAY-011)

---

### Key Findings

1. **Business requirements say "aggregate storms"** but current implementation only TRACKS storms (no aggregation behavior)
2. **No downstream consumer** of `status.stormAggregation.isStorm` (RO doesn't use it, AIAnalysis doesn't see it)
3. **Only observable output** is a Prometheus metric

---

## ðŸ¤” Potential Business Values (Brainstorm)

### Option 1: Circuit Breaker for Gateway Overload Protection

**Hypothesis**: Storm detection prevents Gateway from being overwhelmed by alert floods.

#### **CRITICAL ARCHITECTURAL ISSUE**:

**Current storm detection = per-fingerprint** (too granular for circuit breaking):
```
âŒ WRONG: Per-fingerprint storm detection
Storm detected for SHA256("PodNotReady:prod:Pod:app-pod-1")
â†’ Reject only alerts for this ONE specific pod?
â†’ Doesn't protect Gateway from overload (other pods still creating load)
```

**Proper circuit breaker = service-level** (protects Gateway itself):
```
âœ… CORRECT: Service-level circuit breaker
Total QPS > threshold (e.g., 1000 req/s)
â†’ Reject ALL new requests with HTTP 503
â†’ Protects Gateway pod from OOM/CPU exhaustion
â†’ Load balancer routes traffic to other pods
```

#### **How a REAL circuit breaker would work**:
```go
// Service-level protection (NOT per-fingerprint)
type CircuitBreaker struct {
    qpsThreshold int       // e.g., 1000 req/s
    errorRate    float64   // e.g., 50% errors triggers open
    state        State     // Closed, Open, HalfOpen
}

func (cb *CircuitBreaker) Allow() bool {
    if cb.state == Open {
        return false  // Reject ALL requests
    }

    currentQPS := cb.metrics.GetCurrentQPS()
    if currentQPS > cb.qpsThreshold {
        cb.state = Open
        return false
    }

    return true
}
```

#### **Current state**:
```
âŒ NO CIRCUIT BREAKER EXISTS

Gateway has:
- âœ… Rate limiting delegated to proxy (ADR-048)
- âœ… Retry logic for K8s API errors (exponential backoff)
- âŒ NO service-level circuit breaker
- âŒ NO per-namespace circuit breaker
- âŒ NO overload protection

Storm detection does NOT provide circuit breaking:
- Storm = per-fingerprint tracking (single resource flapping)
- Circuit breaker = service-level protection (Gateway overload)
```

#### **Key distinctions**:

| Mechanism | Scope | Purpose | Status |
|-----------|-------|---------|--------|
| **Rate limiting** | Per-source IP | Prevent abuse | âœ… Delegated to proxy (ADR-048) |
| **Storm detection** | Per-fingerprint | Track resource flapping | âœ… Implemented (but no action taken) |
| **Circuit breaker** | Service-level | Protect Gateway from overload | âŒ NOT IMPLEMENTED |

#### **Investigation needed**:
- **Q1**: Is Gateway at risk of overload? (QPS capacity analysis)
- **Q2**: Should we add service-level circuit breaker?
- **Q3**: If yes, storm detection is NOT the right mechanism (too granular)

---

### Option 2: Observability Signal for SRE Teams

**Hypothesis**: Storm detection is purely for SRE observability, not automation.

#### **How it works (current)**:
```
Storm detected â†’ Prometheus metric incremented
                â†’ Grafana dashboard shows spike
                â†’ SRE team investigates manually
```

#### **Business value**:
- âœ… SREs can see when a resource is flapping
- âœ… Identifies problematic deployments/nodes
- âœ… Tracks storm frequency over time

#### **Current state**:
```
âœ… IMPLEMENTED
Metric: alert_storms_detected_total{storm_type="rate",alert_name="..."}
```

#### **Problems**:
- âŒ Unclear if SREs actually use this metric
- âŒ Duplicate signal: `occurrence_count` already shows flapping
- âŒ If observability is the only value, why the complexity?

---

### Option 3: Aggregation for Reduced Downstream Load

**Hypothesis**: Storm detection aggregates multiple alerts into a single CRD to reduce downstream processing load.

#### **How it would work**:
```
WITHOUT storm aggregation:
  Alert 1-20 â†’ 20 separate CRDs â†’ 20 SignalProcessing â†’ 20 AIAnalysis â†’ 20 WorkflowExecutions

WITH storm aggregation:
  Alert 1-5  â†’ 5 separate CRDs â†’ 5 SignalProcessing â†’ 5 AIAnalysis â†’ 5 WorkflowExecutions
  Alert 6-20 â†’ UPDATE existing CRD (no new CRDs) â†’ Reduced load
```

#### **Business value**:
- âœ… Reduces K8s API server load (fewer CRD creates)
- âœ… Reduces downstream service load (SP, AA, WE)
- âœ… Faster processing (no redundant enrichment/analysis)

#### **Current state**:
```
âŒ NOT FULLY IMPLEMENTED

Current behavior:
  Alert 1 â†’ Create CRD (occurrenceCount=1)
  Alert 2 â†’ Update CRD (occurrenceCount=2) âœ… Deduplication works!
  Alert 5 â†’ Update CRD (occurrenceCount=5, isStorm=true) âœ… Storm flag set!
  Alert 6-20 â†’ Update CRD (occurrenceCount=6...20) âœ… Still deduplicated!

Result: Aggregation ALREADY HAPPENS via deduplication!
        Storm flag adds NO additional aggregation behavior!
```

#### **Key insight**:
**Deduplication already aggregates storms!**
- Same fingerprint â†’ Same CRD â†’ Occurrence count increases
- Storm flag is just a threshold indicator, not an aggregation mechanism

---

### Option 4: Workflow Routing Signal (Already Disproven)

**Hypothesis**: RO uses storm flag to skip AIAnalysis for storms.

**Status**: âŒ **IMPOSSIBLE** (see Decision Document)
- RO makes routing decision before storm threshold is reached
- RO cannot make remediation decisions (no workflow selection capability)

---

### Option 5: Operator Alert for Manual Intervention

**Hypothesis**: Storm detection triggers operator notifications for manual triage.

#### **How it would work**:
```
IF isStorm == true:
   â†’ Send Slack/PagerDuty notification
   â†’ Alert: "Storm detected for PodNotReady in prod-payments (20 occurrences)"
   â†’ Operator manually investigates root cause
   â†’ Operator decides to:
      a) Let remediation proceed
      b) Manually fix infrastructure
      c) Silence alerts
```

#### **Business value**:
- âœ… Human escalation for severe issues
- âœ… Prevents automated remediation for dangerous scenarios
- âœ… Enables manual root cause analysis

#### **Current state**:
```
âŒ NOT IMPLEMENTED

No notification logic exists for storm detection.
Only Prometheus metric exists.
```

#### **Problems**:
- âŒ This overlaps with existing alerting (Prometheus Alertmanager)
- âŒ Why not just alert on `occurrence_count >= 5` in Prometheus?
- âŒ Gateway shouldn't be in the notification business

---

## ðŸ” Investigation: What Do Other Systems Do?

### Prometheus Alertmanager: Alert Grouping

```yaml
# Alertmanager groups similar alerts to reduce notification noise
route:
  group_by: ['alertname', 'namespace', 'pod']
  group_wait: 30s
  group_interval: 5m

# Result: Multiple PodNotReady alerts â†’ Single grouped notification
```

**Insight**: Alertmanager already handles storm aggregation for notifications.

---

### Kubernetes Event Rate Limiting

Kubernetes API server has built-in event rate limiting:
- Per-source rate limits
- Event deduplication (similar events aggregated)
- Prevents event storms from overloading API server

**Insight**: K8s already has infrastructure-level storm protection.

---

### AWS CloudWatch: Alarm Throttling

CloudWatch suppresses repeat alarm notifications:
- Alarm enters ALARM state â†’ Send notification
- Alarm stays in ALARM state â†’ Suppress repeat notifications
- Alarm clears â†’ Send OK notification

**Insight**: Storm suppression is for NOTIFICATIONS, not processing.

---

## ðŸŽ¯ Hypothesis: Storm Detection is Redundant

### Evidence

1. **Deduplication already aggregates**:
   - Same fingerprint â†’ Same CRD â†’ Occurrence count increases
   - No additional CRD creation for storm alerts
   - Storm flag adds nothing beyond `occurrenceCount >= threshold`

2. **No downstream consumer**:
   - RO doesn't use storm flag (routing happens before storm)
   - AIAnalysis doesn't see storm flag (created before storm threshold)
   - WorkflowExecution doesn't know about storms

3. **Observability duplication**:
   - Storm metric = `occurrence_count >= 5`
   - Could be replaced with Prometheus query: `count(occurrence_count >= 5)`

4. **Rate limiting removed**:
   - ADR-048: Rate limiting delegated to proxy
   - Storm detection might have been intended for this, but it's now redundant

---

## ðŸ’¡ Recommendation Options

### Option A: Remove Storm Detection Entirely âœ… RECOMMENDED

**Status**: âœ… **APPROVED** - See [DD-GATEWAY-015: Storm Detection Logic Removal](../architecture/decisions/DD-GATEWAY-015-storm-detection-removal.md)

**Rationale**:
- Deduplication already provides aggregation
- No downstream consumer uses storm flag (DD-AIANALYSIS-004)
- Observability can be achieved via Prometheus query on `occurrence_count`
- Simpler codebase, less maintenance

**Impact**:
```diff
- status.stormAggregation (entire field)
- pkg/gateway/processing/status_updater.go UpdateStormAggregationStatus()
- test/integration/gateway/webhook_integration_test.go storm test
- docs references to storm detection
```

**Risk**: Low - no known consumer of storm flag

---

### Option B: Repurpose Storm Detection as Circuit Breaker

**Status**: âŒ **ARCHITECTURALLY INCORRECT**

**Problem**: Storm detection is per-fingerprint, circuit breakers should be service-level.

**Decision**: See [DD-GATEWAY-014: Service-Level Circuit Breaker Deferral](../architecture/decisions/DD-GATEWAY-014-circuit-breaker-deferral.md) for authoritative decision on Gateway circuit breaker.

**Why this doesn't work**:
```
Storm detection = per-fingerprint
  â†’ Tracks: SHA256("PodNotReady:prod:Pod:app-pod-1")
  â†’ Granularity: Single specific resource
  â†’ Protection: None (other fingerprints still create load)

Circuit breaker = service-level
  â†’ Tracks: Total Gateway QPS, memory, error rate
  â†’ Granularity: Entire Gateway service
  â†’ Protection: Prevents Gateway pod from OOM/crash
```

**If we wanted circuit breaking**, we'd need NEW functionality:
```go
// NEW: Service-level circuit breaker (NOT storm detection)
type GatewayCircuitBreaker struct {
    state State
    qpsThreshold int
    memoryThreshold float64
}

func (gcb *GatewayCircuitBreaker) CheckOverload() bool {
    currentQPS := metrics.GetQPS()
    memoryUsage := metrics.GetMemoryPercent()

    if currentQPS > gcb.qpsThreshold || memoryUsage > gcb.memoryThreshold {
        gcb.state = Open
        return true  // Gateway is overloaded
    }
    return false
}
```

**Recommendation**: **DO NOT repurpose storm detection for circuit breaking**
- Storm detection operates at wrong granularity (per-fingerprint vs service-level)
- If circuit breaking is needed, implement it separately
- Circuit breaker monitors Gateway health, not individual fingerprints

**Risk**: High - architectural mismatch between storm detection and circuit breaking

---

### Option C: Keep as Observability Metric Only

**Rationale**:
- Storm metric might be useful for SRE teams
- Low cost to maintain (already implemented)
- No harm in keeping if observability value exists

**Implementation**: Keep current code, document as observability-only

**Risk**: Low - but adds complexity for minimal value

---

## ðŸ”Ž Questions to Answer

Before deciding on Option A/B/C:

1. **Capacity Analysis**:
   - Q: What is Gateway's actual QPS capacity?
   - Q: Has Gateway ever been overloaded in production?
   - Q: Is per-namespace circuit breaking needed?

2. **Observability Analysis**:
   - Q: Do SRE teams use `alert_storms_detected_total` metric?
   - Q: Could this be replaced with Prometheus query on `occurrence_count`?
   - Q: Is there value in a separate storm metric?

3. **Historical Context**:
   - Q: Why was storm detection originally implemented?
   - Q: Was it intended for rate limiting (now removed via ADR-048)?
   - Q: Was it intended for aggregation (already handled by deduplication)?

4. **Downstream Dependencies**:
   - Q: Does ANY service read `status.stormAggregation`?
   - Q: Are there any future plans to use storm flag?
   - Q: Is this being kept for a future feature?

---

## ðŸ“‹ Action Items

1. **Investigate Gateway capacity**: Determine if circuit breaking is needed
2. **Check metric usage**: Query Grafana/Prometheus to see if storm metric is used
3. **Review ADR-048**: Confirm rate limiting delegation covers storm scenarios
4. **Consult SRE team**: Ask if storm detection has observability value
5. **Make decision**: Keep, repurpose, or remove storm detection

---

## ðŸ”— Related Documents

- **[DECISION_STORM_CONTEXT_NOT_EXPOSED.md](../../crd-controllers/02-aianalysis/DECISION_STORM_CONTEXT_NOT_EXPOSED.md)** - Storm context not exposed to LLM
- **[ADR-048](../../../architecture/decisions/ADR-048-rate-limiting-proxy-delegation.md)** - Rate limiting delegated to proxy
- **[DD-GATEWAY-011](../../../architecture/decisions/DD-GATEWAY-011-shared-status-deduplication.md)** - Storm state in CRD status
- **[BR-GATEWAY-008](./BUSINESS_REQUIREMENTS.md)** - Storm detection business requirement

---

**Document Status**: ðŸ¤” Open Question - Needs Investigation
**Priority**: Medium - Not blocking, but architectural clarity needed
**Next Step**: Answer investigation questions, make decision on Option A/B/C

