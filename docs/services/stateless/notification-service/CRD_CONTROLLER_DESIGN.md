# Notification Controller - Design Document

**Date**: 2025-10-12
**Version**: 1.0
**Status**: âœ… **APPROVED**
**Architecture**: CRD-Based Declarative Controller

---

## ðŸŽ¯ **Purpose**

Design a Kubernetes controller that reconciles NotificationRequest CRDs to deliver multi-channel notifications with:
- âœ… Zero data loss (etcd persistence)
- âœ… Complete audit trail (status tracking)
- âœ… Automatic retry (controller reconciliation)
- âœ… At-least-once delivery guarantee
- âœ… Graceful degradation (per-channel failure isolation)

---

## ðŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Kubernetes Cluster                           â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚             NotificationRequest CRD (etcd)                â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  apiVersion: notification.kubernaut.ai/v1alpha1           â”‚  â”‚
â”‚  â”‚  kind: NotificationRequest                                â”‚  â”‚
â”‚  â”‚  metadata:                                                 â”‚  â”‚
â”‚  â”‚    name: escalation-remediation-001                       â”‚  â”‚
â”‚  â”‚  spec:                                                     â”‚  â”‚
â”‚  â”‚    type: escalation                                       â”‚  â”‚
â”‚  â”‚    priority: critical                                     â”‚  â”‚
â”‚  â”‚    channels: [email, slack]                               â”‚  â”‚
â”‚  â”‚    recipients: [...]                                      â”‚  â”‚
â”‚  â”‚  status:                                                   â”‚  â”‚
â”‚  â”‚    phase: Sending                                         â”‚  â”‚
â”‚  â”‚    deliveryAttempts: [...]                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                   â”‚                                              â”‚
â”‚                   â”‚ Watch/Reconcile                              â”‚
â”‚                   â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚          Notification Controller (Pod)                    â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Reconciliation Loop (controller-runtime)         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  1. Get NotificationRequest from API server       â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  2. Check current phase (Pending/Sending/...)     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  3. Deliver to each channel independently         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  4. Update status (attempts, conditions, phase)   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  5. Requeue on failure with exponential backoff   â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Delivery Service (Internal)                      â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Email Sender (SMTP)                            â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Slack Client (Webhook)                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Teams Client (Webhook)                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ SMS Provider (Twilio/AWS SNS)                  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Webhook Client (HTTP)                          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Console Logger (stdout)                        â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Formatting Service (Internal)                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Email Formatter (HTML templates)               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Slack Formatter (Block Kit)                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Teams Formatter (Adaptive Cards)               â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ SMS Formatter (Plain text, 160 chars)          â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Webhook Formatter (JSON)                       â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Sanitization Service (Internal)                  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚                                                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Redact secrets, API keys, passwords            â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Sanitize PII per policy                        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Applied BEFORE CRD creation                    â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  External Integrations:                                          â”‚
â”‚  â€¢ SMTP Server (Email)                                           â”‚
â”‚  â€¢ Slack Webhooks                                                â”‚
â”‚  â€¢ Microsoft Teams Webhooks                                      â”‚
â”‚  â€¢ SMS Provider (Twilio/AWS SNS)                                 â”‚
â”‚  â€¢ Custom Webhooks                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”„ **Controller Reconciliation Logic**

### **Reconcile Flow**

```go
func (r *NotificationRequestReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    log := log.FromContext(ctx)

    // 1. GET NOTIFICATION REQUEST FROM API SERVER
    notification := &notificationv1alpha1.NotificationRequest{}
    if err := r.Get(ctx, req.NamespacedName, notification); err != nil {
        if apierrors.IsNotFound(err) {
            // NotificationRequest deleted, stop reconciliation
            return ctrl.Result{}, nil
        }
        log.Error(err, "Failed to get NotificationRequest")
        return ctrl.Result{}, err
    }

    // 2. CHECK IF ALREADY COMPLETED
    if notification.Status.Phase == notificationv1alpha1.NotificationPhaseSent {
        // Delivery succeeded, no further action needed
        log.Info("Notification already sent", "name", notification.Name)
        return ctrl.Result{}, nil
    }

    if notification.Status.Phase == notificationv1alpha1.NotificationPhaseFailed {
        // Max retries exceeded, no further action needed
        log.Info("Notification failed after max retries", "name", notification.Name)
        return ctrl.Result{}, nil
    }

    // 3. UPDATE PHASE TO SENDING (IF PENDING)
    if notification.Status.Phase == "" || notification.Status.Phase == notificationv1alpha1.NotificationPhasePending {
        notification.Status.Phase = notificationv1alpha1.NotificationPhaseSending
        now := metav1.Now()
        notification.Status.QueuedAt = &now
        notification.Status.ProcessingStartedAt = &now

        if err := r.Status().Update(ctx, notification); err != nil {
            log.Error(err, "Failed to update status to Sending")
            return ctrl.Result{}, err
        }
    }

    // 4. DELIVER TO EACH CHANNEL INDEPENDENTLY
    deliveryResults := r.deliverToAllChannels(ctx, notification)

    // 5. UPDATE STATUS BASED ON RESULTS
    return r.updateStatusAndRequeue(ctx, notification, deliveryResults)
}

// deliverToAllChannels delivers notification to all specified channels
func (r *NotificationRequestReconciler) deliverToAllChannels(ctx context.Context, notification *notificationv1alpha1.NotificationRequest) map[string]error {
    results := make(map[string]error)

    // Deliver to each channel in parallel
    for _, channel := range notification.Spec.Channels {
        channelName := string(channel)

        // Check if channel already succeeded (idempotent)
        if r.channelAlreadySucceeded(notification, channelName) {
            continue
        }

        // Deliver to channel
        err := r.deliveryService.Deliver(ctx, notification, channel)
        results[channelName] = err

        // Record delivery attempt
        attempt := notificationv1alpha1.DeliveryAttempt{
            Channel:   channelName,
            Attempt:   r.getChannelAttemptCount(notification, channelName) + 1,
            Timestamp: metav1.Now(),
            Status:    "success",
        }

        if err != nil {
            attempt.Status = "failed"
            attempt.Error = err.Error()
        }

        notification.Status.DeliveryAttempts = append(notification.Status.DeliveryAttempts, attempt)
        notification.Status.TotalAttempts++
    }

    return results
}

// updateStatusAndRequeue updates notification status and decides whether to requeue
func (r *NotificationRequestReconciler) updateStatusAndRequeue(ctx context.Context, notification *notificationv1alpha1.NotificationRequest, deliveryResults map[string]error) (ctrl.Result, error) {
    log := log.FromContext(ctx)

    // Count successes and failures
    successCount := 0
    failureCount := 0
    for _, err := range deliveryResults {
        if err == nil {
            successCount++
        } else {
            failureCount++
        }
    }

    notification.Status.SuccessfulDeliveries += successCount
    notification.Status.FailedDeliveries += failureCount

    // Determine final phase
    if successCount == len(notification.Spec.Channels) {
        // All channels succeeded
        notification.Status.Phase = notificationv1alpha1.NotificationPhaseSent
        now := metav1.Now()
        notification.Status.CompletionTime = &now
        notification.Status.Message = "Successfully delivered to all channels"

        // Update status and stop reconciliation
        if err := r.Status().Update(ctx, notification); err != nil {
            log.Error(err, "Failed to update status to Sent")
            return ctrl.Result{}, err
        }

        log.Info("Notification sent successfully", "name", notification.Name)
        return ctrl.Result{}, nil // No requeue
    }

    if failureCount > 0 {
        // Some channels failed
        retryPolicy := r.getRetryPolicy(notification)
        currentAttempts := notification.Status.TotalAttempts / len(notification.Spec.Channels)

        if currentAttempts >= retryPolicy.MaxAttempts {
            // Max retries exceeded
            notification.Status.Phase = notificationv1alpha1.NotificationPhaseFailed
            now := metav1.Now()
            notification.Status.CompletionTime = &now
            notification.Status.Reason = "MaxRetriesExceeded"
            notification.Status.Message = fmt.Sprintf("Failed after %d attempts", currentAttempts)

            // Update status and stop reconciliation
            if err := r.Status().Update(ctx, notification); err != nil {
                log.Error(err, "Failed to update status to Failed")
                return ctrl.Result{}, err
            }

            log.Info("Notification failed after max retries", "name", notification.Name, "attempts", currentAttempts)
            return ctrl.Result{}, nil // No requeue
        }

        // Calculate backoff for retry
        backoffDuration := r.calculateBackoff(retryPolicy, currentAttempts)

        notification.Status.Phase = notificationv1alpha1.NotificationPhaseSending
        notification.Status.Message = fmt.Sprintf("Retrying failed channels in %s", backoffDuration)

        // Update status
        if err := r.Status().Update(ctx, notification); err != nil {
            log.Error(err, "Failed to update status")
            return ctrl.Result{}, err
        }

        log.Info("Requeuing notification for retry",
            "name", notification.Name,
            "backoff", backoffDuration,
            "attempt", currentAttempts+1)

        // Requeue with backoff
        return ctrl.Result{RequeueAfter: backoffDuration}, nil
    }

    // Partial success (some channels succeeded, others haven't been attempted yet)
    notification.Status.Phase = notificationv1alpha1.NotificationPhasePartiallySent
    notification.Status.Message = "Partial delivery, retrying failed channels"

    if err := r.Status().Update(ctx, notification); err != nil {
        log.Error(err, "Failed to update status to PartiallySent")
        return ctrl.Result{}, err
    }

    // Requeue immediately
    return ctrl.Result{Requeue: true}, nil
}

// calculateBackoff calculates exponential backoff duration
func (r *NotificationRequestReconciler) calculateBackoff(retryPolicy *notificationv1alpha1.RetryPolicy, attemptCount int) time.Duration {
    initialBackoff := time.Duration(retryPolicy.InitialBackoffSeconds) * time.Second
    maxBackoff := time.Duration(retryPolicy.MaxBackoffSeconds) * time.Second

    // Exponential backoff: initialBackoff * multiplier^attemptCount
    backoff := initialBackoff * time.Duration(math.Pow(float64(retryPolicy.BackoffMultiplier), float64(attemptCount)))

    if backoff > maxBackoff {
        backoff = maxBackoff
    }

    return backoff
}

// getRetryPolicy returns retry policy for notification (from spec or defaults)
func (r *NotificationRequestReconciler) getRetryPolicy(notification *notificationv1alpha1.NotificationRequest) *notificationv1alpha1.RetryPolicy {
    if notification.Spec.RetryPolicy != nil {
        return notification.Spec.RetryPolicy
    }

    // Default retry policy
    return &notificationv1alpha1.RetryPolicy{
        MaxAttempts:           5,
        InitialBackoffSeconds: 30,
        BackoffMultiplier:     2,
        MaxBackoffSeconds:     480,
    }
}

// channelAlreadySucceeded checks if channel was already successfully delivered
func (r *NotificationRequestReconciler) channelAlreadySucceeded(notification *notificationv1alpha1.NotificationRequest, channelName string) bool {
    for _, attempt := range notification.Status.DeliveryAttempts {
        if attempt.Channel == channelName && attempt.Status == "success" {
            return true
        }
    }
    return false
}

// getChannelAttemptCount counts previous attempts for a specific channel
func (r *NotificationRequestReconciler) getChannelAttemptCount(notification *notificationv1alpha1.NotificationRequest, channelName string) int {
    count := 0
    for _, attempt := range notification.Status.DeliveryAttempts {
        if attempt.Channel == channelName {
            count++
        }
    }
    return count
}
```

---

## ðŸ“Š **State Transitions**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Notification Lifecycle                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Pending  â”‚ (Initial state, CRD just created)
                          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚ Controller picks up notification
                                â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Sending  â”‚ (Actively delivering to channels)
                          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚             â”‚             â”‚
     All channels â”‚             â”‚ Some failed â”‚             â”‚ All failed, max retries
      succeeded   â”‚             â”‚             â”‚             â”‚ exceeded
                  â–¼             â–¼             â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Sent   â”‚  â”‚ PartiallySentâ”‚  â”‚ Failed â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ Retry failed channels
                                 â”‚ (exponential backoff)
                                 â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Sending  â”‚ (Retry attempt)
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                          (Loop until Sent or Failed)
```

### **Phase Descriptions**

| Phase | Description | Next States | Reconcile Action |
|-------|-------------|-------------|------------------|
| **Pending** | CRD created, not yet processed | Sending | Start delivery to all channels |
| **Sending** | Actively delivering to channels | Sent, PartiallySent, Failed | Deliver to channels, update status |
| **Sent** | All channels delivered successfully | N/A (terminal) | None (reconciliation stops) |
| **PartiallySent** | Some channels succeeded, some failed | Sending (retry) | Retry failed channels with backoff |
| **Failed** | Max retries exceeded, delivery failed | N/A (terminal) | None (reconciliation stops) |

---

## ðŸ”’ **Security**

### **Sensitive Data Protection** (BR-NOT-034)

**Critical**: Sanitization MUST occur BEFORE CRD creation (etcd is persistent and backed up).

```go
// Example: Creating NotificationRequest with sanitization
func CreateNotificationRequest(ctx context.Context, escalation *Escalation) error {
    // 1. Sanitize content BEFORE creating CRD
    sanitizer := sanitization.NewSanitizer()
    sanitizedSubject := sanitizer.Sanitize(escalation.Subject)
    sanitizedBody := sanitizer.Sanitize(escalation.Body)

    // 2. Create NotificationRequest with sanitized content only
    notification := &notificationv1alpha1.NotificationRequest{
        ObjectMeta: metav1.ObjectMeta{
            Name:      fmt.Sprintf("escalation-%s", escalation.ID),
            Namespace: "kubernaut-system",
        },
        Spec: notificationv1alpha1.NotificationRequestSpec{
            Type:     notificationv1alpha1.NotificationTypeEscalation,
            Priority: notificationv1alpha1.NotificationPriorityCritical,
            Subject:  sanitizedSubject,  // SANITIZED
            Body:     sanitizedBody,     // SANITIZED
            // ... rest of spec
        },
    }

    // 3. Create CRD (sanitized content will be persisted in etcd)
    return r.Create(ctx, notification)
}
```

### **Secret Management**

**Channel Credentials** (SMTP password, Slack tokens, etc.) stored in Kubernetes Secrets:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: notification-channel-credentials
  namespace: kubernaut-system
type: Opaque
stringData:
  smtp-password: "secret123"
  slack-webhook-url: "https://hooks.slack.com/services/..."
  teams-webhook-url: "https://outlook.office.com/webhook/..."
  twilio-api-key: "SKxxxxx"
```

**Mounted as Projected Volume**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: notification-controller
spec:
  template:
    spec:
      containers:
      - name: controller
        volumeMounts:
        - name: channel-credentials
          mountPath: /etc/notification/credentials
          readOnly: true
      volumes:
      - name: channel-credentials
        projected:
          sources:
          - secret:
              name: notification-channel-credentials
              items:
              - key: smtp-password
                path: smtp/password
                mode: 0400
          - secret:
              name: notification-channel-credentials
              items:
              - key: slack-webhook-url
                path: slack/webhook-url
                mode: 0400
```

---

## ðŸ“Š **Observability**

### **Metrics** (Prometheus)

```go
// Controller metrics
var (
    notificationRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "notification_requests_total",
            Help: "Total number of notification requests",
        },
        []string{"type", "priority", "phase"},
    )

    notificationDeliveryTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "notification_delivery_total",
            Help: "Total number of notification deliveries",
        },
        []string{"channel", "status"},
    )

    notificationDeliveryDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "notification_delivery_duration_seconds",
            Help:    "Duration of notification delivery",
            Buckets: prometheus.ExponentialBuckets(0.1, 2, 10),
        },
        []string{"channel"},
    )

    notificationRetryCount = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "notification_retry_count",
            Help: "Number of notification retries",
        },
        []string{"channel", "reason"},
    )
)
```

### **Kubernetes Events**

```go
// Emit events for state transitions
r.eventRecorder.Event(notification, corev1.EventTypeNormal, "DeliveryStarted", "Started delivery to all channels")
r.eventRecorder.Event(notification, corev1.EventTypeNormal, "DeliverySucceeded", "Successfully delivered to email")
r.eventRecorder.Event(notification, corev1.EventTypeWarning, "DeliveryFailed", "Failed to deliver to Slack: webhook timeout")
r.eventRecorder.Event(notification, corev1.EventTypeNormal, "RetryScheduled", "Retry scheduled in 60 seconds")
```

### **Status Conditions**

```yaml
status:
  phase: Sending
  conditions:
  - type: EmailSent
    status: "True"
    reason: SMTPSuccess
    message: "Email delivered to oncall@company.com at 2025-10-12T10:30:00Z"
    lastTransitionTime: "2025-10-12T10:30:00Z"
  - type: SlackSent
    status: "False"
    reason: WebhookTimeout
    message: "Slack webhook timed out after 10s, retry scheduled"
    lastTransitionTime: "2025-10-12T10:30:05Z"
  - type: TeamsSent
    status: "True"
    reason: WebhookSuccess
    message: "Teams message posted successfully"
    lastTransitionTime: "2025-10-12T10:30:03Z"
```

---

## ðŸ§ª **Testing Strategy**

### **Unit Tests** (70%+ coverage)

```go
// Test reconciliation logic
func TestReconcile_Pending_ToSending(t *testing.T) {
    // GIVEN: NotificationRequest in Pending state
    notification := &NotificationRequest{
        Status: NotificationRequestStatus{
            Phase: NotificationPhasePending,
        },
    }

    // WHEN: Reconcile is called
    result, err := reconciler.Reconcile(ctx, req)

    // THEN: Phase transitions to Sending
    assert.NoError(t, err)
    assert.Equal(t, NotificationPhaseSending, notification.Status.Phase)
    assert.NotNil(t, notification.Status.ProcessingStartedAt)
}

// Test exponential backoff calculation
func TestCalculateBackoff(t *testing.T) {
    retryPolicy := &RetryPolicy{
        InitialBackoffSeconds: 30,
        BackoffMultiplier:     2,
        MaxBackoffSeconds:     480,
    }

    tests := []struct {
        attempt  int
        expected time.Duration
    }{
        {0, 30 * time.Second},   // 30s
        {1, 60 * time.Second},   // 30s * 2
        {2, 120 * time.Second},  // 60s * 2
        {3, 240 * time.Second},  // 120s * 2
        {4, 480 * time.Second},  // Capped at max
        {5, 480 * time.Second},  // Still capped
    }

    for _, tt := range tests {
        actual := calculateBackoff(retryPolicy, tt.attempt)
        assert.Equal(t, tt.expected, actual)
    }
}

// Test channel isolation (one channel failure doesn't block others)
func TestDeliverToAllChannels_ChannelIsolation(t *testing.T) {
    // GIVEN: Email succeeds, Slack fails
    mockDeliveryService := &MockDeliveryService{
        emailResult: nil,         // Success
        slackResult: errors.New("webhook timeout"),
    }

    notification := &NotificationRequest{
        Spec: NotificationRequestSpec{
            Channels: []Channel{ChannelEmail, ChannelSlack},
        },
    }

    // WHEN: Deliver to all channels
    results := reconciler.deliverToAllChannels(ctx, notification)

    // THEN: Email succeeds, Slack fails, both attempts recorded
    assert.Nil(t, results["email"])
    assert.NotNil(t, results["slack"])
    assert.Equal(t, 2, len(notification.Status.DeliveryAttempts))
    assert.Equal(t, 1, notification.Status.SuccessfulDeliveries)
    assert.Equal(t, 1, notification.Status.FailedDeliveries)
}
```

### **Integration Tests** (>50% coverage)

```go
// Test complete notification lifecycle with real Kind cluster
func TestNotificationLifecycle_Success(t *testing.T) {
    suite := kind.Setup("notification-test")
    defer suite.Cleanup()

    // GIVEN: NotificationRequest CRD created
    notification := &NotificationRequest{
        ObjectMeta: metav1.ObjectMeta{
            Name:      "test-notification",
            Namespace: "kubernaut-system",
        },
        Spec: NotificationRequestSpec{
            Type:     NotificationTypeSimple,
            Priority: NotificationPriorityMedium,
            Channels: []Channel{ChannelEmail, ChannelSlack},
            Recipients: []Recipient{
                {Email: "test@example.com"},
                {Slack: "#test-channel"},
            },
            Subject: "Test Notification",
            Body:    "This is a test notification",
        },
    }

    err := suite.KindClient.Create(ctx, notification)
    require.NoError(t, err)

    // WHEN: Wait for delivery
    Eventually(func() string {
        n := &NotificationRequest{}
        suite.KindClient.Get(ctx, client.ObjectKeyFromObject(notification), n)
        return string(n.Status.Phase)
    }, 60*time.Second, 5*time.Second).Should(Equal("Sent"))

    // THEN: Notification delivered successfully
    n := &NotificationRequest{}
    suite.KindClient.Get(ctx, client.ObjectKeyFromObject(notification), n)

    assert.Equal(t, NotificationPhaseSent, n.Status.Phase)
    assert.Equal(t, 2, n.Status.SuccessfulDeliveries)
    assert.Equal(t, 0, n.Status.FailedDeliveries)
    assert.NotNil(t, n.Status.CompletionTime)
}

// Test automatic retry on failure
func TestNotificationLifecycle_RetryOnFailure(t *testing.T) {
    suite := kind.Setup("notification-test")
    defer suite.Cleanup()

    // GIVEN: Slack webhook initially fails (503), then succeeds
    mockSlack := suite.MockSlackWebhook()
    mockSlack.SetResponses(
        503, // First attempt fails
        503, // Second attempt fails
        200, // Third attempt succeeds
    )

    notification := &NotificationRequest{
        Spec: NotificationRequestSpec{
            Channels: []Channel{ChannelSlack},
            RetryPolicy: &RetryPolicy{
                MaxAttempts:           3,
                InitialBackoffSeconds: 1, // Fast retry for testing
                BackoffMultiplier:     2,
            },
        },
    }

    err := suite.KindClient.Create(ctx, notification)
    require.NoError(t, err)

    // WHEN: Wait for delivery (with retries)
    Eventually(func() string {
        n := &NotificationRequest{}
        suite.KindClient.Get(ctx, client.ObjectKeyFromObject(notification), n)
        return string(n.Status.Phase)
    }, 60*time.Second, 5*time.Second).Should(Equal("Sent"))

    // THEN: Notification succeeded after 3 attempts
    n := &NotificationRequest{}
    suite.KindClient.Get(ctx, client.ObjectKeyFromObject(notification), n)

    assert.Equal(t, NotificationPhaseSent, n.Status.Phase)
    assert.Equal(t, 3, n.Status.TotalAttempts)
    assert.Equal(t, 1, n.Status.SuccessfulDeliveries)
}
```

### **E2E Tests** (<10% coverage)

```go
// Test escalation notification flow (RemediationRequest â†’ NotificationRequest)
func TestE2E_EscalationNotification(t *testing.T) {
    // GIVEN: RemediationRequest created
    remediation := &RemediationRequest{
        ObjectMeta: metav1.ObjectMeta{
            Name:      "remediation-001",
            Namespace: "kubernaut-system",
        },
        Spec: RemediationRequestSpec{
            Timeout: metav1.Duration{Duration: 5 * time.Minute},
        },
    }

    err := k8sClient.Create(ctx, remediation)
    require.NoError(t, err)

    // WHEN: Wait for timeout + escalation
    time.Sleep(6 * time.Minute)

    // THEN: NotificationRequest created for escalation
    notificationList := &NotificationRequestList{}
    err = k8sClient.List(ctx, notificationList, client.MatchingLabels{
        "remediation-request": remediation.Name,
    })
    require.NoError(t, err)
    assert.Equal(t, 1, len(notificationList.Items))

    notification := notificationList.Items[0]
    assert.Equal(t, NotificationTypeEscalation, notification.Spec.Type)
    assert.Equal(t, NotificationPriorityCritical, notification.Spec.Priority)

    // Verify notification delivered
    Eventually(func() string {
        n := &NotificationRequest{}
        k8sClient.Get(ctx, client.ObjectKeyFromObject(&notification), n)
        return string(n.Status.Phase)
    }, 120*time.Second, 10*time.Second).Should(Equal("Sent"))
}
```

---

## ðŸ”— **Integration Points**

### **Remediation Service** (Primary Caller)

```go
// Remediation Service creates NotificationRequest on escalation
func (r *RemediationReconciler) handleEscalation(ctx context.Context, remediation *RemediationRequest) error {
    // Build notification content
    subject := fmt.Sprintf("ðŸš¨ Remediation Escalation: %s", remediation.Name)
    body := buildEscalationBody(remediation)

    // Create NotificationRequest CRD
    notification := &NotificationRequest{
        ObjectMeta: metav1.ObjectMeta{
            Name:      fmt.Sprintf("escalation-%s", remediation.Name),
            Namespace: remediation.Namespace,
            OwnerReferences: []metav1.OwnerReference{
                *metav1.NewControllerRef(remediation, remediationv1alpha1.GroupVersion.WithKind("RemediationRequest")),
            },
        },
        Spec: NotificationRequestSpec{
            Type:     NotificationTypeEscalation,
            Priority: NotificationPriorityCritical,
            Subject:  subject,
            Body:     body,
            Channels: []Channel{ChannelEmail, ChannelSlack},
            Recipients: []Recipient{
                {Email: "oncall@company.com"},
                {Slack: "#platform-oncall"},
            },
            Metadata: map[string]string{
                "remediationRequestName": remediation.Name,
                "cluster":                remediation.Spec.Cluster,
                "severity":               "P0",
            },
        },
    }

    return r.Create(ctx, notification)
}
```

### **AI Analysis Service** (Secondary Caller)

```go
// AI Analysis Service creates NotificationRequest for status updates
func (r *AIAnalysisReconciler) sendAnalysisComplete(ctx context.Context, analysis *AIAnalysisRequest) error {
    notification := &NotificationRequest{
        ObjectMeta: metav1.ObjectMeta{
            Name:      fmt.Sprintf("analysis-%s", analysis.Name),
            Namespace: analysis.Namespace,
            OwnerReferences: []metav1.OwnerReference{
                *metav1.NewControllerRef(analysis, aianalysisv1alpha1.GroupVersion.WithKind("AIAnalysisRequest")),
            },
        },
        Spec: NotificationRequestSpec{
            Type:     NotificationTypeStatusUpdate,
            Priority: NotificationPriorityLow,
            Subject:  fmt.Sprintf("AI Analysis Complete: %s", analysis.Name),
            Body:     fmt.Sprintf("Root cause: %s\nConfidence: %.2f%%", analysis.Status.RootCause, analysis.Status.Confidence*100),
            Channels: []Channel{ChannelSlack},
            Recipients: []Recipient{
                {Slack: "#ai-alerts"},
            },
        },
    }

    return r.Create(ctx, notification)
}
```

---

## ðŸ“Š **Confidence Assessment**

| Aspect | Confidence | Rationale |
|--------|-----------|-----------|
| **Data Loss Prevention** | 100% | etcd persistence guarantees |
| **Audit Trail Completeness** | 100% | CRD status tracks all attempts |
| **Automatic Retry** | 95% | controller-runtime reconciliation |
| **At-Least-Once Delivery** | 95% | Reconciliation loop guarantees |
| **Graceful Degradation** | 90% | Independent channel delivery |
| **Observability** | 95% | CRD status + metrics + events |
| **Overall** | **95%** | Declarative CRD architecture |

**vs REST API**: 45% confidence (data loss, no audit trail, manual retry)

---

## ðŸš€ **Next Steps**

1. âœ… **CRD API Definition** - Complete
2. âœ… **Controller Design** - This document
3. ðŸ“ **Implementation Plan** - Create detailed implementation plan (similar to Data Storage v4.1)
4. ðŸ”¨ **Controller Implementation** - Implement reconciliation logic
5. ðŸ§ª **Testing** - Unit, integration, E2E tests
6. ðŸ“Š **Update Service Documentation** - Update overview.md, api-specification.md

---

**Status**: âœ… Controller Design Complete
**Confidence**: 95%
**Approval**: âœ… User Approved (CRD-based architecture)
**Ready for**: Implementation Plan Creation

