# Multi-Provider CRD Architecture - Alternative Approaches

**Date**: October 5, 2025
**Challenge**: Support K8s + Non-K8s (AWS, Datadog, Azure) signals in single CRD schema
**Constraint**: No backwards compatibility required
**Minimum Confidence**: 80%

---

## üéØ High-Confidence Alternatives (‚â•80%)

Five approaches that solve the multi-provider challenge with different trade-offs.

---

## üìä Alternative 1: Pure Raw JSON Provider Data ‚≠ê

**Confidence**: 90%

### Schema

```go
type RemediationRequestSpec struct {
    // ========================================
    // UNIVERSAL FIELDS (strongly typed)
    // ========================================
    AlertFingerprint string      `json:"alertFingerprint"`
    AlertName        string      `json:"alertName"`
    Severity         string      `json:"severity"`
    Environment      string      `json:"environment"`
    Priority         string      `json:"priority"`
    SignalType       string      `json:"signalType"`
    TargetType       string      `json:"targetType"` // "kubernetes", "aws", "datadog"

    FiringTime       metav1.Time `json:"firingTime"`
    ReceivedTime     metav1.Time `json:"receivedTime"`
    Deduplication    DeduplicationInfo `json:"deduplication"`

    // ========================================
    // PROVIDER DATA (raw JSON for flexibility)
    // ========================================
    ProviderData     json.RawMessage `json:"providerData,omitempty"`

    OriginalPayload  []byte          `json:"originalPayload,omitempty"`
    TimeoutConfig    *TimeoutConfig  `json:"timeoutConfig,omitempty"`
}
```

### Examples

**Kubernetes**:
```json
{
  "targetType": "kubernetes",
  "providerData": {
    "namespace": "production",
    "resource": {"kind": "Pod", "name": "api-xyz"},
    "alertmanagerURL": "https://..."
  }
}
```

**AWS**:
```json
{
  "targetType": "aws",
  "providerData": {
    "region": "us-east-1",
    "instanceId": "i-abc123",
    "resourceType": "ec2"
  }
}
```

### Controller Usage

```go
func (r *Reconciler) processRemediation(remediation *remediationv1.RemediationRequest) error {
    switch remediation.Spec.TargetType {
    case "kubernetes":
        var k8s KubernetesProviderData
        json.Unmarshal(remediation.Spec.ProviderData, &k8s)
        return r.processKubernetes(k8s)

    case "aws":
        var aws AWSProviderData
        json.Unmarshal(remediation.Spec.ProviderData, &aws)
        return r.processAWS(aws)
    }
}
```

### Pros & Cons

**Pros**:
- ‚úÖ **Simplicity**: One field for all provider data
- ‚úÖ **Consistency**: All providers treated equally
- ‚úÖ **Scalability**: Add providers without schema changes
- ‚úÖ **No Empty Fields**: Clean for all providers

**Cons**:
- ‚ö†Ô∏è **No K8s Validation**: Can't validate provider data structure
- ‚ö†Ô∏è **No Field Queries**: Can't query by provider-specific fields
- ‚ö†Ô∏è **JSON Parsing**: Controllers must parse for every access
- ‚ö†Ô∏è **Documentation Critical**: Provider schemas must be well-documented

### Mitigation Strategies

**For Queryability**: Use labels
```go
Labels: map[string]string{
    "namespace": extractFromProviderData(signal.ProviderData, "namespace"),
    "region":    extractFromProviderData(signal.ProviderData, "region"),
}
```

**For Validation**: Gateway adapter validates before CRD creation
```go
func (a *PrometheusAdapter) Validate(signal *NormalizedSignal) error {
    var k8s KubernetesProviderData
    if err := json.Unmarshal(signal.ProviderData, &k8s); err != nil {
        return fmt.Errorf("invalid K8s provider data: %w", err)
    }
    if k8s.Namespace == "" {
        return errors.New("namespace is required")
    }
    return nil
}
```

**For Type Safety**: Create typed helper structs
```go
// pkg/apis/remediation/v1/provider_types.go
type KubernetesProviderData struct {
    Namespace       string             `json:"namespace"`
    Resource        ResourceIdentifier `json:"resource"`
    AlertmanagerURL string             `json:"alertmanagerURL,omitempty"`
}

type AWSProviderData struct {
    Region       string `json:"region"`
    AccountID    string `json:"accountId"`
    InstanceID   string `json:"instanceId"`
    ResourceType string `json:"resourceType"`
}
```

### Confidence Justification

**90% confidence** because:
- ‚úÖ Proven pattern in Kubernetes (ConfigMaps use similar approach)
- ‚úÖ Simple to implement
- ‚úÖ Highly flexible
- ‚úÖ Used successfully in other projects (Tekton, ArgoCD)
- ‚ö†Ô∏è Requires strong documentation discipline

---

## üìä Alternative 2: Typed Union with OneOf Validation

**Confidence**: 85%

### Schema

```go
type RemediationRequestSpec struct {
    // Universal
    AlertFingerprint string
    Priority         string
    TargetType       string

    // Typed provider data (only ONE populated)
    Kubernetes       *KubernetesTarget `json:"kubernetes,omitempty"`
    AWS              *AWSTarget        `json:"aws,omitempty"`
    Azure            *AzureTarget      `json:"azure,omitempty"`
    Datadog          *DatadogTarget    `json:"datadog,omitempty"`
}

// +kubebuilder:validation:XValidation:rule="self.targetType == 'kubernetes' ? has(self.kubernetes) : true"
// +kubebuilder:validation:XValidation:rule="self.targetType == 'aws' ? has(self.aws) : true"
```

### Provider Types

```go
type KubernetesTarget struct {
    Namespace       string             `json:"namespace"`
    Resource        ResourceIdentifier `json:"resource"`
    AlertmanagerURL string             `json:"alertmanagerURL,omitempty"`
    GrafanaURL      string             `json:"grafanaURL,omitempty"`
}

type AWSTarget struct {
    Region          string            `json:"region"`
    AccountID       string            `json:"accountId"`
    ResourceType    string            `json:"resourceType"` // "ec2", "rds", "lambda"
    ResourceID      string            `json:"resourceId"`
    Tags            map[string]string `json:"tags,omitempty"`
    CloudWatchURL   string            `json:"cloudWatchURL,omitempty"`
}

type AzureTarget struct {
    SubscriptionID  string            `json:"subscriptionId"`
    ResourceGroup   string            `json:"resourceGroup"`
    ResourceType    string            `json:"resourceType"`
    ResourceName    string            `json:"resourceName"`
    Location        string            `json:"location"`
    Tags            map[string]string `json:"tags,omitempty"`
    AzurePortalURL  string            `json:"azurePortalURL,omitempty"`
}

type DatadogTarget struct {
    MonitorID       int64             `json:"monitorId"`
    MonitorName     string            `json:"monitorName"`
    Host            string            `json:"host,omitempty"`
    Tags            []string          `json:"tags,omitempty"`
    MetricQuery     string            `json:"metricQuery"`
    DatadogURL      string            `json:"datadogURL,omitempty"`
}
```

### Examples

**Kubernetes**:
```json
{
  "targetType": "kubernetes",
  "kubernetes": {
    "namespace": "production",
    "resource": {"kind": "Pod", "name": "api-xyz"}
  },
  "aws": null,
  "azure": null,
  "datadog": null
}
```

**AWS**:
```json
{
  "targetType": "aws",
  "kubernetes": null,
  "aws": {
    "region": "us-east-1",
    "resourceType": "ec2",
    "resourceId": "i-abc123"
  },
  "azure": null,
  "datadog": null
}
```

### Controller Usage

```go
func (r *Reconciler) processRemediation(remediation *remediationv1.RemediationRequest) error {
    switch remediation.Spec.TargetType {
    case "kubernetes":
        if remediation.Spec.Kubernetes == nil {
            return errors.New("kubernetes target data missing")
        }
        return r.processKubernetes(remediation.Spec.Kubernetes)

    case "aws":
        if remediation.Spec.AWS == nil {
            return errors.New("aws target data missing")
        }
        return r.processAWS(remediation.Spec.AWS)
    }
}
```

### Pros & Cons

**Pros**:
- ‚úÖ **Fully Typed**: Complete type safety for all providers
- ‚úÖ **K8s Validation**: CRD validation validates structure
- ‚úÖ **Self-Documenting**: Types show what's expected
- ‚úÖ **IDE Support**: Auto-complete works perfectly
- ‚úÖ **Queryable**: Can query K8s-specific fields

**Cons**:
- ‚ö†Ô∏è **Schema Updates**: Every new provider requires CRD schema change
- ‚ö†Ô∏è **Multiple Nil Pointers**: 3-4 nil pointers per CRD
- ‚ö†Ô∏è **Validation Complexity**: OneOf validation can be tricky
- ‚ö†Ô∏è **CRD Size**: Schema gets large with many providers

### Mitigation Strategies

**For Schema Updates**: Use CRD versioning
```go
// When adding new provider, bump version
// v1 -> v2 with conversion webhook
```

**For Nil Pointers**: Document clearly which field applies
```go
// Only ONE of kubernetes, aws, azure, datadog is populated
// Determined by targetType field
```

**For Validation**: Use CEL validation (Kubernetes 1.25+)
```go
// +kubebuilder:validation:XValidation:rule="(self.targetType == 'kubernetes' && has(self.kubernetes)) || (self.targetType == 'aws' && has(self.aws))"
```

### Confidence Justification

**85% confidence** because:
- ‚úÖ Strong type safety
- ‚úÖ K8s native validation
- ‚úÖ Clear schema
- ‚ö†Ô∏è Requires schema updates for new providers (acceptable if infrequent)
- ‚ö†Ô∏è More complex than raw JSON

---

## üìä Alternative 3: Separate CRD Types per Provider

**Confidence**: 80%

### Schema

**Base CRD** (abstract):
```go
// Common fields only
type RemediationRequestBase struct {
    AlertFingerprint string
    Priority         string
    Severity         string
    Environment      string
    TargetType       string // Set automatically by CRD kind
}
```

**K8s-specific CRD**:
```go
// KubernetesRemediationRequest CRD
type KubernetesRemediationRequestSpec struct {
    RemediationRequestBase

    // K8s-specific (strongly typed)
    Namespace       string
    Resource        ResourceIdentifier
    AlertmanagerURL string
    GrafanaURL      string
}
```

**AWS-specific CRD**:
```go
// AWSRemediationRequest CRD
type AWSRemediationRequestSpec struct {
    RemediationRequestBase

    // AWS-specific (strongly typed)
    Region          string
    AccountID       string
    ResourceType    string
    ResourceID      string
    CloudWatchURL   string
}
```

### Examples

**Kubernetes CRD**:
```yaml
apiVersion: remediation.kubernaut.io/v1
kind: KubernetesRemediationRequest
metadata:
  name: remediation-abc123
spec:
  alertFingerprint: abc123
  priority: P0
  namespace: production
  resource:
    kind: Pod
    name: api-xyz
```

**AWS CRD**:
```yaml
apiVersion: remediation.kubernaut.io/v1
kind: AWSRemediationRequest
metadata:
  name: remediation-def456
spec:
  alertFingerprint: def456
  priority: P1
  region: us-east-1
  resourceType: ec2
  resourceId: i-abc123
```

### Controller Architecture

**Separate controllers per provider**:
```go
// KubernetesRemediationReconciler
func (r *KubernetesRemediationReconciler) Reconcile(ctx context.Context, req ctrl.Request) {
    var k8sRemediation remediationv1.KubernetesRemediationRequest
    // ... process K8s remediation
}

// AWSRemediationReconciler
func (r *AWSRemediationReconciler) Reconcile(ctx context.Context, req ctrl.Request) {
    var awsRemediation remediationv1.AWSRemediationRequest
    // ... process AWS remediation
}
```

**OR Unified controller with type switching**:
```go
func (r *RemediationReconciler) SetupWithManager(mgr ctrl.Manager) error {
    return ctrl.NewControllerManagedBy(mgr).
        For(&remediationv1.KubernetesRemediationRequest{}).
        For(&remediationv1.AWSRemediationRequest{}).
        For(&remediationv1.AzureRemediationRequest{}).
        Complete(r)
}
```

### Pros & Cons

**Pros**:
- ‚úÖ **Perfect Type Safety**: Each CRD has exact fields needed
- ‚úÖ **No Empty Fields**: Zero waste
- ‚úÖ **Clear Separation**: K8s vs AWS vs Azure is explicit
- ‚úÖ **Independent Evolution**: Each CRD can evolve independently
- ‚úÖ **Simple Queries**: No confusion about which fields exist

**Cons**:
- ‚ùå **Multiple CRDs**: More API complexity
- ‚ùå **Gateway Complexity**: Must choose correct CRD type
- ‚ùå **Controller Complexity**: Must watch multiple CRD types
- ‚ùå **Code Duplication**: Common logic repeated across controllers
- ‚ùå **Listing Complexity**: Can't `kubectl get remediationrequests` (must query each type)

### Mitigation Strategies

**For Gateway Complexity**: Factory pattern
```go
func (g *Gateway) createRemediationCRD(signal *NormalizedSignal) (client.Object, error) {
    switch signal.TargetType {
    case "kubernetes":
        return g.createKubernetesRemediationCRD(signal)
    case "aws":
        return g.createAWSRemediationCRD(signal)
    }
}
```

**For Listing**: Use labels
```go
// All CRDs share common labels
Labels: map[string]string{
    "kubernaut.io/remediation": "true",
    "kubernaut.io/priority": signal.Priority,
}

// List all remediations across types
kubectl get kubernetesremediationrequests,awsremediationrequests -l kubernaut.io/remediation=true
```

**For Code Duplication**: Shared base reconciler
```go
type BaseRemediationReconciler struct {
    // Common logic
}

type KubernetesRemediationReconciler struct {
    BaseRemediationReconciler
    // K8s-specific logic
}
```

### Confidence Justification

**80% confidence** because:
- ‚úÖ Perfect type safety
- ‚úÖ Clear separation of concerns
- ‚ö†Ô∏è Adds operational complexity (multiple CRDs to manage)
- ‚ö†Ô∏è More code to maintain
- ‚ö†Ô∏è Listing/querying across types is awkward

---

## üìä Alternative 4: Extensible Metadata Pattern

**Confidence**: 82%

### Schema

```go
type RemediationRequestSpec struct {
    // Universal fields
    AlertFingerprint string
    Priority         string
    TargetType       string

    // Core target info (minimal, typed)
    TargetIdentifier string // K8s: "namespace/kind/name", AWS: "region/resource-type/id"

    // Extensible metadata (key-value)
    TargetMetadata   map[string]string `json:"targetMetadata,omitempty"`

    // Structured data (when needed)
    TargetData       json.RawMessage   `json:"targetData,omitempty"`
}
```

### Examples

**Kubernetes**:
```json
{
  "targetType": "kubernetes",
  "targetIdentifier": "production/Pod/api-xyz",
  "targetMetadata": {
    "namespace": "production",
    "kind": "Pod",
    "name": "api-xyz",
    "alertmanagerURL": "https://..."
  },
  "targetData": {
    "labels": {"app": "api", "version": "v2"},
    "nodeSelector": {"disktype": "ssd"}
  }
}
```

**AWS**:
```json
{
  "targetType": "aws",
  "targetIdentifier": "us-east-1/ec2/i-abc123",
  "targetMetadata": {
    "region": "us-east-1",
    "resourceType": "ec2",
    "instanceId": "i-abc123",
    "accountId": "123456789012"
  },
  "targetData": {
    "instanceType": "t3.large",
    "availabilityZone": "us-east-1a",
    "tags": {...}
  }
}
```

### Controller Usage

```go
func (r *Reconciler) processRemediation(remediation *remediationv1.RemediationRequest) error {
    // Parse identifier
    parts := strings.Split(remediation.Spec.TargetIdentifier, "/")

    // Access metadata (flat, typed as strings)
    namespace := remediation.Spec.TargetMetadata["namespace"]
    region := remediation.Spec.TargetMetadata["region"]

    // Parse structured data when needed
    if remediation.Spec.TargetData != nil {
        var data map[string]interface{}
        json.Unmarshal(remediation.Spec.TargetData, &data)
    }
}
```

### Pros & Cons

**Pros**:
- ‚úÖ **Queryable Metadata**: Can query by common metadata keys
- ‚úÖ **Extensible**: Add metadata without schema changes
- ‚úÖ **Identifier Pattern**: Standard format across providers
- ‚úÖ **Flexible**: Structured data for complex cases

**Cons**:
- ‚ö†Ô∏è **String-Only Metadata**: All values are strings (no nested objects)
- ‚ö†Ô∏è **Parsing Required**: Must parse identifier string
- ‚ö†Ô∏è **Convention-Based**: Relies on metadata key conventions
- ‚ö†Ô∏è **Mixed Patterns**: Some data in metadata, some in targetData

### Mitigation Strategies

**For Type Safety**: Define metadata key constants
```go
const (
    MetadataNamespace    = "namespace"
    MetadataRegion       = "region"
    MetadataResourceType = "resourceType"
)
```

**For Identifier Parsing**: Helper functions
```go
func ParseKubernetesIdentifier(id string) (namespace, kind, name string, err error) {
    parts := strings.Split(id, "/")
    if len(parts) != 3 {
        return "", "", "", errors.New("invalid K8s identifier")
    }
    return parts[0], parts[1], parts[2], nil
}
```

### Confidence Justification

**82% confidence** because:
- ‚úÖ Good balance of flexibility and structure
- ‚úÖ Queryable metadata
- ‚ö†Ô∏è Requires conventions and documentation
- ‚ö†Ô∏è String-only metadata is limiting for complex data

---

## üìä Alternative 5: Dynamic CRD with Schema Registry

**Confidence**: 80%

### Architecture

**Core CRD** (minimal, dynamic):
```go
type RemediationRequestSpec struct {
    // Minimal universal fields
    AlertFingerprint string
    Priority         string

    // Schema reference
    SchemaVersion    string          `json:"schemaVersion"` // "kubernetes-v1", "aws-v1"

    // Dynamic data (validated against schema)
    Data             json.RawMessage `json:"data"`
}
```

**Schema Registry** (ConfigMaps or CRDs):
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: remediation-schema-kubernetes-v1
data:
  schema: |
    {
      "type": "object",
      "required": ["namespace", "resource"],
      "properties": {
        "namespace": {"type": "string"},
        "resource": {
          "type": "object",
          "properties": {
            "kind": {"type": "string"},
            "name": {"type": "string"}
          }
        }
      }
    }
```

### Validation

**Gateway validates against schema**:
```go
func (g *Gateway) createRemediationCRD(signal *NormalizedSignal) error {
    // Load schema
    schema, err := g.schemaRegistry.GetSchema(signal.SchemaVersion)
    if err != nil {
        return fmt.Errorf("schema not found: %w", err)
    }

    // Validate data against schema
    if err := schema.Validate(signal.Data); err != nil {
        return fmt.Errorf("data validation failed: %w", err)
    }

    // Create CRD
    return g.k8sClient.Create(ctx, &remediationv1.RemediationRequest{
        Spec: remediationv1.RemediationRequestSpec{
            SchemaVersion: signal.SchemaVersion,
            Data:          signal.Data,
        },
    })
}
```

### Pros & Cons

**Pros**:
- ‚úÖ **Ultimate Flexibility**: Schema evolves without CRD changes
- ‚úÖ **Versioned Schemas**: Multiple versions can coexist
- ‚úÖ **Validation**: JSON Schema validation ensures correctness
- ‚úÖ **Runtime Evolution**: Add new schemas without redeployment

**Cons**:
- ‚ùå **Complexity**: Schema registry adds significant complexity
- ‚ùå **Runtime Validation**: Can't use K8s CRD validation
- ‚ùå **Learning Curve**: Team must learn JSON Schema
- ‚ùå **Debugging**: Harder to debug schema issues
- ‚ùå **Tooling**: Requires custom tooling for schema management

### Confidence Justification

**80% confidence** (minimum threshold) because:
- ‚úÖ Very flexible and powerful
- ‚ö†Ô∏è High complexity - only worth it for highly dynamic systems
- ‚ö†Ô∏è Requires schema registry infrastructure
- ‚ö†Ô∏è May be over-engineering for this use case

---

## üìä Comparison Matrix

| Criteria | Alt 1: Raw JSON | Alt 2: Typed Union | Alt 3: Separate CRDs | Alt 4: Metadata | Alt 5: Schema Registry |
|----------|----------------|-------------------|---------------------|----------------|----------------------|
| **Confidence** | 90% | 85% | 80% | 82% | 80% |
| **Type Safety** | ‚ö†Ô∏è Medium | ‚úÖ High | ‚úÖ Highest | ‚ö†Ô∏è Medium | ‚ö†Ô∏è Low |
| **Simplicity** | ‚úÖ Highest | ‚ö†Ô∏è Medium | ‚ùå Low | ‚ö†Ô∏è Medium | ‚ùå Lowest |
| **Scalability** | ‚úÖ Highest | ‚ö†Ô∏è Medium | ‚ö†Ô∏è Medium | ‚úÖ High | ‚úÖ Highest |
| **Query Support** | ‚ùå Via Labels | ‚úÖ Native | ‚úÖ Native | ‚úÖ Metadata | ‚ùå Limited |
| **K8s Validation** | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes | ‚ö†Ô∏è Partial | ‚ùå No |
| **Schema Changes** | ‚úÖ None | ‚ùå Per Provider | ‚ùå New CRD | ‚úÖ None | ‚úÖ None |
| **Implementation Time** | ‚úÖ 1-2 days | ‚ö†Ô∏è 3-4 days | ‚ùå 5-7 days | ‚ö†Ô∏è 2-3 days | ‚ùå 7-10 days |
| **Maintenance** | ‚úÖ Low | ‚ö†Ô∏è Medium | ‚ùå High | ‚ö†Ô∏è Medium | ‚ùå High |

---

## üéØ Recommendations by Use Case

### **For V1 (K8s Only, Plan for Future)**
‚Üí **Alternative 1** (Raw JSON) - 90% confidence
- Simple to implement now
- Easy to extend later
- Proven pattern

### **For Multi-Provider from Day 1**
‚Üí **Alternative 2** (Typed Union) - 85% confidence
- Strong type safety
- Good developer experience
- Worth the complexity

### **For Provider-Specific Logic**
‚Üí **Alternative 3** (Separate CRDs) - 80% confidence
- Clear separation
- Independent evolution
- Accept the operational complexity

### **For Hybrid Approach**
‚Üí **Alternative 4** (Metadata Pattern) - 82% confidence
- Balance of structure and flexibility
- Queryable metadata
- Good for gradual adoption

### **For Highly Dynamic Systems**
‚Üí **Alternative 5** (Schema Registry) - 80% confidence
- Only if you need extreme flexibility
- Only if you have schema management expertise

---

## üéØ Final Recommendation

**For Kubernaut V1**: **Alternative 1 (Raw JSON Provider Data)**

**Why**:
1. ‚úÖ **Highest Confidence** (90%)
2. ‚úÖ **Fastest to Implement** (1-2 days)
3. ‚úÖ **Most Flexible** (add providers without schema changes)
4. ‚úÖ **Simplest** (one pattern for all providers)
5. ‚úÖ **Proven** (used in Tekton, ArgoCD, Crossplane)

**Trade-offs Accepted**:
- No K8s validation (mitigate with Gateway adapter validation)
- No field queries (mitigate with labels)
- JSON parsing required (mitigate with typed helper structs)

**When to Reconsider**:
- If K8s validation is critical ‚Üí Choose Alternative 2
- If provider-specific controllers needed ‚Üí Choose Alternative 3
- If extreme type safety required ‚Üí Choose Alternative 2

---

**What's your decision?** Which alternative aligns best with your requirements?
