# coding: utf-8

"""
    Data Storage Service API

    Data Storage Service provides REST API access to audit trail persistence.  **Business Requirements**: - BR-STORAGE-001 to BR-STORAGE-020: Audit write API - BR-STORAGE-021: Incident query API (READ) - BR-STORAGE-024: RFC 7807 error responses - BR-AUDIT-006: Legal hold capability (SOC2 Gap #8)  **Design Decisions**: - ADR-031: OpenAPI 3.0+ specification for all stateless REST APIs - ADR-032: Data Access Layer Isolation (only Data Storage connects to PostgreSQL) - DD-009: Dead Letter Queue fallback on database errors - DD-AUTH-004: OAuth-proxy sidecar for authentication/authorization - DD-AUTH-005: Client authentication pattern (ServiceAccount tokens)  **Architecture**: This service is the **ONLY** service that directly accesses PostgreSQL. All other services (Context API, Effectiveness Monitor, etc.) access data through this REST API Gateway.  **Authentication & Authorization (Production/E2E)**: All requests to DataStorage are protected by an OAuth-proxy sidecar:  1. **Client Authentication**: Services authenticate with Kubernetes ServiceAccount tokens    - Token mounted at: `/var/run/secrets/kubernetes.io/serviceaccount/token`    - Clients inject: `Authorization: Bearer <token>` header    - See DD-AUTH-005 for client implementation patterns  2. **OAuth-Proxy Validation**: The sidecar validates requests    - Validates JWT token signature and expiration    - Performs Subject Access Review (SAR) to check RBAC permissions    - Injects `X-Auth-Request-User` header with authenticated user identity    - Returns HTTP 401 if token invalid, HTTP 403 if SAR fails  3. **Handler Enforcement**: DataStorage handlers extract user identity    - Legal hold operations REQUIRE `X-Auth-Request-User` header    - HTTP 401 returned if header missing (authentication failed)    - User identity stored in audit events for SOC2 compliance  **Routing Flow**: ``` Client → data-storage-service:8080 (Service)        ↓      oauth-proxy:8080 (validates token + SAR)        ↓      DataStorage:8081 (X-Auth-Request-User header) ```  **Integration Tests**: Integration tests run without oauth-proxy. Use `testutil.NewMockUserTransport()` to inject mock `X-Auth-Request-User` headers directly.  **SOC2 Compliance**: - All legal hold operations attributed to authenticated users - Audit trail captures placed_by/released_by from X-Auth-Request-User - Unauthorized access blocked at oauth-proxy layer (defense-in-depth) 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import Any, ClassVar, Dict, List, Optional, Union
from pydantic import BaseModel, StrictFloat, StrictInt, StrictStr, field_validator
from pydantic import Field
from datastorage.models.effectiveness_components import EffectivenessComponents
from datastorage.models.hash_comparison_data import HashComparisonData
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class EffectivenessScoreResponse(BaseModel):
    """
    On-demand effectiveness score response. DS computes the weighted score from component audit events emitted by the Effectiveness Monitor. Per ADR-EM-001 Principle 5 and DD-017 v2.1 scoring formula. 
    """ # noqa: E501
    correlation_id: StrictStr = Field(description="The correlation ID linking all audit events in the remediation lifecycle.")
    score: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Weighted effectiveness score (0.0 to 1.0). Null if no component scores available. Formula: (health * 0.40 + alert * 0.35 + metrics * 0.25) / total_assessed_weight ")
    components: EffectivenessComponents
    hash_comparison: Optional[HashComparisonData] = None
    assessment_status: StrictStr = Field(description="Current assessment status: - no_data: No component events found - in_progress: Some component events present but assessment not completed - full: All components assessed successfully - partial: Some components assessed, others unavailable - spec_drift: Target resource spec changed during assessment (score unreliable, forced to 0.0) - expired: Assessment timed out before completing - no_execution: No workflow execution found for this correlation ID - metrics_timed_out: Prometheus metrics collection timed out - EffectivenessAssessed: Legacy value (equivalent to \"full\") ")
    computed_at: datetime = Field(description="Timestamp when this score was computed.")
    __properties: ClassVar[List[str]] = ["correlation_id", "score", "components", "hash_comparison", "assessment_status", "computed_at"]

    @field_validator('assessment_status')
    def assessment_status_validate_enum(cls, value):
        """Validates the enum"""
        if value not in ('no_data', 'in_progress', 'full', 'partial', 'spec_drift', 'expired', 'no_execution', 'metrics_timed_out', 'EffectivenessAssessed'):
            raise ValueError("must be one of enum values ('no_data', 'in_progress', 'full', 'partial', 'spec_drift', 'expired', 'no_execution', 'metrics_timed_out', 'EffectivenessAssessed')")
        return value

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of EffectivenessScoreResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of components
        if self.components:
            _dict['components'] = self.components.to_dict()
        # override the default output from pydantic by calling `to_dict()` of hash_comparison
        if self.hash_comparison:
            _dict['hash_comparison'] = self.hash_comparison.to_dict()
        # set to None if score (nullable) is None
        # and model_fields_set contains the field
        if self.score is None and "score" in self.model_fields_set:
            _dict['score'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of EffectivenessScoreResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "correlation_id": obj.get("correlation_id"),
            "score": obj.get("score"),
            "components": EffectivenessComponents.from_dict(obj.get("components")) if obj.get("components") is not None else None,
            "hash_comparison": HashComparisonData.from_dict(obj.get("hash_comparison")) if obj.get("hash_comparison") is not None else None,
            "assessment_status": obj.get("assessment_status"),
            "computed_at": obj.get("computed_at")
        })
        return _obj


