//go:build integration
// +build integration

package ai

import (
	"context"
	"os"
	"testing"
	"time"

	"github.com/jordigilh/kubernaut/internal/config"
	"github.com/jordigilh/kubernaut/pkg/ai/llm"
	"github.com/sirupsen/logrus"
)

// TestRealLLMConnectivity tests the real LLM service at the configured endpoint
func TestRealLLMConnectivity(t *testing.T) {
	logger := logrus.New()
	logger.SetLevel(logrus.InfoLevel)

	// Configure for the real LLM service using environment variables
	endpoint := os.Getenv("LLM_ENDPOINT")
	if endpoint == "" {
		endpoint = "http://192.168.1.169:8080" // Default to ramalama endpoint
	}

	model := os.Getenv("LLM_MODEL")
	if model == "" {
		model = "ggml-org/gpt-oss-20b-GGUF" // Default to 20B model
	}

	provider := os.Getenv("LLM_PROVIDER")
	if provider == "" {
		provider = "ramalama" // Default to ramalama provider
	}

	cfg := config.LLMConfig{
		Provider: provider,
		Model:    model,
		Endpoint: endpoint,
		Timeout:  30 * time.Second,
	}

	client, err := llm.NewClient(cfg, logger)
	if err != nil {
		t.Fatalf("Failed to create LLM client: %v", err)
	}

	// Test basic connectivity
	testPrompt := "Respond with 'CONNECTIVITY_OK' to confirm the LLM is working."
	response, err := client.GenerateResponse(testPrompt)
	if err != nil {
		t.Fatalf("Failed to get response from LLM: %v", err)
	}

	if response == "" {
		t.Fatal("Received empty response from LLM")
	}

	t.Logf("‚úÖ Real LLM connectivity test successful!")
	t.Logf("üìù Prompt: %s", testPrompt)
	t.Logf("ü§ñ Response: %s", response)

	// Test with a more complex prompt
	alertPrompt := "Analyze this Kubernetes alert: HighMemoryUsage in production namespace. Recommend an action."
	alertResponse, err := client.GenerateResponse(alertPrompt)
	if err != nil {
		t.Fatalf("Failed to get alert analysis from LLM: %v", err)
	}

	if alertResponse == "" {
		t.Fatal("Received empty alert analysis from LLM")
	}

	t.Logf("‚úÖ Real LLM alert analysis test successful!")
	t.Logf("üìù Alert Prompt: %s", alertPrompt)
	t.Logf("ü§ñ Alert Analysis: %s", alertResponse)

	// Test context-aware functionality
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	if err := client.ReadinessCheck(ctx); err != nil {
		t.Fatalf("LLM readiness check failed: %v", err)
	}

	if err := client.LivenessCheck(ctx); err != nil {
		t.Fatalf("LLM liveness check failed: %v", err)
	}

	t.Logf("‚úÖ Real LLM health checks successful!")
	t.Logf("üîß Endpoint: %s", client.GetEndpoint())
	t.Logf("üß† Model: %s", client.GetModel())
}
