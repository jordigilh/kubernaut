---
globs: "pkg/ai/**/*,pkg/workflow/**/*,pkg/intelligence/**/*"
description: "AI/ML components and integration patterns for kubernaut"
---

# AI/ML Guidelines for Kubernaut

## AI Service Architecture
Kubernaut integrates multiple AI providers through a unified interface pattern following strict interface reuse principles.

**CRITICAL**: Follow AI development methodology in [12-ai-ml-development-methodology.mdc](mdc:.cursor/rules/12-ai-ml-development-methodology.mdc) for TDD and interface management.

### Interface Reuse Principles - MANDATORY
- **FORBIDDEN**: Creating new AI interfaces - use existing `pkg/ai/llm.Client`
- **MANDATORY**: Enhance existing AI clients rather than creating new ones
- **INTEGRATION**: All AI components must integrate with main applications (`cmd/*/main.go`)

### Supported AI Providers
- **HolmesGPT**: Primary AI service via [pkg/ai/holmesgpt/client.go](mdc:pkg/ai/holmesgpt/client.go)
- **OpenAI**: GPT-3.5, GPT-4 models
- **Anthropic**: Claude models
- **Azure OpenAI**: Enterprise OpenAI deployment
- **AWS Bedrock**: Amazon's AI service
- **Ollama**: Local LLM deployment
- **Ramalama**: Local model serving

## HolmesGPT Integration Patterns
### Client Usage - ENHANCE EXISTING INTERFACES
```go
// âœ… CORRECT: Use existing unified interface
import "pkg/ai/llm"

// Use existing LLM client interface
llmClient := llm.NewClient(config.LLM)
response, err := llmClient.AnalyzeAlert(ctx, alertData)
if err != nil {
    return fmt.Errorf("AI analysis failed: %w", err)
}
```

### Context Enrichment
- **Kubernetes Context**: Real-time cluster data from [pkg/platform/k8s/client.go](mdc:pkg/platform/k8s/client.go)
- **Historical Context**: Action patterns from PostgreSQL via [pkg/ai/context/](mdc:pkg/ai/context/)
- **Vector Context**: Similarity search from vector database

## AI Response Processing
### Validation Pipeline
1. **Structure Validation**: Ensure response matches expected schema
2. **Confidence Scoring**: Evaluate AI recommendation confidence
3. **Safety Validation**: Check recommendations against safety policies
4. **Business Rule Validation**: Ensure recommendations align with business logic

### Confidence Thresholds
```go
type ConfidenceLevel struct {
    High   float64 // >0.8 - Execute automatically
    Medium float64 // 0.5-0.8 - Require approval
    Low    float64 // <0.5 - Log only, no action
}
```

## Workflow Engine AI Integration
### Intelligent Workflow Builder
**Location**: [pkg/workflow/engine/intelligent_workflow_builder_impl.go](mdc:pkg/workflow/engine/intelligent_workflow_builder_impl.go)
- AI-generated multi-step remediation workflows
- Dynamic template generation based on alert patterns
- Learning from historical workflow effectiveness

### AI Condition Evaluator
**Location**: [pkg/workflow/engine/ai_condition_evaluator_impl.go](mdc:pkg/workflow/engine/ai_condition_evaluator_impl.go)
- Intelligent step condition evaluation
- Context-aware decision making
- Pattern recognition for workflow branching

## Vector Database Integration
### Embedding Generation
**Location**: [pkg/ai/embedding/pipeline.go](mdc:pkg/ai/embedding/pipeline.go)
- Support for multiple embedding models (OpenAI, HuggingFace)
- Consistent embedding generation for similarity search
- Caching for performance optimization

### Vector Storage
**Location**: [pkg/storage/vector/](mdc:pkg/storage/vector/)
- PostgreSQL with pgvector extension
- Similarity search for historical patterns
- RAG (Retrieval Augmented Generation) enhancement

## AI Safety and Reliability
### Circuit Breaker Pattern
```go
// Implement circuit breaker for AI service calls
breaker := circuitbreaker.New(&Config{
    Timeout:     30 * time.Second,
    MaxRequests: 100,
    Interval:    60 * time.Second,
})
```

### Fallback Strategies
1. **Primary**: HolmesGPT with full context
2. **Secondary**: Direct LLM provider with reduced context
3. **Fallback**: Rule-based decision making
4. **Emergency**: Safe default actions only

### Rate Limiting and Quotas
- Respect AI provider rate limits
- Implement exponential backoff for retries
- Monitor AI service usage and costs
- Prioritize high-criticality alerts

## Learning and Adaptation
### Effectiveness Assessment
**Location**: [pkg/ai/insights/assessor.go](mdc:pkg/ai/insights/assessor.go)
- Track action outcomes and effectiveness
- Learn from successful and failed interventions
- Adjust confidence scores based on historical performance

### Pattern Discovery
**Location**: [pkg/intelligence/patterns/pattern_discovery_engine.go](mdc:pkg/intelligence/patterns/pattern_discovery_engine.go)
- Identify recurring alert patterns
- Discover correlation between actions and outcomes
- Generate insights for proactive maintenance

## AI Testing Patterns
### Mock Strategy - REFERENCE AUTHORITATIVE SOURCE
**AUTHORITY**: Follow the comprehensive mock usage matrix in [03-testing-strategy.mdc](mdc:.cursor/rules/03-testing-strategy.mdc#mock-usage-decision-matrix---authoritative-source)

### AI-Specific Implementation
- **Unit Tests**: Use [pkg/testutil/mocks/ai_mocks.go](mdc:pkg/testutil/mocks/ai_mocks.go) for external AI APIs
- **Test Scenarios**: Support configurable responses for different test scenarios
- **Error Testing**: Include error simulation and timeout testing with mocks
- **Business Logic**: Always test real AI analysis algorithms and business logic

### Integration Testing
- **Development**: Test against real AI services when available
- **CI/CD**: Use mock LLM for reliability: `USE_MOCK_LLM=true`
- **Quality Validation**: Test AI response quality and consistency with real components
- **Fallback Testing**: Test fallback mechanisms under various failure conditions

## Performance Optimization
### Caching Strategy
- Cache embedding generation results
- Store frequent AI responses with TTL
- Use Redis for distributed caching across instances

### Batch Processing
- Group similar alerts for batch AI analysis
- Optimize context sharing across related requests
- Balance latency vs. throughput based on criticality

## Monitoring and Observability
### AI Metrics
- Track AI response times and success rates
- Monitor confidence score distributions
- Measure action effectiveness over time
- Alert on AI service degradation

### Cost Management
- Track AI service usage and costs per provider
- Implement budget alerts and quotas
- Optimize prompt size and frequency
- Use appropriate model tiers based on use case complexity