package conditions

import (
	"context"
	"time"

	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"
	"github.com/sirupsen/logrus"

	"github.com/jordigilh/kubernaut/pkg/ai/conditions"
	"github.com/jordigilh/kubernaut/pkg/shared/types"
	"github.com/jordigilh/kubernaut/pkg/testutil/mocks"
	workflowtypes "github.com/jordigilh/kubernaut/pkg/workflow/types"
)

// Suite structure moved to conditions_suite_test.go - generated by ginkgo bootstrap

var _ = Describe("AI Conditions Engine - Business Requirements Testing", func() {
	var (
		logger             *logrus.Logger
		ctx                context.Context
		conditionEvaluator *mocks.MockConditionEvaluator
	)

	BeforeEach(func() {
		logger = logrus.New()
		logger.SetLevel(logrus.WarnLevel)
		ctx = context.Background()

		// Use shared mock following development guidelines
		conditionEvaluator = mocks.NewMockConditionEvaluator()
	})

	// BR-COND-001: MUST evaluate complex logical conditions using natural language processing
	Context("BR-COND-001: Complex Logical Condition Evaluation", func() {
		It("should evaluate complex logical conditions with high accuracy", func() {
			// Arrange: Create complex logical condition
			condition := &types.ConditionSpec{
				ID:          "ComplexCPUAndMemoryCondition",
				Type:        "expression",
				Description: "(cpu_usage > 80 AND memory_usage > 70) OR (response_time > 2000 AND error_rate > 0.05)",
				Parameters: map[string]interface{}{
					"expression":        "(cpu_usage > 80 AND memory_usage > 70) OR (response_time > 2000 AND error_rate > 0.05)",
					"complexity_score":  0.8,
					"logical_operators": []string{"AND", "OR"},
				},
			}

			stepContext := &workflowtypes.StepContext{
				StepID:      "step-1",
				WorkflowID:  "workflow-cpu-memory-check",
				ExecutionID: "exec-123",
				Variables: map[string]interface{}{
					"cpu_usage":     85.5,
					"memory_usage":  75.2,
					"response_time": 1500.0,
					"error_rate":    0.02,
					"namespace":     "production",
					"pod_name":      "web-server-abc123",
				},
			}

			// Setup mock to return complex condition evaluation
			conditionEvaluator.SetConditionResult(&conditions.EvaluationResult{
				Result:     true,
				Confidence: 0.92,
				Reasoning:  "CPU usage (85.5%) exceeds 80% threshold AND memory usage (75.2%) exceeds 70% threshold, satisfying first logical clause",
				Metadata: map[string]interface{}{
					"evaluated_clauses": []string{
						"cpu_usage > 80 = true (85.5 > 80)",
						"memory_usage > 70 = true (75.2 > 70)",
					},
					"logical_evaluation": "true AND true = true",
					"nlp_parsing_score":  0.95,
				},
				EvaluatedAt: time.Now(),
			})

			// Act: Evaluate complex logical condition
			result, err := conditionEvaluator.EvaluateExpressionCondition(ctx, condition, stepContext)

			// **Business Requirement BR-COND-001**: Validate complex logical evaluation
			Expect(err).ToNot(HaveOccurred(), "Should successfully evaluate complex logical conditions")
			Expect(result.Confidence).To(BeNumerically(">=", 0.85),
				"BR-COND-001: Complex condition evaluation should have high confidence (≥85%)")
			Expect(result.Reasoning).ToNot(BeEmpty(),
				"BR-COND-001: Should provide natural language reasoning for complex conditions")

			// **Business Value Validation**: Verify NLP processing quality
			nlpScore, exists := result.Metadata["nlp_parsing_score"]
			Expect(exists).To(BeTrue(), "BR-COND-001: Should track NLP parsing quality")
			Expect(nlpScore).To(BeNumerically(">=", 0.9),
				"BR-COND-001: NLP parsing should be highly accurate (≥90%)")

			// Validate logical evaluation breakdown
			evaluatedClauses, exists := result.Metadata["evaluated_clauses"]
			Expect(exists).To(BeTrue(), "BR-COND-001: Should provide clause-by-clause evaluation")
			clauses, ok := evaluatedClauses.([]string)
			Expect(ok).To(BeTrue(), "BR-COND-001: Clause evaluation should be structured")
			Expect(len(clauses)).To(BeNumerically(">=", 2),
				"BR-COND-001: Should evaluate multiple logical clauses")
		})

		It("should handle natural language condition expressions with contextual understanding", func() {
			// Arrange: Create natural language condition
			condition := &types.ConditionSpec{
				ID:          "NaturalLanguageCondition",
				Type:        "natural_language",
				Description: "When the web server shows signs of memory pressure and response times are degraded for more than 5 minutes",
				Parameters: map[string]interface{}{
					"expression":       "When the web server shows signs of memory pressure and response times are degraded for more than 5 minutes",
					"natural_language": true,
					"context_required": true,
				},
			}

			stepContext := &workflowtypes.StepContext{
				StepID:      "step-2",
				WorkflowID:  "workflow-natural-language-check",
				ExecutionID: "exec-124",
				Variables: map[string]interface{}{
					"memory_pressure_duration": "7m",
					"avg_response_time":        2500.0,
					"degraded_duration":        "6m",
					"service_type":             "web_server",
					"alert_context":            "HighResponseTime",
				},
			}

			// Setup mock for natural language processing
			conditionEvaluator.SetConditionResult(&conditions.EvaluationResult{
				Result:     true,
				Confidence: 0.88,
				Reasoning:  "Detected memory pressure for 7 minutes (exceeds 5-minute threshold) and response time degradation for 6 minutes, matching natural language condition criteria",
				Metadata: map[string]interface{}{
					"nlp_entities":          []string{"memory_pressure", "response_times", "5_minutes"},
					"context_understanding": 0.87,
					"duration_analysis": map[string]interface{}{
						"memory_pressure":      "7m > 5m threshold",
						"degraded_performance": "6m > 5m threshold",
					},
				},
				EvaluatedAt: time.Now(),
			})

			// Act: Evaluate natural language condition
			result, err := conditionEvaluator.EvaluateCustomCondition(ctx, condition, stepContext)

			// **Business Requirement BR-COND-001**: Validate NLP condition evaluation
			Expect(err).ToNot(HaveOccurred(), "Should process natural language conditions")
			Expect(result.Confidence).To(BeNumerically(">=", 0.8),
				"BR-COND-001: Natural language processing should maintain high confidence")

			// **Business Value Validation**: Verify contextual understanding
			contextUnderstanding, exists := result.Metadata["context_understanding"]
			Expect(exists).To(BeTrue(), "BR-COND-001: Should measure contextual understanding")
			Expect(contextUnderstanding).To(BeNumerically(">=", 0.8),
				"BR-COND-001: Contextual understanding should be strong (≥80%)")

			// Validate entity extraction
			entities, exists := result.Metadata["nlp_entities"]
			Expect(exists).To(BeTrue(), "BR-COND-001: Should extract entities from natural language")
			entityList, ok := entities.([]string)
			Expect(ok).To(BeTrue(), "BR-COND-001: Extracted entities should be structured")
			Expect(len(entityList)).To(BeNumerically(">=", 2),
				"BR-COND-001: Should extract multiple meaningful entities")
		})
	})

	// BR-COND-003: MUST handle temporal conditions with time-based evaluation
	Context("BR-COND-003: Temporal Condition Evaluation", func() {
		It("should evaluate time-based conditions with accurate temporal analysis", func() {
			// Arrange: Create temporal condition
			condition := &types.ConditionSpec{
				ID:          "TemporalMemoryLeakCondition",
				Type:        "temporal",
				Description: "memory_usage increased by more than 20% over the last 30 minutes",
				Parameters: map[string]interface{}{
					"expression":  "memory_usage increased by more than 20% over the last 30 minutes",
					"time_window": "30m",
					"trend_type":  "increasing",
					"threshold":   0.20,
				},
			}

			stepContext := &workflowtypes.StepContext{
				StepID:      "step-3",
				WorkflowID:  "workflow-temporal-check",
				ExecutionID: "exec-125",
				Variables: map[string]interface{}{
					"current_memory_usage": 78.5,
					"memory_usage_30m_ago": 62.0,
					"evaluation_time":      time.Now(),
					"memory_trend_data": []map[string]interface{}{
						{"timestamp": time.Now().Add(-30 * time.Minute), "value": 62.0},
						{"timestamp": time.Now().Add(-20 * time.Minute), "value": 68.5},
						{"timestamp": time.Now().Add(-10 * time.Minute), "value": 74.2},
						{"timestamp": time.Now(), "value": 78.5},
					},
				},
			}

			// Setup mock for temporal evaluation
			conditionEvaluator.SetConditionResult(&conditions.EvaluationResult{
				Result:     true,
				Confidence: 0.94,
				Reasoning:  "Memory usage increased from 62.0% to 78.5% over 30 minutes, representing a 26.6% increase (exceeds 20% threshold)",
				Metadata: map[string]interface{}{
					"temporal_analysis": map[string]interface{}{
						"start_value":     62.0,
						"end_value":       78.5,
						"percent_change":  26.6,
						"threshold_met":   true,
						"trend_direction": "increasing",
					},
					"time_window_accuracy": 0.98,
					"data_points_analyzed": 4,
				},
				EvaluatedAt: time.Now(),
			})

			// Act: Evaluate temporal condition
			result, err := conditionEvaluator.EvaluateTimeCondition(ctx, condition, stepContext)

			// **Business Requirement BR-COND-003**: Validate temporal evaluation
			Expect(err).ToNot(HaveOccurred(), "Should successfully evaluate temporal conditions")
			Expect(result.Confidence).To(BeNumerically(">=", 0.9),
				"BR-COND-003: Temporal analysis should have very high confidence (≥90%)")

			// **Business Value Validation**: Verify temporal analysis accuracy
			temporalAnalysis, exists := result.Metadata["temporal_analysis"]
			Expect(exists).To(BeTrue(), "BR-COND-003: Should provide detailed temporal analysis")

			analysis, ok := temporalAnalysis.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-COND-003: Temporal analysis should be structured")

			percentChange := analysis["percent_change"]
			Expect(percentChange).To(BeNumerically(">=", 20.0),
				"BR-COND-003: Should accurately calculate temporal changes")

			thresholdMet := analysis["threshold_met"]
			Expect(thresholdMet).To(BeTrue(),
				"BR-COND-003: Should correctly determine threshold satisfaction")

			// Validate time window accuracy
			timeWindowAccuracy, exists := result.Metadata["time_window_accuracy"]
			Expect(exists).To(BeTrue(), "BR-COND-003: Should measure time window accuracy")
			Expect(timeWindowAccuracy).To(BeNumerically(">=", 0.95),
				"BR-COND-003: Time window analysis should be highly accurate (≥95%)")
		})
	})

	// BR-COND-005: MUST provide condition evaluation confidence scoring
	Context("BR-COND-005: Confidence Scoring Framework", func() {
		It("should provide accurate confidence scoring with detailed confidence breakdown", func() {
			// Arrange: Create condition requiring confidence analysis
			condition := &types.ConditionSpec{
				ID:          "ConfidenceTestCondition",
				Type:        "metric",
				Description: "cpu_usage > threshold AND data_quality > 0.8",
				Parameters: map[string]interface{}{
					"expression":         "cpu_usage > threshold AND data_quality > 0.8",
					"confidence_factors": []string{"data_quality", "metric_freshness", "historical_accuracy"},
				},
			}

			stepContext := &workflowtypes.StepContext{
				Variables: map[string]interface{}{
					"cpu_usage":        85.5,
					"threshold":        80.0,
					"data_quality":     0.92,
					"metric_freshness": 0.88,
					"sample_size":      150,
				},
			}

			// Setup mock with detailed confidence breakdown
			conditionEvaluator.SetConditionResult(&conditions.EvaluationResult{
				Result:     true,
				Confidence: 0.89,
				Reasoning:  "High confidence based on excellent data quality (92%), good metric freshness (88%), and sufficient sample size (150 points)",
				Metadata: map[string]interface{}{
					"confidence_breakdown": map[string]interface{}{
						"data_quality_score":     0.92,
						"metric_freshness_score": 0.88,
						"sample_size_score":      0.90,
						"historical_accuracy":    0.87,
					},
					"confidence_calculation": "weighted_average(0.92*0.3 + 0.88*0.25 + 0.90*0.25 + 0.87*0.2) = 0.89",
					"uncertainty_sources":    []string{"minor metric staleness"},
				},
				EvaluatedAt: time.Now(),
			})

			// Act: Evaluate condition with confidence analysis
			result, err := conditionEvaluator.EvaluateMetricCondition(ctx, condition, stepContext)

			// **Business Requirement BR-COND-005**: Validate confidence scoring
			Expect(err).ToNot(HaveOccurred(), "Should successfully evaluate with confidence scoring")
			Expect(result.Confidence).To(BeNumerically(">=", 0.75),
				"BR-COND-005: Should meet minimum confidence threshold (≥75%)")
			Expect(result.Confidence).To(BeNumerically("<=", 1.0),
				"BR-COND-005: Confidence score should be valid (≤100%)")

			// **Business Value Validation**: Verify confidence breakdown
			confidenceBreakdown, exists := result.Metadata["confidence_breakdown"]
			Expect(exists).To(BeTrue(), "BR-COND-005: Should provide confidence breakdown")

			breakdown, ok := confidenceBreakdown.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-COND-005: Confidence breakdown should be structured")
			Expect(len(breakdown)).To(BeNumerically(">=", 3),
				"BR-COND-005: Should analyze multiple confidence factors")

			// Validate individual confidence factors
			for factorName, factorScore := range breakdown {
				score, ok := factorScore.(float64)
				Expect(ok).To(BeTrue(), "BR-COND-005: Confidence factors should be numeric")
				Expect(score).To(BeNumerically(">=", 0.0),
					"BR-COND-005: Factor %s should have valid score", factorName)
				Expect(score).To(BeNumerically("<=", 1.0),
					"BR-COND-005: Factor %s should have valid score", factorName)
			}

			// Verify uncertainty tracking
			uncertaintySources, exists := result.Metadata["uncertainty_sources"]
			Expect(exists).To(BeTrue(), "BR-COND-005: Should identify uncertainty sources")
			Expect(uncertaintySources).ToNot(BeEmpty(), "BR-COND-005: Should provide uncertainty source details")
		})
	})

	// BR-COND-006: MUST learn from condition evaluation outcomes to improve accuracy
	Context("BR-COND-006: Learning Integration Framework", func() {
		It("should track evaluation outcomes and improve accuracy through learning", func() {
			// Arrange: Create condition for learning analysis
			condition := &types.ConditionSpec{
				ID:          "LearningCondition",
				Type:        "adaptive",
				Description: "error_rate > dynamic_threshold",
				Parameters: map[string]interface{}{
					"expression":             "error_rate > dynamic_threshold",
					"learning_enabled":       true,
					"historical_evaluations": 25,
				},
			}

			stepContext := &workflowtypes.StepContext{
				Variables: map[string]interface{}{
					"error_rate":        0.08,
					"dynamic_threshold": 0.05,
					"previous_accuracy": 0.82,
				},
			}

			// Setup mock with learning integration
			conditionEvaluator.SetConditionResult(&conditions.EvaluationResult{
				Result:     true,
				Confidence: 0.91,
				Reasoning:  "Error rate (8%) exceeds learned dynamic threshold (5%), adjusted from historical accuracy of 82%",
				Metadata: map[string]interface{}{
					"learning_metrics": map[string]interface{}{
						"previous_accuracy":     0.82,
						"current_accuracy":      0.91,
						"accuracy_improvement":  0.09,
						"evaluations_analyzed":  25,
						"threshold_adjustments": 3,
					},
					"adaptive_parameters": map[string]interface{}{
						"original_threshold": 0.03,
						"learned_threshold":  0.05,
						"adjustment_reason":  "false_positive_reduction",
					},
					"learning_confidence": 0.88,
				},
				EvaluatedAt: time.Now(),
			})

			// Act: Evaluate with learning integration
			result, err := conditionEvaluator.EvaluateCustomCondition(ctx, condition, stepContext)

			// **Business Requirement BR-COND-006**: Validate learning integration
			Expect(err).ToNot(HaveOccurred(), "Should successfully integrate learning")
			Expect(result.Confidence).To(BeNumerically(">", 0.82),
				"BR-COND-006: Learning should improve accuracy over baseline")

			// **Business Value Validation**: Verify learning metrics
			learningMetrics, exists := result.Metadata["learning_metrics"]
			Expect(exists).To(BeTrue(), "BR-COND-006: Should provide learning metrics")

			metrics, ok := learningMetrics.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-COND-006: Learning metrics should be structured")

			accuracyImprovement := metrics["accuracy_improvement"]
			Expect(accuracyImprovement).To(BeNumerically(">", 0),
				"BR-COND-006: Should demonstrate measurable accuracy improvement")

			// Validate adaptive parameters
			adaptiveParams, exists := result.Metadata["adaptive_parameters"]
			Expect(exists).To(BeTrue(), "BR-COND-006: Should track adaptive parameter changes")

			params, ok := adaptiveParams.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-COND-006: Adaptive parameters should be structured")
			Expect(params["adjustment_reason"]).ToNot(BeEmpty(),
				"BR-COND-006: Should provide reasons for parameter adjustments")

			// **BR-COND-010**: Validate performance optimization through learning
			evaluationsAnalyzed := metrics["evaluations_analyzed"]
			Expect(evaluationsAnalyzed).To(BeNumerically(">=", 20),
				"BR-COND-010: Should analyze sufficient historical evaluations for optimization")
		})
	})

	// BR-COND-011: MUST track condition evaluation accuracy rates
	Context("BR-COND-011: Accuracy Rate Tracking", func() {
		It("should track and report condition evaluation accuracy rates with trend analysis", func() {
			// Arrange: Create accuracy tracking scenario
			condition := &types.ConditionSpec{
				ID:          "AccuracyTrackingCondition",
				Type:        "monitored",
				Description: "response_time > sla_threshold",
				Parameters: map[string]interface{}{
					"expression":       "response_time > sla_threshold",
					"tracking_enabled": true,
					"evaluation_count": 100,
				},
			}

			stepContext := &workflowtypes.StepContext{
				Variables: map[string]interface{}{
					"response_time": 1200.0,
					"sla_threshold": 1000.0,
				},
			}

			// Setup mock with accuracy tracking
			conditionEvaluator.SetConditionResult(&conditions.EvaluationResult{
				Result:     true,
				Confidence: 0.93,
				Reasoning:  "Response time (1200ms) exceeds SLA threshold (1000ms) with high accuracy confidence",
				Metadata: map[string]interface{}{
					"accuracy_metrics": map[string]interface{}{
						"current_accuracy_rate": 0.93,
						"7_day_accuracy_rate":   0.91,
						"30_day_accuracy_rate":  0.89,
						"total_evaluations":     100,
						"correct_predictions":   93,
						"false_positives":       4,
						"false_negatives":       3,
					},
					"accuracy_trends": map[string]interface{}{
						"trend_direction":  "improving",
						"improvement_rate": 0.02,
						"stability_score":  0.87,
					},
					"performance_baseline": 0.85,
				},
				EvaluatedAt: time.Now(),
			})

			// Act: Evaluate with accuracy tracking
			result, err := conditionEvaluator.EvaluateMetricCondition(ctx, condition, stepContext)

			// **Business Requirement BR-COND-011**: Validate accuracy tracking
			Expect(err).ToNot(HaveOccurred(), "Should successfully track accuracy rates")

			// **Business Value Validation**: Verify accuracy metrics
			accuracyMetrics, exists := result.Metadata["accuracy_metrics"]
			Expect(exists).To(BeTrue(), "BR-COND-011: Should provide accuracy metrics")

			metrics, ok := accuracyMetrics.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-COND-011: Accuracy metrics should be structured")

			currentAccuracy := metrics["current_accuracy_rate"]
			Expect(currentAccuracy).To(BeNumerically(">=", 0.85),
				"BR-COND-011: Current accuracy should meet baseline (≥85%)")

			totalEvaluations := metrics["total_evaluations"]
			Expect(totalEvaluations).To(BeNumerically(">=", 50),
				"BR-COND-011: Should have sufficient evaluations for statistical significance")

			// **BR-COND-014**: Validate performance baseline comparison
			performanceBaseline, exists := result.Metadata["performance_baseline"]
			Expect(exists).To(BeTrue(), "BR-COND-014: Should maintain performance baseline")
			Expect(currentAccuracy).To(BeNumerically(">=", performanceBaseline),
				"BR-COND-014: Current performance should meet or exceed baseline")

			// Validate trend analysis
			accuracyTrends, exists := result.Metadata["accuracy_trends"]
			Expect(exists).To(BeTrue(), "BR-COND-011: Should provide accuracy trend analysis")

			trends, ok := accuracyTrends.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-COND-011: Trend analysis should be structured")
			Expect(trends["trend_direction"]).ToNot(BeEmpty(),
				"BR-COND-011: Should identify accuracy trend direction")
		})
	})
})
