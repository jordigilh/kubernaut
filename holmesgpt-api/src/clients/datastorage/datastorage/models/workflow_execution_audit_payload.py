# coding: utf-8

"""
    Data Storage Service API

    Data Storage Service provides REST API access to audit trail persistence.  **Business Requirements**: - BR-STORAGE-001 to BR-STORAGE-020: Audit write API - BR-STORAGE-021: Incident query API (READ) - BR-STORAGE-024: RFC 7807 error responses - BR-AUDIT-006: Legal hold capability (SOC2 Gap #8)  **Design Decisions**: - ADR-031: OpenAPI 3.0+ specification for all stateless REST APIs - ADR-032: Data Access Layer Isolation (only Data Storage connects to PostgreSQL) - DD-009: Dead Letter Queue fallback on database errors - DD-AUTH-004: OAuth-proxy sidecar for authentication/authorization - DD-AUTH-005: Client authentication pattern (ServiceAccount tokens)  **Architecture**: This service is the **ONLY** service that directly accesses PostgreSQL. All other services (Context API, Effectiveness Monitor, etc.) access data through this REST API Gateway.  **Authentication & Authorization (Production/E2E)**: All requests to DataStorage are protected by an OAuth-proxy sidecar:  1. **Client Authentication**: Services authenticate with Kubernetes ServiceAccount tokens    - Token mounted at: `/var/run/secrets/kubernetes.io/serviceaccount/token`    - Clients inject: `Authorization: Bearer <token>` header    - See DD-AUTH-005 for client implementation patterns  2. **OAuth-Proxy Validation**: The sidecar validates requests    - Validates JWT token signature and expiration    - Performs Subject Access Review (SAR) to check RBAC permissions    - Injects `X-Auth-Request-User` header with authenticated user identity    - Returns HTTP 401 if token invalid, HTTP 403 if SAR fails  3. **Handler Enforcement**: DataStorage handlers extract user identity    - Legal hold operations REQUIRE `X-Auth-Request-User` header    - HTTP 401 returned if header missing (authentication failed)    - User identity stored in audit events for SOC2 compliance  **Routing Flow**: ``` Client → data-storage-service:8080 (Service)        ↓      oauth-proxy:8080 (validates token + SAR)        ↓      DataStorage:8081 (X-Auth-Request-User header) ```  **Integration Tests**: Integration tests run without oauth-proxy. Use `testutil.NewMockUserTransport()` to inject mock `X-Auth-Request-User` headers directly.  **SOC2 Compliance**: - All legal hold operations attributed to authenticated users - Audit trail captures placed_by/released_by from X-Auth-Request-User - Unauthorized access blocked at oauth-proxy layer (defense-in-depth) 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import Any, ClassVar, Dict, List, Optional
from pydantic import BaseModel, StrictStr, field_validator
from pydantic import Field
from datastorage.models.error_details import ErrorDetails
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class WorkflowExecutionAuditPayload(BaseModel):
    """
    Type-safe audit event payload for WorkflowExecution (workflow.started, workflow.completed, workflow.failed)
    """ # noqa: E501
    event_type: StrictStr = Field(description="Event type for discriminator (matches parent event_type). Per ADR-034 v1.5, all WorkflowExecution events use 'workflowexecution' prefix.")
    workflow_id: StrictStr = Field(description="ID of the workflow being executed")
    workflow_version: StrictStr = Field(description="Version of the workflow being executed")
    target_resource: StrictStr = Field(description="Kubernetes resource being acted upon (format depends on scope)")
    phase: StrictStr = Field(description="Current phase of the WorkflowExecution")
    container_image: StrictStr = Field(description="Tekton PipelineRun container image")
    execution_name: StrictStr = Field(description="Name of the WorkflowExecution CRD")
    started_at: Optional[datetime] = Field(default=None, description="When the PipelineRun started execution")
    completed_at: Optional[datetime] = Field(default=None, description="When the PipelineRun finished (success or failure)")
    duration: Optional[StrictStr] = Field(default=None, description="Human-readable execution duration")
    failure_reason: Optional[StrictStr] = Field(default=None, description="Categorized failure reason")
    failure_message: Optional[StrictStr] = Field(default=None, description="Detailed failure message from Tekton")
    failed_task_name: Optional[StrictStr] = Field(default=None, description="Name of the failed TaskRun (if identified)")
    error_details: Optional[ErrorDetails] = None
    pipelinerun_name: Optional[StrictStr] = Field(default=None, description="Name of the associated Tekton PipelineRun")
    __properties: ClassVar[List[str]] = ["event_type", "workflow_id", "workflow_version", "target_resource", "phase", "container_image", "execution_name", "started_at", "completed_at", "duration", "failure_reason", "failure_message", "failed_task_name", "error_details", "pipelinerun_name"]

    @field_validator('event_type')
    def event_type_validate_enum(cls, value):
        """Validates the enum"""
        if value not in ('workflowexecution.workflow.started', 'workflowexecution.workflow.completed', 'workflowexecution.workflow.failed', 'workflowexecution.selection.completed', 'workflowexecution.execution.started'):
            raise ValueError("must be one of enum values ('workflowexecution.workflow.started', 'workflowexecution.workflow.completed', 'workflowexecution.workflow.failed', 'workflowexecution.selection.completed', 'workflowexecution.execution.started')")
        return value

    @field_validator('phase')
    def phase_validate_enum(cls, value):
        """Validates the enum"""
        if value not in ('Pending', 'Running', 'Completed', 'Failed'):
            raise ValueError("must be one of enum values ('Pending', 'Running', 'Completed', 'Failed')")
        return value

    @field_validator('failure_reason')
    def failure_reason_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in ('OOMKilled', 'DeadlineExceeded', 'Forbidden', 'ImagePullBackOff', 'ConfigurationError', 'ResourceExhausted', 'TaskFailed', 'Unknown'):
            raise ValueError("must be one of enum values ('OOMKilled', 'DeadlineExceeded', 'Forbidden', 'ImagePullBackOff', 'ConfigurationError', 'ResourceExhausted', 'TaskFailed', 'Unknown')")
        return value

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of WorkflowExecutionAuditPayload from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of error_details
        if self.error_details:
            _dict['error_details'] = self.error_details.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of WorkflowExecutionAuditPayload from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "event_type": obj.get("event_type"),
            "workflow_id": obj.get("workflow_id"),
            "workflow_version": obj.get("workflow_version"),
            "target_resource": obj.get("target_resource"),
            "phase": obj.get("phase"),
            "container_image": obj.get("container_image"),
            "execution_name": obj.get("execution_name"),
            "started_at": obj.get("started_at"),
            "completed_at": obj.get("completed_at"),
            "duration": obj.get("duration"),
            "failure_reason": obj.get("failure_reason"),
            "failure_message": obj.get("failure_message"),
            "failed_task_name": obj.get("failed_task_name"),
            "error_details": ErrorDetails.from_dict(obj.get("error_details")) if obj.get("error_details") is not None else None,
            "pipelinerun_name": obj.get("pipelinerun_name")
        })
        return _obj


