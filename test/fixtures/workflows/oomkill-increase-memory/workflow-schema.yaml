# OOMKill Increase Memory Workflow Schema (BR-WORKFLOW-004)
# Used by: AIAnalysis E2E, HolmesGPT-API E2E
metadata:
  workflowId: oomkill-increase-memory-v1
  version: "1.0.0"
  description:
    what: "Increases memory limits for pods experiencing OOMKill events"
    whenToUse: "When pods are OOMKilled due to insufficient memory limits"
    whenNotToUse: "When OOM is caused by a memory leak requiring code fix"
    preconditions: "Pod is managed by a Deployment or StatefulSet"

actionType: IncreaseMemoryLimits

labels:
  signalName: OOMKilled
  severity: [critical]
  environment: [production, staging, test]
  component: deployment
  priority: P1

execution:
  engine: tekton
  bundle: quay.io/kubernaut-cicd/test-workflows/placeholder-execution:v1.0.0@sha256:f313b9632f3a8d0ffd41150b12715a43a41c6c8e7871bb830fd82c09b5988cc4

parameters:
  - name: NAMESPACE
    type: string
    required: true
    description: "Target namespace containing the affected deployment"
  - name: DEPLOYMENT_NAME
    type: string
    required: true
    description: "Name of the deployment to update memory limits"
  - name: MEMORY_INCREASE_PERCENT
    type: integer
    required: false
    description: "Percentage to increase memory limits by"
    default: 25
    minimum: 10
    maximum: 100
