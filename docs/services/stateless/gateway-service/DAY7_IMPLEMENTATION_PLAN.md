# Gateway Service - Day 7 Implementation Plan

**Date**: October 22, 2025
**Status**: ğŸ¯ **READY TO START** - Days 1-6 Complete (114/116 tests passing)
**Focus**: Integration Testing + Production Readiness
**Estimated Duration**: 6-8 hours

---

## Executive Summary

Days 1-6 delivered **core Gateway functionality** with 98.3% test coverage. Day 7 focuses on **integration testing** and **production readiness** to validate the complete webhook-to-CRD flow with real infrastructure.

**Key Objectives**:
1. âœ… Complete K8s API failure integration tests (deferred from Day 6)
2. âœ… End-to-end webhook processing validation
3. âœ… Production readiness assessment
4. âœ… Performance baseline establishment

---

## Current State Assessment

### âœ… **What's Complete** (Days 1-6)

```
Core Functionality: 100% âœ…
â”œâ”€â”€ Signal Ingestion (Prometheus + K8s Events)
â”œâ”€â”€ Deduplication (Redis-backed, 5-min TTL)
â”œâ”€â”€ Storm Detection (10 alerts/min threshold)
â”œâ”€â”€ Validation (Fail-fast, early rejection)
â”œâ”€â”€ Classification (Namespace-based)
â”œâ”€â”€ Priority Assignment (Severity Ã— Environment matrix)
â””â”€â”€ CRD Creation (RemediationRequest)

Unit Tests: 114/116 passing (98.3%) âœ…
Integration Tests: 6 tests (Redis resilience + TTL) âœ…
E2E Tests: 0 tests â¸ï¸
```

### â¸ï¸ **What's Pending** (Day 7 Focus)

```
Integration Testing:
â”œâ”€â”€ âŒ K8s API failure scenarios (deferred from Day 6)
â”œâ”€â”€ âŒ Full webhook-to-CRD flow with real cluster
â”œâ”€â”€ âŒ Multi-adapter concurrent processing
â””â”€â”€ âŒ Storm aggregation end-to-end

Production Readiness:
â”œâ”€â”€ âŒ Performance baseline (latency, throughput)
â”œâ”€â”€ âŒ Resource limits validation
â”œâ”€â”€ âŒ Operational runbooks
â””â”€â”€ âŒ Deployment automation
```

---

## Day 7 Implementation Schedule

### **Phase 1: K8s API Failure Integration Tests** (2-3 hours)

#### **Objective**
Implement the K8s API failure integration tests that were deferred from Day 6.

#### **APDC Analysis** (30 min)

**Business Context**:
- **BR-GATEWAY-019**: Error handling must return 500 when K8s API unavailable
- **Business Value**: Prometheus automatic retry achieves eventual consistency

**Technical Context**:
- Existing: `CRDCreator` with error handling
- Existing: `Server` with error response formatting
- Missing: Integration tests with K8s API failure simulation

**Integration Points**:
- Real Kubernetes cluster (Kind or OCP)
- OR Error-injectable K8s client wrapper

**Complexity**: Medium (requires K8s cluster or mock infrastructure)

#### **APDC Plan** (30 min)

**TDD Strategy**:
1. **RED**: Write integration test for K8s API failure
2. **GREEN**: Verify existing error handling works
3. **REFACTOR**: Extract K8s client wrapper if needed

**Integration Approach**:
```go
// Option A: Error-injectable client wrapper
type ErrorInjectableClient struct {
    client.Client
    failCreate bool
    errorMsg   string
}

// Option B: Real K8s cluster with API manipulation
// Requires Kind cluster + network policy manipulation
```

**Success Criteria**:
- âœ… Test returns 500 when K8s API fails
- âœ… Test returns 201 when K8s API recovers
- âœ… Error message includes K8s context for debugging

#### **APDC Do** (1-1.5 hours)

**DO-RED** (30 min):
```bash
# Create integration test file
touch test/integration/gateway/k8s_api_failure_test.go

# Write failing tests:
# 1. Webhook returns 500 when K8s API unavailable
# 2. Webhook returns 201 when K8s API recovers
# 3. Error details include K8s context
# 4. Prometheus retry simulation
```

**DO-GREEN** (30 min):
```go
// Implement error-injectable K8s client
// OR
// Use existing CRDCreator with failing client

// Verify existing error handling works:
// - Server.handlePrometheusWebhook() returns 500
// - respondError() includes K8s error details
// - Metrics increment error counter
```

**DO-REFACTOR** (30 min):
```go
// Extract K8s client wrapper if duplication found
// Improve error messages for operational clarity
// Add structured logging for K8s failures
```

#### **APDC Check** (30 min)

**Validation**:
- âœ… All K8s API failure tests passing
- âœ… Error responses include actionable details
- âœ… Metrics correctly track K8s failures
- âœ… Documentation updated with test instructions

**Confidence Assessment**: Target 95%

---

### **Phase 2: End-to-End Webhook Flow** (2-3 hours)

#### **Objective**
Validate complete webhook-to-CRD flow with real Kubernetes cluster.

#### **APDC Analysis** (30 min)

**Business Context**:
- **BR-GATEWAY-001-015**: Complete signal processing pipeline
- **Business Value**: Confidence in production deployment

**Technical Context**:
- All components implemented and unit tested
- Integration: Webhook â†’ Adapter â†’ Deduplication â†’ Storm â†’ Classification â†’ Priority â†’ CRD
- Infrastructure: Requires Kind/OCP cluster + Redis

**Complexity**: Medium-High (full stack integration)

#### **APDC Plan** (30 min)

**Test Strategy**:
```
Test 1: Prometheus Alert â†’ CRD Creation
â”œâ”€â”€ Send Prometheus webhook
â”œâ”€â”€ Verify CRD created with correct fields
â”œâ”€â”€ Verify deduplication metadata in Redis
â””â”€â”€ Verify Prometheus metrics incremented

Test 2: Duplicate Alert â†’ 202 Accepted
â”œâ”€â”€ Send same alert twice
â”œâ”€â”€ First: 201 Created
â”œâ”€â”€ Second: 202 Accepted (duplicate)
â””â”€â”€ Verify single CRD, metadata updated

Test 3: Storm Detection â†’ Aggregation
â”œâ”€â”€ Send 15 alerts to same namespace
â”œâ”€â”€ Verify storm flag set in Redis
â”œâ”€â”€ Verify storm metadata returned
â””â”€â”€ Verify aggregation behavior

Test 4: Multi-Adapter Concurrent
â”œâ”€â”€ Send Prometheus + K8s Event webhooks concurrently
â”œâ”€â”€ Verify both create CRDs
â”œâ”€â”€ Verify no race conditions
â””â”€â”€ Verify metrics accurate
```

**Infrastructure**:
```bash
# Option A: Kind cluster (local)
kind create cluster --name gateway-integration

# Option B: OCP cluster (already available)
# Use existing kubernaut-system namespace
```

#### **APDC Do** (1-1.5 hours)

**DO-RED** (30 min):
```bash
# Create E2E test file
touch test/integration/gateway/webhook_e2e_test.go

# Write 4 failing tests (listed above)
```

**DO-GREEN** (45 min):
```bash
# Setup test infrastructure:
# - Port-forward to Redis (kubernaut-system)
# - Create test namespace
# - Deploy Gateway server (or run locally)

# Run tests, verify they pass
go test -v ./test/integration/gateway/webhook_e2e_test.go
```

**DO-REFACTOR** (15 min):
```go
// Extract common test setup (Redis, K8s client)
// Create test helper functions
// Improve test readability
```

#### **APDC Check** (30 min)

**Validation**:
- âœ… All 4 E2E tests passing
- âœ… CRDs created with correct structure
- âœ… Deduplication working end-to-end
- âœ… Storm detection working end-to-end
- âœ… Metrics accurate

**Confidence Assessment**: Target 90%

---

### **Phase 3: Production Readiness** (2 hours)

#### **Objective**
Establish performance baseline and create operational runbooks.

#### **Performance Baseline** (1 hour)

**Metrics to Establish**:
```
Latency (p50, p95, p99):
â”œâ”€â”€ Webhook processing time
â”œâ”€â”€ Redis operations
â”œâ”€â”€ K8s API calls
â””â”€â”€ End-to-end request time

Throughput:
â”œâ”€â”€ Requests per second (sustained)
â”œâ”€â”€ Concurrent webhook handling
â””â”€â”€ Storm handling capacity

Resource Usage:
â”œâ”€â”€ Memory (baseline, peak)
â”œâ”€â”€ CPU (baseline, peak)
â””â”€â”€ Redis connections
```

**Test Approach**:
```bash
# Simple load test with curl
for i in {1..100}; do
  curl -X POST http://localhost:8080/webhook/prometheus \
    -d @test/fixtures/prometheus_alert.json &
done
wait

# Analyze Prometheus metrics
# Check Gateway logs for latency
# Monitor resource usage
```

**Success Criteria**:
- âœ… p95 latency < 500ms
- âœ… Sustained 50 req/s
- âœ… Memory < 100MB baseline
- âœ… CPU < 50% baseline

#### **Operational Runbooks** (1 hour)

**Create Documentation**:
```
docs/services/stateless/gateway-service/operations/
â”œâ”€â”€ 01-deployment.md         # How to deploy Gateway
â”œâ”€â”€ 02-troubleshooting.md    # Common issues + fixes
â”œâ”€â”€ 03-rollback.md           # How to rollback
â”œâ”€â”€ 04-performance-tuning.md # Optimization guide
â””â”€â”€ 05-on-call-escalation.md # When to escalate
```

**Key Runbook Sections**:
1. **Deployment**: Makefile targets, environment variables, health checks
2. **Troubleshooting**: Redis connection failures, K8s API errors, high latency
3. **Rollback**: Safe rollback procedure, data migration considerations
4. **Performance**: Redis tuning, K8s resource limits, scaling guidelines
5. **Escalation**: SLA definitions, escalation paths, on-call contacts

---

## Day 7 Deliverables

### **Code Deliverables**

```
test/integration/gateway/
â”œâ”€â”€ k8s_api_failure_test.go      # K8s API failure scenarios (NEW)
â”œâ”€â”€ webhook_e2e_test.go          # End-to-end webhook flow (NEW)
â”œâ”€â”€ redis_resilience_test.go     # Existing Redis tests
â””â”€â”€ deduplication_ttl_test.go    # Existing TTL tests

pkg/gateway/
â””â”€â”€ (No new implementation files - validation only)
```

### **Documentation Deliverables**

```
docs/services/stateless/gateway-service/
â”œâ”€â”€ DAY7_COMPLETE.md                    # Day 7 summary (NEW)
â”œâ”€â”€ INTEGRATION_TESTS_COMPLETE.md       # Integration test summary (NEW)
â”œâ”€â”€ PERFORMANCE_BASELINE.md             # Performance metrics (NEW)
â””â”€â”€ operations/                         # Operational runbooks (NEW)
    â”œâ”€â”€ 01-deployment.md
    â”œâ”€â”€ 02-troubleshooting.md
    â”œâ”€â”€ 03-rollback.md
    â”œâ”€â”€ 04-performance-tuning.md
    â””â”€â”€ 05-on-call-escalation.md
```

---

## Success Criteria

### **Integration Tests**

- âœ… K8s API failure tests: 4-5 tests passing
- âœ… E2E webhook flow tests: 4 tests passing
- âœ… Total integration tests: 14-15 tests (6 existing + 8-9 new)

### **Performance**

- âœ… p95 latency < 500ms
- âœ… Sustained throughput > 50 req/s
- âœ… Memory usage < 100MB baseline
- âœ… CPU usage < 50% baseline

### **Documentation**

- âœ… 5 operational runbooks created
- âœ… Performance baseline documented
- âœ… Integration test README updated

### **Production Readiness**

- âœ… Integration tests passing
- âœ… Performance acceptable
- âœ… Operational runbooks complete
- âœ… Deployment automation working

---

## Risk Assessment

| Risk | Severity | Mitigation |
|------|----------|------------|
| **K8s cluster unavailable** | Medium | Use error-injectable mock for unit-style integration tests |
| **Redis unavailable** | Low | Already have OCP Redis, fallback to local Docker |
| **Performance below target** | Medium | Optimize hot paths, add caching, tune Redis |
| **Integration test flakiness** | Medium | Add retries, improve test isolation, use test fixtures |

---

## Confidence Assessment

**Day 7 Completion Confidence**: 90% âœ… **Very High**

**Justification**:
1. âœ… **Core functionality complete**: Days 1-6 provide solid foundation
2. âœ… **Infrastructure available**: OCP Redis, Kind/OCP clusters accessible
3. âœ… **Clear test strategy**: Well-defined integration test scenarios
4. âœ… **Operational focus**: Runbooks provide production confidence
5. âš ï¸ **Performance unknown**: Baseline needs establishment

**Risks**:
- âš ï¸ Performance may require optimization (mitigated by baseline + tuning)
- âš ï¸ Integration tests may be flaky (mitigated by retries + isolation)

---

## Next Steps After Day 7

### **Option 1: Advanced Features (Days 8-9)**

**Scope**:
- Rego policy integration (BR-GATEWAY-014)
- Namespace label reading (BR-GATEWAY-011-012)
- Remediation path decision matrix (BR-GATEWAY-022)
- Storm aggregation implementation

**Estimated Effort**: 2-3 days
**Business Value**: Enhanced customization

### **Option 2: Production Deployment**

**Scope**:
- Deploy to staging environment
- Monitor real-world performance
- Iterate on operational runbooks
- Establish SLAs

**Estimated Effort**: 1-2 days
**Business Value**: Production readiness

### **Option 3: E2E Testing**

**Scope**:
- Complete alert-to-remediation workflow
- Multi-cluster scenarios
- Load testing (1000+ req/s)
- Chaos testing

**Estimated Effort**: 2-3 days
**Business Value**: Production confidence

---

## Summary

**Day 7 Focus**: Integration Testing + Production Readiness

**Key Deliverables**:
1. âœ… K8s API failure integration tests (4-5 tests)
2. âœ… End-to-end webhook flow tests (4 tests)
3. âœ… Performance baseline established
4. âœ… Operational runbooks created (5 documents)

**Success Metrics**:
- Integration tests: 14-15 total (6 existing + 8-9 new)
- Performance: p95 < 500ms, 50+ req/s
- Documentation: 5 operational runbooks

**Production Readiness**: Target 85% (up from 70%)

---

**Status**: ğŸ¯ **READY TO START** - All prerequisites met, clear implementation path

**Recommendation**: Proceed with Day 7 implementation, focusing on integration testing first, then production readiness.

