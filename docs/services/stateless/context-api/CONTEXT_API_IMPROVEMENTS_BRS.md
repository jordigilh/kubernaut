# Context API Service - Improvement Business Requirements

**Date**: November 9, 2025
**Status**: üí° **PROPOSED FOR V1/V1.1/V2**
**Based On**: [HOLMESGPT_CONTEXT_API_ARCHITECTURE_IMPROVEMENTS.md](../../../../HOLMESGPT_CONTEXT_API_ARCHITECTURE_IMPROVEMENTS.md)
**Confidence**: 90-92% (all improvements ‚â•90% confidence)

---

## üìã Business Requirements Overview

| BR ID | Feature | Version | Priority | Effort | Impact |
|-------|---------|---------|----------|--------|--------|
| **BR-CONTEXT-011** | LLM-Friendly Context Summarization | V1 | P0 | 1-2 weeks | +8-12% success rate, -20-30% tokens |
| **BR-CONTEXT-012** | Context Quality Scoring | V1 | P0 | 2-3 weeks | +10-15% success rate, -20% false positives |
| **BR-CONTEXT-013** | Context Caching Strategy | V1 | P0 | 2-3 weeks | -40-50% latency, -60% load |
| **BR-CONTEXT-014** | Playbook Execution History Metadata | V1.1 | P1 | 2-3 weeks | +12-18% success rate, -30% false positives |
| **BR-CONTEXT-015** | Multi-Dimensional Context Queries | V1.1 | P1 | 2-3 weeks | +8-12% success rate, -25% env mismatches |
| **BR-CONTEXT-016** | Progressive Context Disclosure | V2 | P2 | 2-3 weeks | -30-40% cost |
| **BR-CONTEXT-017** | Historical Pattern Learning | V2 | P2 | 4-6 weeks | +3-5% success rate, -10-15% cost |

---

## üöÄ V1 Business Requirements (Core Foundation)

### BR-CONTEXT-011: LLM-Friendly Context Summarization

**Version**: V1
**Priority**: P0 (Critical - Quick Win)
**Confidence**: 90%
**Effort**: 1-2 weeks
**Dependencies**: None (additive feature)

#### Business Value
- **Token Reduction**: -20-30% (LLM doesn't need to parse/summarize JSON)
- **Latency Reduction**: -15-20% (faster LLM processing)
- **Success Rate**: +8-12% (better pattern recognition)
- **Cost Savings**: $511-$767/year (20-30% of $2,555/year LLM cost)

#### Functional Requirements

**FR-011.1**: Pre-compute Natural Language Summaries
- Context API SHALL generate human-readable summaries for each playbook result
- Summaries SHALL be template-based (not LLM-generated) for speed and cost
- Summaries SHALL include: execution count, success rate, environment analysis, failure analysis, recency, trend

**FR-011.2**: Key Insights Generation
- Context API SHALL generate 3-5 key insights per playbook
- Insights SHALL highlight: environment differences, recent successes/failures, trends, common failure reasons
- Insights SHALL use emoji indicators (‚ö†Ô∏è, ‚úÖ, üìà) for visual clarity

**FR-011.3**: Actionable Recommendations
- Context API SHALL generate 2-4 actionable recommendations per playbook
- Recommendations SHALL be specific (e.g., "increase timeout threshold for production")
- Recommendations SHALL be based on failure pattern analysis

#### Technical Requirements

**TR-011.1**: Response Format
```json
{
  "playbook": "restart-pod",
  "confidence": 0.91,
  "success_rate": 0.85,
  "executions": 120,
  "llm_summary": "This playbook has been executed 120 times with 85% success rate...",
  "key_insights": [
    "‚ö†Ô∏è Lower success rate in production (78%) vs staging (95%)",
    "‚úÖ Recently successful (last success: 1 day ago)"
  ],
  "recommendations": [
    "Consider increasing timeout threshold for production deployments"
  ]
}
```

**TR-011.2**: Performance
- Summary generation SHALL complete in <10ms per playbook
- Summaries SHALL be cached (5-minute TTL)
- No external LLM calls for summary generation

#### Success Criteria
- [ ] Token usage reduced by 20-30% (measured over 30 days)
- [ ] LLM processing time reduced by 15-20%
- [ ] Pattern detection accuracy improved by 10-15%
- [ ] No performance degradation (<10ms overhead)

#### Risk Mitigation
- **Low Risk**: Additive field (doesn't change existing data)
- **Rollback**: Can disable summarization without code changes
- **Validation**: A/B test with 10% traffic before full rollout

---

### BR-CONTEXT-012: Context Quality Scoring

**Version**: V1
**Priority**: P0 (Critical - High Impact)
**Confidence**: 92%
**Effort**: 2-3 weeks
**Dependencies**: None (additive feature)

#### Business Value
- **Success Rate**: +10-15% (prevents poor decisions from low-quality data)
- **False Positives**: -20% (filters unreliable recommendations)
- **Manual Review Rate**: +5% (appropriate escalation when data insufficient)

#### Functional Requirements

**FR-012.1**: Quality Score Calculation
- Context API SHALL calculate quality score (0.0-1.0) for each playbook result
- Quality score SHALL be based on:
  - Sample size: >100 executions = 1.0, 50-100 = 0.8, 10-50 = 0.6, <10 = 0.3 (40% weight)
  - Recency: >80% last 30d = 1.0, >60% = 0.8, >40% = 0.6, <40% = 0.3 (30% weight)
  - Consistency: std_dev <0.1 = 1.0, <0.2 = 0.8, <0.3 = 0.6, >0.3 = 0.3 (20% weight)
  - Environment match: same cluster = 1.0, same region = 0.8, other = 0.5 (10% weight)

**FR-012.2**: Quality Factors Explanation
- Context API SHALL provide quality_factors explaining score breakdown
- Factors SHALL include: sample_size (excellent/good/fair/poor), recency, consistency, environment_match

**FR-012.3**: Quality-Based Filtering
- Context API SHALL support min_quality_score parameter (default: 0.6)
- Context API SHALL return warning when no results meet quality threshold
- Context API SHALL recommend manual review when data quality insufficient

#### Technical Requirements

**TR-012.1**: Response Format
```json
{
  "playbook": "restart-pod",
  "confidence": 0.91,
  "success_rate": 0.85,
  "executions": 120,
  "quality_score": 0.95,
  "quality_factors": {
    "sample_size": "excellent",
    "recency": "good",
    "consistency": "excellent",
    "environment_match": "high"
  }
}
```

**TR-012.2**: Performance
- Quality score calculation SHALL complete in <5ms per playbook
- Quality scores SHALL be cached (5-minute TTL)

#### Success Criteria
- [ ] Success rate improved by 10-15% (measured over 30 days)
- [ ] False positives reduced by 20%
- [ ] Manual review rate increased by 5% (appropriate escalation)
- [ ] LLM tool call behavior changes tracked (quality-aware decisions)

#### Risk Mitigation
- **Low Risk**: Additive feature with conservative thresholds
- **A/B Testing**: 10% traffic before full rollout
- **Monitoring**: Track LLM behavior changes (tool call rate, confidence scores)

---

### BR-CONTEXT-012: Context Caching Strategy

**Version**: V1
**Priority**: P0 (Critical - Latency Improvement)
**Confidence**: 92%
**Effort**: 2-3 weeks
**Dependencies**: Redis infrastructure (already available)

#### Business Value
- **Latency Reduction**: 40-50% overall (60% cache hit rate)
- **Context API Load**: -60% (fewer database queries)
- **Cost Reduction**: -20% (reduced infrastructure costs)

#### Functional Requirements

**FR-013.1**: Multi-Level Caching
- Context API SHALL implement 3-level caching:
  - Level 1: HolmesGPT API session cache (in-memory, 5-minute TTL)
  - Level 2: Context API Redis cache (distributed, 15-minute TTL)
  - Level 3: Semantic similarity cache (for similar alerts, 15-minute TTL)

**FR-013.2**: Cache Invalidation (Integrates with Effectiveness Monitor)
- Context API SHALL listen for remediation completion events from Effectiveness Monitor Service
- Context API SHALL invalidate cache when new remediation data added to `remediation_audit` table
- Context API SHALL invalidate semantic similarity cache (distance < 0.1)
- Context API SHALL support manual cache invalidation via API

**Integration with V1 Effectiveness Monitor**:
- Effectiveness Monitor Service (V1) already tracks remediation outcomes
- Effectiveness Monitor writes to `effectiveness_results` table
- Data Storage Service writes to `remediation_audit` table
- Context API SHALL subscribe to database change notifications (PostgreSQL NOTIFY/LISTEN) or poll for new data

**FR-013.3**: Cache Metrics
- Context API SHALL expose cache hit rate metrics
- Context API SHALL track cache miss reasons (expired, not found, invalidated)

#### Technical Requirements

**TR-013.1**: Redis Cache Implementation
```go
// Cache key format
cacheKey := fmt.Sprintf("context:%s:%.2f", alertFingerprint, threshold)

// Cache TTL
cacheTTL := 15 * time.Minute

// Cache invalidation pattern
invalidatePattern := fmt.Sprintf("context:%s:*", alertFingerprint)
```

**TR-013.2**: Performance
- Cache lookup SHALL complete in <5ms (p95)
- Cache hit rate SHALL be >60% after 1 week
- Cache invalidation SHALL complete in <10ms

#### Success Criteria
- [ ] Latency reduced by 40-50% (measured over 30 days)
- [ ] Cache hit rate >60%
- [ ] Context API load reduced by 60%
- [ ] No stale data incidents (cache invalidation working)

#### Risk Mitigation
- **Very Low Risk**: Cache misses fall back to database
- **Gradual Rollout**: Start with short TTL (5 minutes), increase gradually
- **Monitoring**: Track cache hit rate and stale data incidents

---

## üîÑ V1.1 Business Requirements (Advanced Features)

### BR-CONTEXT-014: Playbook Execution History Metadata

**Version**: V1.1
**Priority**: P1 (High Impact)
**Confidence**: 91%
**Effort**: 2-3 weeks
**Dependencies**: BR-CONTEXT-011 (summarization), BR-CONTEXT-012 (quality scoring)

#### Business Value
- **Success Rate**: +12-18% (LLM avoids recently-failed or degrading playbooks)
- **False Positives**: -30% (LLM detects environment-specific failures)
- **LLM Reasoning Quality**: +20% (richer context for decision-making)

#### Functional Requirements

**FR-014.1**: Temporal Metadata
- Context API SHALL provide last_success and last_failure timestamps
- Context API SHALL calculate recent_trend (improving/stable/degrading)
- Context API SHALL compare last 30 days vs previous 30 days for trend

**FR-014.2**: Failure Pattern Analysis
- Context API SHALL provide environment-specific success rates (production vs staging)
- Context API SHALL identify common failure reasons with percentages
- Context API SHALL rank failure reasons by frequency

**FR-014.3**: Environmental Changes Tracking
- Context API SHALL detect recent environmental changes (Kubernetes upgrades, config changes)
- Context API SHALL correlate changes with success rate trends
- Context API SHALL provide change dates and descriptions

#### Technical Requirements

**TR-014.1**: Response Format
```json
{
  "playbook": "restart-pod",
  "execution_history": {
    "last_success": "2025-11-08T14:30:00Z",
    "last_failure": "2025-11-01T09:15:00Z",
    "recent_trend": "improving",
    "failure_pattern": {
      "production_success_rate": 0.78,
      "staging_success_rate": 0.95,
      "common_failure_reasons": [
        {"reason": "timeout", "percentage": 0.60},
        {"reason": "OOMKilled", "percentage": 0.30}
      ]
    },
    "recent_changes": [
      {"date": "2025-11-05", "change": "Kubernetes upgraded to 1.28"}
    ]
  }
}
```

**TR-014.2**: Performance
- History metadata calculation SHALL complete in <20ms per playbook
- Metadata SHALL be cached (15-minute TTL)

#### Success Criteria
- [ ] Success rate improved by 12-18%
- [ ] False positives reduced by 30%
- [ ] LLM playbook selection accuracy improved by 13%
- [ ] Environment mismatch rate reduced by 67%

#### Risk Mitigation
- **Low Risk**: Additive metadata (doesn't change existing fields)
- **Validation**: Track LLM behavior changes (playbook selection accuracy)

---

### BR-CONTEXT-015: Multi-Dimensional Context Queries

**Version**: V1.1
**Priority**: P1 (Environment Filtering)
**Confidence**: 90%
**Effort**: 2-3 weeks
**Dependencies**: None (additive filters)

#### Business Value
- **Success Rate**: +8-12% (more relevant historical data)
- **False Positives**: -25% (avoid dev/staging playbooks in production)
- **LLM Confidence**: +10% (higher quality context)

#### Functional Requirements

**FR-015.1**: Multi-Dimensional Filters
- Context API SHALL support environment filter (production/staging/dev)
- Context API SHALL support cluster filter (specific cluster name)
- Context API SHALL support namespace filter (specific namespace)
- Context API SHALL support time_range filter (last_7d/last_30d/last_90d)

**FR-015.2**: Filter Combinations
- Context API SHALL support multiple filters simultaneously
- Context API SHALL validate filter combinations (e.g., production + specific cluster)
- Context API SHALL return empty results with explanation when filters too restrictive

**FR-015.3**: Backward Compatibility
- All filters SHALL be optional (default: no filters = all results)
- Context API SHALL maintain backward compatibility with existing clients

#### Technical Requirements

**TR-015.1**: Query Parameters
```
GET /api/v1/context/enrich?alert_fingerprint=X&threshold=0.70&environment=production&cluster=prod-us-east-1&namespace=api-services&time_range=last_30d
```

**TR-015.2**: SQL Implementation
```sql
SELECT * FROM remediation_audit
WHERE
    embedding <-> $1 < $2  -- Semantic similarity
    AND environment = $3   -- Environment filter
    AND cluster = $4       -- Cluster filter
    AND namespace = $5     -- Namespace filter
    AND completed_at > $6  -- Time range filter
ORDER BY similarity ASC
LIMIT 10
```

**TR-015.3**: Performance
- Filtered queries SHALL complete in <200ms (p95)
- Indexes SHALL be added for filter columns (environment, cluster, namespace)

#### Success Criteria
- [ ] Success rate improved by 8-12%
- [ ] False positives reduced by 25%
- [ ] Production success rate 10-15% higher than non-production
- [ ] LLM confidence improved by 10%

#### Risk Mitigation
- **Low Risk**: Optional filters (backward compatible)
- **Validation**: Monitor query performance with filters
- **Indexing**: Add database indexes before enabling filters

---

## üîÆ V2 Business Requirements (Advanced Optimization)

**Note**: V1 already includes **real-time feedback loop** via Effectiveness Monitor Service. V2 focuses on advanced cost optimization and adaptive learning.

### BR-CONTEXT-016: Progressive Context Disclosure

**Version**: V2
**Priority**: P2 (Cost Optimization)
**Confidence**: 85%
**Effort**: 2-3 weeks
**Dependencies**: BR-CONTEXT-011 (summarization)

#### Business Value
- **Cost Reduction**: -30-40% (most investigations use summary only)
- **Latency Reduction**: -200-300ms (summary is faster to generate)
- **Success Rate**: +5% (LLM makes better decisions with progressive disclosure)

#### Functional Requirements

**FR-016.1**: Two-Stage Context Retrieval
- Context API SHALL provide lightweight summary endpoint (GET /api/v1/context/summary)
- Context API SHALL provide full details endpoint (GET /api/v1/context/details)
- HolmesGPT API SHALL expose two LLM tools: get_context_summary, get_context_details

**FR-016.2**: Summary-Based Recommendations
- Summary SHALL include recommendation field (request_full_context / sufficient_for_decision)
- Summary SHALL include data_quality indicator (high/medium/low)
- Summary SHALL include similar_incidents_count

**FR-016.3**: LLM Tool Descriptions
- get_context_summary tool SHALL be described as "fast, low cost, use FIRST"
- get_context_details tool SHALL be described as "use ONLY if summary indicates high-quality data"

#### Technical Requirements

**TR-016.1**: Summary Response Format (~100 tokens)
```json
{
  "context_summary": {
    "similar_incidents_count": 15,
    "top_playbook": "restart-pod",
    "top_success_rate": 0.85,
    "data_quality": "high",
    "recommendation": "request_full_context"
  }
}
```

**TR-016.2**: Performance
- Summary generation SHALL complete in <50ms (p95)
- Full details SHALL complete in <200ms (p95)

#### Success Criteria
- [ ] Cost reduced by 30-40%
- [ ] 70% of investigations use summary only
- [ ] Latency reduced by 200-300ms for summary-only investigations
- [ ] Success rate improved by 5%

#### Risk Mitigation
- **Medium Risk**: Requires HolmesGPT API changes
- **Validation**: A/B test with 10% traffic
- **Monitoring**: Track tool call patterns (summary vs details)

---

### BR-CONTEXT-017: Historical Pattern Learning

**Version**: V2
**Priority**: P2 (Long-Term Optimization)
**Confidence**: 80%
**Effort**: 4-6 weeks
**Dependencies**: 2-3 months of data collection

#### Business Value
- **Success Rate**: +3-5% (adaptive pre-enrichment)
- **Latency Reduction**: 20-30% for high-frequency alert types
- **Cost Reduction**: -10-15% (reduce tool call overhead)

#### Functional Requirements

**FR-017.1**: LLM Tool Call Pattern Tracking (Builds on V1 Effectiveness Monitor)
- Context API SHALL track tool call rate by alert type
- Context API SHALL track average tool calls per investigation
- Context API SHALL track success rate with/without context
- Context API SHALL integrate with Effectiveness Monitor data for success rate correlation

**Integration with V1 Effectiveness Monitor**:
- Effectiveness Monitor already tracks remediation success rates
- BR-CONTEXT-017 extends this with LLM tool call pattern correlation
- Enables adaptive pre-enrichment based on learned patterns

**FR-017.2**: Adaptive Pre-Enrichment
- AIAnalysis Controller SHALL query pattern table before investigation
- AIAnalysis Controller SHALL pre-enrich when tool_call_rate > 80%
- AIAnalysis Controller SHALL pre-enrich when success_rate_delta > 15%

**FR-017.3**: Pattern Learning Table
```sql
CREATE TABLE llm_tool_call_patterns (
    alert_type VARCHAR(255),
    tool_call_rate FLOAT,
    avg_tool_calls INT,
    success_rate_with_context FLOAT,
    success_rate_without_context FLOAT,
    sample_size INT,
    last_updated TIMESTAMP
);
```

#### Technical Requirements

**TR-017.1**: Pattern Analysis
- Pattern analysis SHALL run every 24 hours
- Pattern analysis SHALL require minimum 50 samples per alert type
- Pattern analysis SHALL calculate tool_call_rate, success_rate_delta

**TR-017.2**: Performance
- Pattern query SHALL complete in <10ms
- Pre-enrichment decision SHALL complete in <5ms

#### Success Criteria
- [ ] Latency reduced by 20-30% for high-frequency alerts
- [ ] Cost reduced by 10-15%
- [ ] Success rate improved by 3-5%
- [ ] Requires 2-3 months of data collection

#### Risk Mitigation
- **Medium Risk**: Requires data collection period
- **Validation**: Start with conservative thresholds (tool_call_rate > 80%)
- **Monitoring**: Track pre-enrichment accuracy (was context actually used?)

---

## üìä Version Triage Summary

**Note**: V1 already includes **Effectiveness Monitor Service** for real-time feedback loop. These BRs extend Context API to leverage that data.

### V1 Scope (Core Foundation) - 6-8 weeks

**Goal**: Immediate impact with low risk, leveraging existing Effectiveness Monitor

| BR | Feature | Effort | Impact | Confidence |
|----|---------|--------|--------|------------|
| BR-CONTEXT-011 | LLM-Friendly Summarization | 1-2 weeks | +8-12% success, -20-30% tokens | 90% |
| BR-CONTEXT-012 | Context Quality Scoring | 2-3 weeks | +10-15% success, -20% false positives | 92% |
| BR-CONTEXT-013 | Context Caching Strategy | 2-3 weeks | -40-50% latency, -60% load | 92% |

**Total V1 Impact**: +18-27% success rate, -40-50% latency, -20-30% cost
**Total V1 Effort**: 6-8 weeks
**V1 ROI**: 67-87% in year 1

---

### V1.1 Scope (Advanced Features) - 4-6 weeks

**Goal**: Rich context and environment filtering

| BR | Feature | Effort | Impact | Confidence |
|----|---------|--------|--------|------------|
| BR-CONTEXT-014 | Playbook Execution History | 2-3 weeks | +12-18% success, -30% false positives | 91% |
| BR-CONTEXT-015 | Multi-Dimensional Queries | 2-3 weeks | +8-12% success, -25% env mismatches | 90% |

**Total V1.1 Impact**: +20-30% additional success rate
**Total V1.1 Effort**: 4-6 weeks
**V1.1 ROI**: 100%+ in year 2

---

### V2 Scope (Advanced Optimization) - 6-9 weeks

**Goal**: Cost optimization and adaptive learning

| BR | Feature | Effort | Impact | Confidence |
|----|---------|--------|--------|------------|
| BR-CONTEXT-016 | Progressive Context Disclosure | 2-3 weeks | -30-40% cost, +5% success | 85% |
| BR-CONTEXT-017 | Historical Pattern Learning | 4-6 weeks | +3-5% success, -10-15% cost | 80% |

**Total V2 Impact**: +8% success rate, -40-55% cost
**Total V2 Effort**: 6-9 weeks
**V2 ROI**: Requires 2-3 months of data collection

---

## üéØ Recommended Implementation Order

### Phase 1: V1 Core (Weeks 1-8)

**Week 1-2**: BR-CONTEXT-011 (LLM-Friendly Summarization)
- Lowest effort, immediate benefits
- -20-30% tokens, -15-20% latency

**Week 3-5**: BR-CONTEXT-012 (Context Quality Scoring)
- High impact on success rate
- +10-15% success rate, -20% false positives

**Week 6-8**: BR-CONTEXT-013 (Context Caching Strategy)
- Massive latency improvement
- -40-50% latency, -60% Context API load
- **Integrates with V1 Effectiveness Monitor** for cache invalidation

**V1 Milestone**: +18-27% success rate, -40-50% latency, -20-30% cost

**V1 Foundation**: Effectiveness Monitor Service already provides:
- ‚úÖ Real-time remediation outcome tracking
- ‚úÖ Success rate calculations
- ‚úÖ Effectiveness assessments
- ‚úÖ PostgreSQL storage (`effectiveness_results`, `remediation_audit`)
- ‚úÖ REST API for effectiveness data

---

### Phase 2: V1.1 Advanced (Weeks 9-14)

**Week 9-11**: BR-CONTEXT-014 (Playbook Execution History)
- Rich temporal context
- +12-18% success rate, -30% false positives

**Week 12-14**: BR-CONTEXT-015 (Multi-Dimensional Queries)
- Environment-specific filtering
- +8-12% success rate, -25% environment mismatches

**V1.1 Milestone**: +20-30% additional success rate

---

### Phase 3: V2 Optimization (Weeks 15-24)

**Week 15-17**: BR-CONTEXT-016 (Progressive Context Disclosure)
- Cost optimization
- -30-40% cost, +5% success rate

**Week 18-24**: BR-CONTEXT-017 (Historical Pattern Learning)
- Adaptive learning (requires 2-3 months data)
- +3-5% success rate, -10-15% cost

**V2 Milestone**: +8% success rate, -40-55% cost

---

## üí∞ Combined ROI Analysis

### Investment
- **V1 Development**: 6-8 weeks (~$40,000-$50,000)
- **V1.1 Development**: 4-6 weeks (~$25,000-$35,000)
- **V2 Development**: 6-9 weeks (~$35,000-$50,000)
- **Total Investment**: 16-23 weeks (~$100,000-$135,000)

### Returns (Annual)

**Success Rate Improvement**:
- Current: 70% (assumed)
- After V1: 88-97% (+18-27%)
- After V1.1: 108-127% (+38-57% total, accounting for overlap: **+30-40%**)
- After V2: 116-135% (+46-65% total, accounting for overlap: **+35-45%**)

**Cost Reduction**:
- Current LLM cost: $2,555/year
- After V1: $1,789-$2,044/year (-20-30%)
- After V1.1: $1,789-$2,044/year (no additional cost reduction)
- After V2: $1,022-$1,278/year (-50-60% total)

**Operational Savings**:
- Reduced manual interventions: 500 ‚Üí 75 per year
- **Savings**: 425 hours √ó $150/hour = **$63,750/year**

**Total Annual Savings**: **$64,027-$65,283/year**
**ROI**: **47-65%** in year 1, **100%+ in year 2**

---

## üìã Next Steps

1. **User Review**: Review and approve V1/V1.1/V2 triage
2. **Create ADR**: Document hybrid Context API strategy (tool calls + pre-enrichment)
3. **V1 Implementation**: Start with BR-CONTEXT-011 (LLM-Friendly Summarization)
4. **Monitoring Setup**: Establish metrics for success rate, latency, cost tracking
5. **V1.1 Planning**: Begin V1.1 planning after V1 validation (2-3 weeks)

---

**Document Version**: 1.0
**Last Updated**: November 9, 2025
**Status**: üí° **READY FOR USER REVIEW AND APPROVAL**

