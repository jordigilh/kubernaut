/*
Copyright 2025 Jordi Gil.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package gateway

import (
	"context"
	"fmt"
	"os"
	"strconv"
	"strings"
	"testing"
	"time"

	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"
	"go.uber.org/zap"

	"github.com/jordigilh/kubernaut/test/infrastructure"
)

// Suite-level resources for cleanup
var (
	suiteK8sClient *K8sTestClient  // Shared K8s client for cleanup
	suiteCtx       context.Context // Suite context
	suiteLogger    *zap.Logger     // Suite logger
	clusterName    string          // Cluster name
	kubeconfigPath string          // Kubeconfig path
	// suiteRedisPort is declared in helpers.go to be accessible by both test and non-test files
)

// SynchronizedBeforeSuite runs ONCE globally before all parallel processes start
// This ensures Kind cluster and Redis are created only once, not by each parallel process
var _ = SynchronizedBeforeSuite(func() []byte {
	// This runs ONCE on process 1 only - creates shared infrastructure
	var err error
	suiteLogger, err = zap.NewDevelopment()
	Expect(err).ToNot(HaveOccurred())

	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	suiteLogger.Info("Gateway Integration Test Suite - Infrastructure Setup (Parallel)")
	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	suiteLogger.Info("Creating Kind cluster + Redis for integration tests...")
	suiteLogger.Info("  â€¢ Kind cluster (2 nodes: control-plane + worker)")
	suiteLogger.Info("  â€¢ RemediationRequest CRD (cluster-wide)")
	suiteLogger.Info("  â€¢ Redis container (localhost:6379)")
	suiteLogger.Info("  â€¢ Kubeconfig: ~/.kube/gateway-kubeconfig")
	suiteLogger.Info("  â€¢ Parallel Execution: 4 concurrent processors")
	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// Set cluster configuration
	clusterName = "gateway-integration"
	homeDir, err := os.UserHomeDir()
	Expect(err).ToNot(HaveOccurred())
	kubeconfigPath = fmt.Sprintf("%s/.kube/gateway-kubeconfig", homeDir)

	// Create Kind cluster for integration tests (no Gateway image build needed)
	err = infrastructure.CreateIntegrationCluster(clusterName, kubeconfigPath, GinkgoWriter)
	Expect(err).ToNot(HaveOccurred())

	// Start Redis container for integration tests (with cleanup first)
	suiteLogger.Info("Cleaning up existing Redis container...")
	_ = infrastructure.StopRedisContainer("redis-integration", GinkgoWriter)

	// Wait for port to be released after container stop
	time.Sleep(2 * time.Second)

	// Use port 0 to get a random available port (prevents conflicts with Data Storage tests)
	suiteLogger.Info("Starting Redis container on random available port...")
	redisPort, err := infrastructure.StartRedisContainer("redis-integration", 0, GinkgoWriter)
	Expect(err).ToNot(HaveOccurred(), "Redis container must start for integration tests")
	suiteLogger.Info(fmt.Sprintf("âœ… Redis running on port: %d", redisPort))

	// Store Redis port for all parallel processes to use
	suiteRedisPort = redisPort

	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	suiteLogger.Info("Infrastructure Setup Complete - Ready for Parallel Tests")
	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// Return kubeconfig path AND Redis port to all parallel processes
	// Format: "kubeconfigPath:redisPort"
	setupData := fmt.Sprintf("%s:%d", kubeconfigPath, redisPort)
	return []byte(setupData)
}, func(data []byte) {
	// This runs on ALL processes (including process 1) - initializes per-process state
	suiteCtx = context.Background()

	// Initialize logger for this process
	var err error
	suiteLogger, err = zap.NewDevelopment()
	Expect(err).ToNot(HaveOccurred())

	// Parse kubeconfig path AND Redis port from process 1
	// Format: "kubeconfigPath:redisPort"
	setupData := string(data)
	parts := strings.Split(setupData, ":")
	Expect(len(parts)).To(Equal(2), "Setup data should contain kubeconfig:port")

	kubeconfigPath = parts[0]
	redisPortStr := parts[1]
	redisPort, err := strconv.Atoi(redisPortStr)
	Expect(err).ToNot(HaveOccurred(), "Redis port should be a valid integer")
	suiteRedisPort = redisPort

	suiteLogger.Info(fmt.Sprintf("Process %d initialized with Redis port: %d", GinkgoParallelProcess(), suiteRedisPort))
	clusterName = "gateway-integration"

	// Set KUBECONFIG environment variable for this process
	err = os.Setenv("KUBECONFIG", kubeconfigPath)
	Expect(err).ToNot(HaveOccurred())

	// Initialize K8s client for this process
	suiteK8sClient = SetupK8sTestClient(suiteCtx)
	Expect(suiteK8sClient).ToNot(BeNil(), "Failed to setup K8s client for suite")

	// Ensure kubernaut-system namespace exists for fallback tests
	EnsureTestNamespace(suiteCtx, suiteK8sClient, "kubernaut-system")
})

// SynchronizedAfterSuite runs cleanup in two phases for parallel execution
var _ = SynchronizedAfterSuite(func() {
	// This runs on ALL processes - ONLY cleanup per-process K8s client
	// DO NOT delete namespaces here - causes race condition with other processes
	if suiteK8sClient != nil {
		suiteK8sClient.Cleanup(suiteCtx)
	}
}, func() {
	// This runs ONCE on process 1 only - cleanup ALL resources AFTER all processes finish
	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	suiteLogger.Info("Gateway Integration Test Suite - Infrastructure Teardown")
	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// CRITICAL FIX: Wait longer for all parallel processes to finish their cleanup
	// With 4 parallel processes, some tests may still be running when the first process finishes
	// We need to ensure ALL tests have completed their AfterEach blocks before deleting namespaces
	suiteLogger.Info("Waiting for all parallel processes to finish cleanup...")
	time.Sleep(10 * time.Second) // Increased from 5s to 10s for more reliable cleanup

	// Collect ALL test namespaces from ALL processes
	testNamespacesMutex.Lock()
	namespaceCount := len(testNamespaces)
	namespaceList := make([]string, 0, namespaceCount)
	for ns := range testNamespaces {
		namespaceList = append(namespaceList, ns)
	}
	testNamespacesMutex.Unlock()

	// CRITICAL FIX: Don't delete namespaces during test run
	// Deleting namespaces causes "namespace is being terminated" errors
	// when parallel tests are still running. Let Kind cluster deletion handle cleanup.
	if namespaceCount > 0 {
		fmt.Printf("\nğŸ“ %d test namespaces will be cleaned up with Kind cluster deletion\n", namespaceCount)
		fmt.Println("   (Skipping namespace deletion to prevent 'namespace is being terminated' errors)")
	} else {
		fmt.Println("\nâœ… No test namespaces created")
	}

	// Stop Redis container
	suiteLogger.Info("Stopping Redis container...")
	err := infrastructure.StopRedisContainer("redis-integration", GinkgoWriter)
	if err != nil {
		suiteLogger.Warn("Failed to stop Redis container", zap.Error(err))
	}

	// Delete Kind cluster
	suiteLogger.Info("Deleting Kind cluster...")
	err = infrastructure.DeleteGatewayCluster(clusterName, kubeconfigPath, GinkgoWriter)
	if err != nil {
		suiteLogger.Warn("Failed to delete cluster", zap.Error(err))
	}

	// Sync logger
	if suiteLogger != nil {
		_ = suiteLogger.Sync()
	}

	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	suiteLogger.Info("Infrastructure Teardown Complete")
	suiteLogger.Info("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
})

func TestGatewayIntegration(t *testing.T) {
	RegisterFailHandler(Fail)
	RunSpecs(t, "Gateway Integration Suite")
}
