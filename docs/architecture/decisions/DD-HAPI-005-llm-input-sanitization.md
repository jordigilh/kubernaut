# DD-HAPI-005: LLM Input Sanitization

**Status**: ‚úÖ **APPROVED**
**Date**: December 9, 2025
**Decision Makers**: HAPI Team, Security Team
**Priority**: P0 (CRITICAL for V1.0)

---

## Context

### Problem Statement

HolmesGPT-API sends data to external LLM providers (OpenAI, Anthropic, etc.) for AI-powered Kubernetes investigation. This data flow includes:

1. **Initial prompts** containing error messages, descriptions, and signal context
2. **Tool call results** from Kubernetes toolsets (logs, pod descriptions, events)
3. **Recovery context** including workflow parameters and failure details

**Security Risk**: This data may contain credentials that would be leaked to external LLM providers:

| Data Source | Risk Level | Example Credential Exposure |
|-------------|------------|----------------------------|
| `kubectl logs` output | üî¥ HIGH | Database passwords in application logs |
| `error_message` field | üî¥ HIGH | Connection strings in error stack traces |
| `kubectl get pods -o yaml` | üü° MEDIUM | Environment variables with secrets |
| `kubectl get events` | üü° MEDIUM | Secrets in event messages |
| Workflow parameters | üî¥ HIGH | Credentials passed to remediation workflows |
| `naturalLanguageSummary` | üü° MEDIUM | WE-generated context may include secrets |

### Business Impact

- **Compliance Risk**: Credentials sent to external services violate security policies
- **Data Leakage**: LLM providers may log/train on sensitive data
- **Audit Failure**: Cannot demonstrate credential protection in security audits

### Requirements

| ID | Requirement | Priority |
|----|-------------|----------|
| **FR-1** | ALL data sent to LLM must be sanitized for credentials | P0 |
| **FR-2** | Sanitization must cover prompts AND tool call results | P0 |
| **FR-3** | Use DD-005 patterns for consistency with Go services | P1 |
| **FR-4** | Sanitization must not break LLM investigation capability | P0 |
| **FR-5** | Graceful degradation on sanitization errors | P1 |

---

## Decision

### APPROVED: Comprehensive LLM Input Sanitization Layer

Implement a sanitization layer that intercepts ALL data flowing to the LLM:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         HAPI Service                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                          ‚îÇ
‚îÇ   Request Data                                                           ‚îÇ
‚îÇ   (error_message,         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ    description,    ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ LLM Sanitizer    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  Sanitized Prompt   ‚îÇ
‚îÇ    parameters)            ‚îÇ (DD-HAPI-005)    ‚îÇ                          ‚îÇ
‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ   Tool Execution                                                         ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ   ‚îÇ kubernetes/ ‚îÇ         ‚îÇ Wrapped          ‚îÇ                          ‚îÇ
‚îÇ   ‚îÇ logs        ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂   ‚îÇ Tool.invoke()    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  Sanitized Result   ‚îÇ
‚îÇ   ‚îÇ core        ‚îÇ         ‚îÇ (DD-HAPI-005)    ‚îÇ                          ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ   Sanitized Data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ External LLM     ‚îÇ                          ‚îÇ
‚îÇ   (no credentials)        ‚îÇ (OpenAI, etc.)   ‚îÇ                          ‚îÇ
‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Alternatives Considered

### Alternative 1: Disable High-Risk Toolsets

**Approach**: Disable `kubernetes/logs` toolset to prevent log-based credential leakage.

**Pros**:
- ‚úÖ Simple implementation (config change only)
- ‚úÖ Zero development effort

**Cons**:
- ‚ùå **CRITICAL**: Logs are essential for root cause analysis
- ‚ùå Severely degrades investigation quality
- ‚ùå Does not address prompt-level leakage

**Confidence**: 10% - REJECTED (breaks core functionality)

---

### Alternative 2: RBAC Restriction Only

**Approach**: Rely on Kubernetes RBAC to prevent secret access.

**Pros**:
- ‚úÖ Already implemented (HAPI SA cannot read arbitrary secrets)
- ‚úÖ No code changes

**Cons**:
- ‚ùå Does not protect against secrets in logs
- ‚ùå Does not protect against secrets in error messages
- ‚ùå ConfigMaps may contain semi-sensitive data

**Confidence**: 30% - INSUFFICIENT (partial protection only)

---

### Alternative 3: Comprehensive Sanitization Layer (APPROVED)

**Approach**: Wrap ALL data paths to LLM with DD-005 compliant sanitization.

**Pros**:
- ‚úÖ Complete coverage (prompts + tool results)
- ‚úÖ Consistent with Go services (DD-005 patterns)
- ‚úÖ Preserves full investigation capability
- ‚úÖ Auditable protection

**Cons**:
- ‚ö†Ô∏è Development effort (~5.5 hours)
- ‚ö†Ô∏è Potential for over-redaction (mitigated by pattern tuning)

**Confidence**: 95% - APPROVED

---

## Implementation

### Architecture

#### Component 1: LLM Sanitizer Module

**Location**: `holmesgpt-api/src/sanitization/llm_sanitizer.py`

**Responsibility**: Regex-based credential detection and redaction

**Patterns** (ported from `pkg/shared/sanitization/sanitizer.go`):

| Pattern Category | Examples | Replacement |
|-----------------|----------|-------------|
| Passwords | `password=secret`, `"pwd":"abc"` | `password=[REDACTED]` |
| API Keys | `api_key=sk-xxx`, `OPENAI_API_KEY` | `api_key=[REDACTED]` |
| Tokens | `Bearer eyJ...`, `token=ghp_xxx` | `[REDACTED_JWT]`, `[REDACTED_GITHUB_TOKEN]` |
| Database URLs | `postgres://user:pass@host` | `postgres://[USER]:[REDACTED]@host` |
| AWS Credentials | `AKIAIOSFODNN7EXAMPLE` | `[REDACTED_AWS_ACCESS_KEY]` |
| Private Keys | `-----BEGIN PRIVATE KEY-----` | `[REDACTED_PRIVATE_KEY]` |
| K8s Secrets | `data:\n  key: base64...` | `[REDACTED_K8S_SECRET_DATA]` |

#### Component 2: Tool Invoke Wrapper

**Location**: `holmesgpt-api/src/extensions/llm_config.py`

**Responsibility**: Intercept `Tool.invoke()` to sanitize `StructuredToolResult.data`

**Hook Point**:
```python
# HolmesGPT SDK's Tool class
Tool.invoke(params) -> StructuredToolResult
    ‚îú‚îÄ‚îÄ status: SUCCESS/ERROR/...
    ‚îú‚îÄ‚îÄ data: Any           # ‚Üê SANITIZE THIS
    ‚îú‚îÄ‚îÄ error: Optional[str] # ‚Üê AND THIS
    ‚îî‚îÄ‚îÄ invocation: str
```

**Wrapping Strategy** (extends existing monkey-patch pattern):
```python
def wrap_tool_results_with_sanitization(tool_executor):
    """BR-HAPI-211: Wrap Tool.invoke() for credential sanitization."""
    for toolset in tool_executor.toolsets:
        for tool in toolset.tools:
            original_invoke = tool.invoke
            
            def sanitized_invoke(params, ...):
                result = original_invoke(params, ...)
                result.data = sanitize_for_llm(result.data)
                result.error = sanitize_for_llm(result.error) if result.error else None
                return result
            
            tool.invoke = sanitized_invoke
```

#### Component 3: Prompt Sanitization

**Location**: `holmesgpt-api/src/extensions/incident.py`, `recovery.py`

**Responsibility**: Sanitize constructed prompts before LLM submission

**Integration Point**:
```python
def _create_incident_investigation_prompt(request_data):
    # ... construct prompt ...
    return sanitize_for_llm(prompt)  # ‚Üê ADD THIS
```

### Data Flow (After Implementation)

```
1. Request arrives with error_message, description, etc.
   ‚Üì
2. Prompt constructed from request data
   ‚Üì
3. ‚úÖ SANITIZE: sanitize_for_llm(prompt)
   ‚Üì
4. HolmesGPT SDK processes prompt
   ‚Üì
5. LLM requests tool call (e.g., kubectl logs)
   ‚Üì
6. Tool.invoke() executes kubectl command
   ‚Üì
7. ‚úÖ SANITIZE: Wrapped invoke() sanitizes result.data
   ‚Üì
8. Sanitized result returned to LLM
   ‚Üì
9. LLM generates analysis (no credentials in context)
```

---

## Consequences

### Positive

- ‚úÖ **Security**: Credentials cannot leak to external LLM providers
- ‚úÖ **Compliance**: Demonstrates security controls for audits
- ‚úÖ **Consistency**: Uses DD-005 patterns (same as Go services)
- ‚úÖ **Preserved Capability**: Logs toolset remains enabled

### Negative

- ‚ö†Ô∏è **Over-Redaction Risk**: Legitimate data may be redacted
  - **Mitigation**: Pattern tuning, logging of redaction events
- ‚ö†Ô∏è **Performance**: Regex processing adds latency
  - **Mitigation**: Minimal (~1-5ms per sanitization call)

### Neutral

- üîÑ Patterns must be maintained in sync with Go shared library
- üîÑ New credential patterns require updates

---

## Validation

### Test Coverage Requirements

| Test Type | Count | Coverage |
|-----------|-------|----------|
| Unit Tests (sanitizer patterns) | 15+ | All DD-005 patterns |
| Unit Tests (tool wrapper) | 5+ | Invoke wrapping |
| Integration Tests | 3+ | End-to-end sanitization |

### Security Verification

```bash
# Verify no credentials in LLM audit events
grep -r "password\|secret\|token\|api_key" audit_events.json
# Should return: Only "[REDACTED]" placeholders
```

---

## Related Documents

| Document | Purpose |
|----------|---------|
| [DD-005-OBSERVABILITY-STANDARDS.md](./DD-005-OBSERVABILITY-STANDARDS.md) | DD-005 patterns source |
| [BR-HAPI-211](../../requirements/BR-HAPI-211-llm-input-sanitization.md) | Business requirement |
| [pkg/shared/sanitization/](../../../pkg/shared/sanitization/) | Go reference implementation |
| [security-configuration.md](../../services/stateless/holmesgpt-api/security-configuration.md) | HAPI security overview |

---

## Review & Evolution

### When to Revisit

- If new credential patterns are identified
- If LLM providers offer built-in PII/credential filtering
- If performance impact becomes significant

### Success Metrics

| Metric | Target |
|--------|--------|
| Credential leakage incidents | 0 |
| False positive redaction rate | <5% |
| Sanitization latency | <10ms |

---

**Document Version**: 1.0
**Created**: December 9, 2025
**Author**: HAPI Team

