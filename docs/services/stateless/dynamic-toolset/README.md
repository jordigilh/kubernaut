# Dynamic Toolset Service

**Version**: V1.0 (Production Ready)
**Last Updated**: October 13, 2025
**Service Type**: Stateless HTTP API
**Status**: ‚úÖ **PRODUCTION READY** - 232/232 Tests Passing (100%)

---

## üéØ Executive Summary

The **Dynamic Toolset Service** automatically discovers Kubernetes services (Prometheus, Grafana, Jaeger, Elasticsearch, custom) and generates HolmesGPT-compatible toolset ConfigMaps. V1.0 is production-ready with **100% test pass rate** (232/232 tests) and comprehensive documentation.

**Key Achievements**:
- ‚úÖ 194/194 unit tests passing (100%)
- ‚úÖ 38/38 integration tests passing (100%)
- ‚úÖ 8/8 business requirements (100% coverage)
- ‚úÖ 101/109 production readiness points (92.7%)
- ‚úÖ 10 comprehensive documents (5,000+ lines)

**Current Deployment**: V1.0 runs **out-of-cluster** (development mode) with full Kubernetes API access via kubeconfig.

**Future Deployment**: V2.0 will support **in-cluster** deployment (production mode) with ServiceAccount-based access.

---

## üìã Quick Navigation

### Getting Started
- [Installation & Deployment](#-deployment) - V1 out-of-cluster setup
- [API Reference](#-api-reference) - Complete endpoint documentation
- [Configuration](#Ô∏è-configuration) - Environment variables and settings
- [Troubleshooting](#-troubleshooting) - Common issues and solutions

### Core Documentation
1. **[Implementation Plan](./implementation/IMPLEMENTATION_PLAN_ENHANCED.md)** - 12-day implementation timeline
2. **[BR Coverage Matrix](./BR_COVERAGE_MATRIX.md)** - Business requirement traceability
3. **[Testing Strategy](./implementation/testing/TESTING_STRATEGY.md)** - Comprehensive test approach
4. **[Production Readiness](./implementation/PRODUCTION_READINESS_REPORT.md)** - 101/109 points (92.7%)
5. **[Handoff Summary](./implementation/00-HANDOFF-SUMMARY.md)** - Complete implementation summary

### Design Decisions
- **[DD-TOOLSET-001](./implementation/design/01-detector-interface-design.md)** - Detector interface design
- **[DD-TOOLSET-002](./implementation/design/DD-TOOLSET-002-discovery-loop-architecture.md)** - Discovery loop (periodic vs. watch)
- **[DD-TOOLSET-003](./implementation/design/DD-TOOLSET-003-reconciliation-strategy.md)** - Reconciliation strategy
- **[ConfigMap Schema](./implementation/design/02-configmap-schema-validation.md)** - Schema validation

---

## üéØ What It Does

**Automatically discover and configure HolmesGPT toolsets.**

**Dynamic configuration** that provides:
- Automatic Kubernetes resource discovery
- HolmesGPT toolset generation
- ConfigMap-based hot-reload
- Toolset validation and compatibility checks

---

## üîå Service Configuration

| Aspect | Value |
|--------|-------|
| **HTTP Port** | 8080 (REST API, `/health`, `/ready`) |
| **Metrics Port** | 9090 (Prometheus `/metrics` with auth) |
| **Namespace** | `prometheus-alerts-slm` |
| **ServiceAccount** | `dynamic-toolset-sa` |

---

## üìä API Endpoints

| Endpoint | Method | Purpose | Latency Target |
|----------|--------|---------|----------------|
| `/api/v1/toolsets/discover` | POST | Discover available K8s resources | < 300ms |
| `/api/v1/toolsets/generate` | POST | Generate toolset configuration | < 200ms |
| `/api/v1/toolsets/validate` | POST | Validate toolset compatibility | < 100ms |

---

## üîç Discovery Capabilities

**Automatically Discovers**:
- Available namespaces
- Deployments, StatefulSets, DaemonSets
- Services and Ingresses
- ConfigMaps and Secrets (metadata only)
- Prometheus instances
- Grafana instances

---

## üéØ Key Features

- ‚úÖ Automatic resource discovery
- ‚úÖ ConfigMap generation for HolmesGPT
- ‚úÖ Hot-reload support (HolmesGPT watches ConfigMaps)
- ‚úÖ Toolset validation
- ‚úÖ RBAC-aware discovery (only shows accessible resources)

---

## üîó Integration Points

**Clients**:
1. **HolmesGPT API** - Reads generated toolset ConfigMaps

**Generates**:
- ConfigMaps in `prometheus-alerts-slm` namespace
- Format: HolmesGPT toolset configuration

---

## üìä Performance

- **Latency**: < 300ms (p95)
- **Throughput**: 5 requests/second
- **Scaling**: 1-2 replicas
- **Discovery Interval**: Every 5 minutes (configurable)

---

## üöÄ Deployment

### V1 vs V2 Deployment Strategy

**V1.0 (Current): Out-of-Cluster Deployment** ‚úÖ
- **Status**: Production Ready (232/232 tests passing)
- **Purpose**: Development, testing, and initial validation
- **Access**: Uses local kubeconfig file
- **Deployment**: Run locally with `go run` or as binary
- **Testing**: Fully validated with unit + integration tests
- **Use Cases**:
  - Local development and testing
  - CI/CD validation
  - Initial production validation
  - Cluster administration tasks

**V2.0 (Future): In-Cluster Deployment** üìã
- **Status**: Planned for V2
- **Purpose**: Production deployment within Kubernetes
- **Access**: Uses ServiceAccount tokens
- **Deployment**: Kubernetes Deployment with RBAC
- **Testing**: E2E tests with in-cluster scenarios
- **Use Cases**:
  - Production workloads
  - Multi-cluster discovery
  - High-availability deployments
  - Enterprise production environments

---

### Why V1 is Out-of-Cluster

**Decision Rationale** (from DD-TOOLSET-002):

**V1 Out-of-Cluster Benefits**:
1. **Faster Time to Value**: Immediately usable without container image building, registry setup, or complex RBAC configuration
2. **Complete Test Coverage**: Integration tests with Kind cluster provide 100% end-to-end validation (38/38 passing)
3. **Simpler Development**: Direct kubectl access simplifies debugging and development
4. **Lower Complexity**: No need for container image management, registry authentication, or in-cluster networking
5. **Sufficient for V1 Goals**: Service functionality fully validated through comprehensive testing

**V2 In-Cluster Requirements** (deferred):
1. **Container Image**: Build and publish to registry
2. **RBAC Setup**: ServiceAccount, ClusterRole, ClusterRoleBinding with thorough validation
3. **Network Configuration**: Service, Ingress, Network Policies
4. **Resource Management**: CPU/memory limits, quotas, pod security policies
5. **Health Probes**: Liveness and readiness probe fine-tuning
6. **E2E Testing**: In-cluster test scenarios (10 scenarios planned)

**Cost/Benefit Analysis**:
- **Cost**: 2-3 additional days for in-cluster deployment infrastructure
- **Benefit**: Integration tests already provide comprehensive end-to-end coverage
- **Decision**: Defer to V2 when production deployment is needed

**Key Insight**: "V1 proves the service works correctly. V2 adds operational deployment capabilities."

---

### V1 Installation (Out-of-Cluster)

#### Prerequisites

- **Kubernetes cluster** (v1.24+)
- **kubectl** configured with cluster access
- **Go** 1.21+ (for building from source)
- **KUBECONFIG** environment variable set

#### Installation Steps

**Option 1: Run from Source** (Recommended for V1)

```bash
# Clone repository
git clone https://github.com/jordigilh/kubernaut.git
cd kubernaut

# Run the service
export KUBECONFIG=~/.kube/config
export DISCOVERY_INTERVAL=5m
go run cmd/dynamic-toolset-server/main.go
```

**Option 2: Build and Run Binary**

```bash
# Build binary
cd cmd/dynamic-toolset-server
go build -o dynamic-toolset

# Run binary
./dynamic-toolset
```

**Option 3: Docker Container** (local testing)

```bash
# Build container image
docker build -t dynamic-toolset:v1.0 -f docker/Dockerfile.dynamictoolset .

# Run container (mount kubeconfig)
docker run -p 8080:8080 -p 9090:9090 \
  -v ~/.kube/config:/root/.kube/config \
  -e KUBECONFIG=/root/.kube/config \
  dynamic-toolset:v1.0
```

#### Verification Steps

**1. Check health endpoints**:
```bash
curl http://localhost:8080/health
# Expected: {"status":"ok"}

curl http://localhost:8080/ready
# Expected: {"kubernetes":true}
```

**2. Verify Kubernetes connectivity**:
```bash
# Service logs should show successful K8s connection
# Look for: "Kubernetes client initialized successfully"
```

**3. Test service discovery** (requires authentication):
```bash
# Get ServiceAccount token (or use your own kubeconfig token)
TOKEN=$(kubectl create token default -n default --duration=1h)

# List discovered services
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/api/v1/services

# Get current toolset
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/api/v1/toolset
```

**4. Check metrics**:
```bash
curl http://localhost:9090/metrics | grep dynamictoolset
# Should see discovery, API, and ConfigMap metrics
```

**5. Verify ConfigMap generation**:
```bash
# Check if ConfigMap was created
kubectl get configmap kubernaut-toolset-config -n kubernaut-system

# View ConfigMap contents
kubectl get configmap kubernaut-toolset-config -n kubernaut-system -o yaml
```

### First Discovery Example

**Scenario**: Discover Prometheus instance in your cluster

```bash
# The service automatically discovers Prometheus every 5 minutes
# To trigger immediate discovery, check the logs:
kubectl logs -n kubernaut-system -l app=dynamic-toolset --tail=50

# Expected log output:
# {"level":"info","msg":"Service discovery complete","discovered_count":1,"prometheus_count":1}
```

**Verify ConfigMap was created**:
```bash
kubectl get configmap kubernaut-toolset-config -n kubernaut-system -o yaml
```

Expected output:
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubernaut-toolset-config
data:
  prometheus-toolset.yaml: |
    toolset: prometheus
    enabled: true
    config:
      url: "http://prometheus.monitoring:9090"
```

### Verification Steps

**1. Check service discovery metrics**:
```bash
kubectl port-forward -n kubernaut-system svc/dynamic-toolset 9090:9090
curl http://localhost:9090/metrics | grep toolset_services_discovered_total
```

**2. Verify HolmesGPT can read the toolsets**:
```bash
# HolmesGPT automatically reads the ConfigMap
# Check HolmesGPT logs for toolset loading confirmation
kubectl logs -n kubernaut-system -l app=holmesgpt | grep "toolset"
```

---

## üìñ Common Workflows

### Workflow 1: Discover Services

**Use Case**: Automatically discover all supported services in your cluster

**Steps**:
1. Deploy service (see Getting Started)
2. Service discovers automatically every 5 minutes
3. Check discovered services via API or logs

**API Method** (on-demand discovery):
```bash
export TOKEN=$(kubectl create token dynamic-toolset-sa -n kubernaut-system)

# Trigger discovery
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  http://localhost:8080/api/v1/services/discover

# Response:
{
  "discovered": [
    {
      "name": "prometheus",
      "namespace": "monitoring",
      "type": "prometheus",
      "endpoint": "http://prometheus.monitoring:9090",
      "healthy": true
    }
  ]
}
```

**Automated Method** (controller loop):
```bash
# Discovery happens automatically
# Monitor via logs:
kubectl logs -f -n kubernaut-system -l app=dynamic-toolset
```

---

### Workflow 2: Generate Toolsets

**Use Case**: Generate HolmesGPT toolset configuration from discovered services

**Automatic Generation** (default):
```bash
# Service generates toolsets automatically after discovery
# Check the ConfigMap:
kubectl get configmap kubernaut-toolset-config -n kubernaut-system -o yaml
```

**Manual Generation** (via API):
```bash
export TOKEN=$(kubectl create token dynamic-toolset-sa -n kubernaut-system)

# Generate toolsets for specific services
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "services": [
      {
        "name": "prometheus",
        "namespace": "monitoring",
        "type": "prometheus"
      }
    ]
  }' \
  http://localhost:8080/api/v1/toolsets/generate

# Response includes generated YAML configuration
```

---

### Workflow 3: Validate Configurations

**Use Case**: Validate toolset configuration before deploying

```bash
export TOKEN=$(kubectl create token dynamic-toolset-sa -n kubernaut-system)

# Validate toolset configuration
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "toolset": "prometheus",
    "config": {
      "url": "http://prometheus.monitoring:9090"
    }
  }' \
  http://localhost:8080/api/v1/toolsets/validate

# Response:
{
  "valid": true,
  "checks": [
    {"check": "url_format", "passed": true},
    {"check": "endpoint_reachable", "passed": true},
    {"check": "health_check", "passed": true}
  ]
}
```

---

### Workflow 4: Manual Override

**Use Case**: Add custom toolset or override auto-generated configuration

**Step 1**: Create override configuration
```yaml
# override-toolset.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubernaut-toolset-config
  namespace: kubernaut-system
data:
  # Add to existing ConfigMap
  overrides.yaml: |
    custom-datadog:
      enabled: true
      toolset: datadog
      config:
        api_key: "${DATADOG_API_KEY}"
        site: "datadoghq.com"
```

**Step 2**: Apply the override
```bash
kubectl patch configmap kubernaut-toolset-config \
  -n kubernaut-system \
  --type merge \
  -p "$(cat override-toolset.yaml)"
```

**Step 3**: Verify override is preserved
```bash
# The service reconciles every 30 seconds
# Your override will be preserved in the "overrides.yaml" key
kubectl get configmap kubernaut-toolset-config -n kubernaut-system -o yaml
```

**Result**: Auto-generated toolsets are maintained, your override is preserved.

---

## üîß API Quick Reference

### Authentication

All API endpoints (except health checks) require authentication:

```bash
# Get service account token
export TOKEN=$(kubectl create token dynamic-toolset-sa -n kubernaut-system --duration=1h)

# Use in requests
curl -H "Authorization: Bearer $TOKEN" <endpoint>
```

### Health Endpoints (No Auth)

```bash
# Health check (liveness probe)
curl http://localhost:8080/health
# Response: {"status":"healthy"}

# Ready check (readiness probe)
curl http://localhost:8080/ready
# Response: {"status":"ready"}
```

### Discovery Endpoints (Auth Required)

**GET /api/v1/services/discovered** - List discovered services
```bash
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/api/v1/services/discovered
```

**POST /api/v1/services/discover** - Trigger discovery
```bash
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/api/v1/services/discover
```

### ConfigMap Endpoints (Auth Required)

**GET /api/v1/configmap** - Get current ConfigMap
```bash
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/api/v1/configmap
```

**POST /api/v1/toolsets/generate** - Generate toolset
```bash
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"services":[...]}' \
  http://localhost:8080/api/v1/toolsets/generate
```

**POST /api/v1/toolsets/validate** - Validate toolset
```bash
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"toolset":"prometheus","config":{...}}' \
  http://localhost:8080/api/v1/toolsets/validate
```

### Common Response Codes

| Code | Meaning | Action |
|------|---------|--------|
| 200 | Success | Request completed |
| 401 | Unauthorized | Check token is valid |
| 403 | Forbidden | Check RBAC permissions |
| 500 | Server Error | Check service logs |
| 503 | Service Unavailable | Service starting up |

---

## üîç Troubleshooting

### Common Issues

#### Issue: Service not discovering any services

**Symptoms**:
```bash
kubectl logs -n kubernaut-system -l app=dynamic-toolset
# Output: "discovered_count":0
```

**Causes & Solutions**:

1. **No services match detection criteria**
   ```bash
   # Check if Prometheus/Grafana exist
   kubectl get svc --all-namespaces | grep -E "prometheus|grafana"

   # If exists, check labels
   kubectl get svc prometheus -n monitoring -o yaml | grep -A5 labels
   ```

2. **RBAC permissions insufficient**
   ```bash
   # Verify ServiceAccount can list services
   kubectl auth can-i list services \
     --as=system:serviceaccount:kubernaut-system:dynamic-toolset-sa \
     --all-namespaces
   ```

3. **Health checks failing**
   ```bash
   # Check if services are actually healthy
   kubectl port-forward -n monitoring svc/prometheus 9090:9090
   curl http://localhost:9090/-/healthy
   ```

---

#### Issue: ConfigMap keeps getting reset

**Symptoms**: Manual edits to ConfigMap are overwritten

**Solution**: Use `overrides.yaml` key for manual configurations
```bash
# Don't edit auto-generated keys (prometheus-toolset.yaml, grafana-toolset.yaml)
# Add your customizations to overrides.yaml instead
kubectl patch configmap kubernaut-toolset-config -n kubernaut-system \
  --type json \
  -p '[{"op":"add","path":"/data/overrides.yaml","value":"custom-config: here"}]'
```

---

#### Issue: API returns 401 Unauthorized

**Symptoms**:
```bash
curl http://localhost:8080/api/v1/services/discovered
# Response: {"error":"unauthorized"}
```

**Solutions**:

1. **Token expired**
   ```bash
   # Create new token
   export TOKEN=$(kubectl create token dynamic-toolset-sa -n kubernaut-system)
   ```

2. **Wrong ServiceAccount**
   ```bash
   # Verify ServiceAccount exists
   kubectl get sa dynamic-toolset-sa -n kubernaut-system
   ```

3. **TokenReview not configured**
   ```bash
   # Check service logs for TokenReview errors
   kubectl logs -n kubernaut-system -l app=dynamic-toolset | grep TokenReview
   ```

---

#### Issue: High memory usage

**Symptoms**: Service using > 128MB memory

**Investigation**:
```bash
# Check current usage
kubectl top pod -n kubernaut-system -l app=dynamic-toolset

# Check discovery cache size
kubectl logs -n kubernaut-system -l app=dynamic-toolset | grep cache_size
```

**Solutions**:
1. Reduce discovery interval in configuration
2. Limit namespaces to monitor
3. Increase memory limits if justified

---

### Getting Help

**Check service logs**:
```bash
kubectl logs -n kubernaut-system -l app=dynamic-toolset --tail=100
```

**Check service status**:
```bash
kubectl describe pod -n kubernaut-system -l app=dynamic-toolset
```

**Enable debug logging**:
```bash
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  LOG_LEVEL=debug
```

**Check metrics**:
```bash
kubectl port-forward -n kubernaut-system svc/dynamic-toolset 9090:9090
curl http://localhost:9090/metrics | grep toolset_
```

---

---

## üìñ API Reference

### Complete Endpoint Documentation

The Dynamic Toolset Service exposes 6 REST endpoints. Public endpoints require no authentication. Protected endpoints require a valid Kubernetes ServiceAccount bearer token.

#### 1. GET /health (Public)

**Purpose**: Liveness probe for Kubernetes
**Authentication**: None
**Response Time**: < 10ms

**Request**:
```bash
curl http://localhost:8080/health
```

**Success Response** (200 OK):
```json
{
  "status": "ok"
}
```

**Use Cases**:
- Kubernetes liveness probe
- Load balancer health check
- Basic connectivity test

---

#### 2. GET /ready (Public)

**Purpose**: Readiness probe for Kubernetes
**Authentication**: None
**Response Time**: < 50ms

**Request**:
```bash
curl http://localhost:8080/ready
```

**Success Response** (200 OK):
```json
{
  "status": "ready",
  "checks": {
    "kubernetes": true,
    "configmap": true
  }
}
```

**Not Ready Response** (503 Service Unavailable):
```json
{
  "status": "not_ready",
  "checks": {
    "kubernetes": true,
    "configmap": false
  },
  "message": "ConfigMap not accessible"
}
```

**Use Cases**:
- Kubernetes readiness probe
- Check if service can accept traffic
- Verify Kubernetes API connectivity

---

#### 3. GET /api/v1/toolset (Protected)

**Purpose**: Get the current HolmesGPT toolset JSON
**Authentication**: Bearer token required
**Response Time**: < 100ms

**Request**:
```bash
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/api/v1/toolset
```

**Success Response** (200 OK):
```json
{
  "tools": [
    {
      "name": "prometheus_query",
      "type": "http",
      "description": "Query Prometheus metrics API",
      "endpoint": "http://prometheus.monitoring.svc.cluster.local:9090",
      "namespace": "monitoring",
      "parameters": {
        "timeout": "30s"
      }
    },
    {
      "name": "grafana_dashboard",
      "type": "http",
      "description": "Access Grafana dashboards",
      "endpoint": "http://grafana.monitoring.svc.cluster.local:3000",
      "namespace": "monitoring"
    }
  ],
  "metadata": {
    "last_updated": "2025-10-13T20:00:00Z",
    "tool_count": 2,
    "discovered_services": 2,
    "manual_overrides": 0
  }
}
```

**Error Response** (401 Unauthorized):
```json
{
  "error": "unauthorized",
  "message": "Bearer token required"
}
```

**Error Response** (500 Internal Server Error):
```json
{
  "error": "internal_server_error",
  "message": "Failed to read ConfigMap"
}
```

**Use Cases**:
- HolmesGPT toolset loading
- Toolset validation
- Debugging toolset configuration

---

#### 4. GET /api/v1/services (Protected)

**Purpose**: List all discovered services
**Authentication**: Bearer token required
**Response Time**: < 100ms

**Request**:
```bash
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/api/v1/services
```

**Success Response** (200 OK):
```json
{
  "services": [
    {
      "name": "prometheus-server",
      "namespace": "monitoring",
      "type": "prometheus",
      "endpoint": "http://prometheus-server.monitoring.svc.cluster.local:9090",
      "health_check": "/api/v1/query",
      "healthy": true,
      "labels": {
        "app": "prometheus"
      },
      "discovered_at": "2025-10-13T20:00:00Z"
    },
    {
      "name": "grafana",
      "namespace": "monitoring",
      "type": "grafana",
      "endpoint": "http://grafana.monitoring.svc.cluster.local:3000",
      "health_check": "/api/health",
      "healthy": true,
      "labels": {
        "app": "grafana"
      },
      "discovered_at": "2025-10-13T20:00:00Z"
    }
  ],
  "total": 2,
  "last_discovery": "2025-10-13T20:00:00Z"
}
```

**Use Cases**:
- Debugging discovery issues
- Validating service detection
- Monitoring discovered services

---

#### 5. POST /api/v1/discover (Protected)

**Purpose**: Trigger immediate service discovery
**Authentication**: Bearer token required
**Response Time**: < 5 seconds (depends on cluster size)

**Request**:
```bash
curl -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  http://localhost:8080/api/v1/discover
```

**Success Response** (200 OK):
```json
{
  "status": "completed",
  "discovered_services": 2,
  "discovery_duration_ms": 1234,
  "services": [
    {
      "name": "prometheus-server",
      "namespace": "monitoring",
      "type": "prometheus"
    },
    {
      "name": "grafana",
      "namespace": "monitoring",
      "type": "grafana"
    }
  ],
  "configmap_updated": true
}
```

**Error Response** (503 Service Unavailable):
```json
{
  "error": "discovery_in_progress",
  "message": "Discovery already running, please wait"
}
```

**Use Cases**:
- Force immediate discovery after deploying new services
- Testing discovery functionality
- Debugging discovery issues

---

#### 6. GET /metrics (Protected)

**Purpose**: Prometheus metrics (separate port 9090)
**Authentication**: Bearer token required
**Response Time**: < 50ms
**Port**: 9090 (separate from API port 8080)

**Request**:
```bash
curl -H "Authorization: Bearer $TOKEN" \
  http://localhost:9090/metrics
```

**Success Response** (200 OK):
```text
# HELP dynamictoolset_discovery_cycles_total Total number of discovery cycles
# TYPE dynamictoolset_discovery_cycles_total counter
dynamictoolset_discovery_cycles_total 42

# HELP dynamictoolset_services_discovered_total Number of services discovered
# TYPE dynamictoolset_services_discovered_total gauge
dynamictoolset_services_discovered_total{type="prometheus"} 1
dynamictoolset_services_discovered_total{type="grafana"} 1

# HELP dynamictoolset_discovery_duration_seconds Discovery cycle duration
# TYPE dynamictoolset_discovery_duration_seconds histogram
dynamictoolset_discovery_duration_seconds_bucket{le="0.1"} 5
dynamictoolset_discovery_duration_seconds_bucket{le="0.5"} 30
dynamictoolset_discovery_duration_seconds_bucket{le="1.0"} 40
dynamictoolset_discovery_duration_seconds_bucket{le="5.0"} 42
dynamictoolset_discovery_duration_seconds_sum 45.2
dynamictoolset_discovery_duration_seconds_count 42

# HELP dynamictoolset_configmap_updates_total Number of ConfigMap updates
# TYPE dynamictoolset_configmap_updates_total counter
dynamictoolset_configmap_updates_total 38

# HELP dynamictoolset_discovery_errors_total Discovery errors
# TYPE dynamictoolset_discovery_errors_total counter
dynamictoolset_discovery_errors_total 0
```

**Use Cases**:
- Prometheus scraping
- Monitoring service health
- Alerting on discovery failures
- Performance analysis

---

### API Error Codes

| Code | Name | Meaning | Resolution |
|------|------|---------|------------|
| **200** | OK | Success | N/A |
| **401** | Unauthorized | Missing or invalid bearer token | Regenerate ServiceAccount token |
| **403** | Forbidden | Valid token but insufficient RBAC permissions | Check ClusterRole/ClusterRoleBinding |
| **404** | Not Found | Endpoint or resource not found | Check API path |
| **500** | Internal Server Error | Server-side error (K8s API, ConfigMap) | Check service logs |
| **503** | Service Unavailable | Service not ready or discovery in progress | Wait and retry |

---

## ‚öôÔ∏è Configuration

### Environment Variables

Complete list of configuration options for the Dynamic Toolset Service.

#### Core Configuration

| Variable | Default | Description | Example |
|----------|---------|-------------|---------|
| **KUBECONFIG** | `~/.kube/config` | Path to kubeconfig file (V1 only) | `/root/.kube/config` |
| **PORT** | `8080` | HTTP API server port | `8080` |
| **METRICS_PORT** | `9090` | Prometheus metrics port | `9090` |
| **LOG_LEVEL** | `info` | Logging level (debug, info, warn, error) | `debug` |
| **LOG_FORMAT** | `json` | Log format (json, text) | `json` |

#### Discovery Configuration

| Variable | Default | Description | Example |
|----------|---------|-------------|---------|
| **DISCOVERY_INTERVAL** | `5m` | Discovery loop interval | `1m`, `30s`, `10m` |
| **NAMESPACES** | `""` (all) | Comma-separated namespaces to monitor | `monitoring,observability` |
| **ENABLE_PROMETHEUS** | `true` | Enable Prometheus detector | `true` |
| **ENABLE_GRAFANA** | `true` | Enable Grafana detector | `true` |
| **ENABLE_JAEGER** | `true` | Enable Jaeger detector | `true` |
| **ENABLE_ELASTICSEARCH** | `true` | Enable Elasticsearch detector | `true` |
| **ENABLE_CUSTOM** | `true` | Enable custom annotation detector | `true` |
| **HEALTH_CHECK_TIMEOUT** | `5s` | Timeout for service health checks | `10s` |

#### ConfigMap Configuration

| Variable | Default | Description | Example |
|----------|---------|-------------|---------|
| **CONFIGMAP_NAME** | `kubernaut-toolset-config` | ConfigMap name | `my-toolset-config` |
| **CONFIGMAP_NAMESPACE** | `kubernaut-system` | ConfigMap namespace | `default` |
| **RECONCILIATION_INTERVAL** | `30s` | ConfigMap reconciliation interval | `1m` |

#### Authentication Configuration

| Variable | Default | Description | Example |
|----------|---------|-------------|---------|
| **AUTH_ENABLED** | `true` | Enable API authentication | `false` (dev only) |
| **TOKEN_REVIEW_ENABLED** | `true` | Enable Kubernetes TokenReview | `true` |
| **PUBLIC_ENDPOINTS** | `/health,/ready` | Comma-separated public endpoints | `/health,/ready,/metrics` |

#### Performance Configuration

| Variable | Default | Description | Example |
|----------|---------|-------------|---------|
| **MAX_CONCURRENT_DETECTORS** | `5` | Max parallel detector executions | `10` |
| **DISCOVERY_TIMEOUT** | `30s` | Max discovery cycle duration | `60s` |
| **API_TIMEOUT** | `30s` | API request timeout | `60s` |
| **CACHE_SIZE** | `100` | Discovery cache size (services) | `200` |

### Configuration Files

#### V1 Configuration Example

```bash
# .env file for V1 deployment
PORT=8080
METRICS_PORT=9090
LOG_LEVEL=info
LOG_FORMAT=json

DISCOVERY_INTERVAL=5m
NAMESPACES=monitoring,observability,default

CONFIGMAP_NAME=kubernaut-toolset-config
CONFIGMAP_NAMESPACE=kubernaut-system

AUTH_ENABLED=true
TOKEN_REVIEW_ENABLED=true
```

#### V2 Configuration Example (ConfigMap)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: dynamic-toolset-config
  namespace: kubernaut-system
data:
  config.yaml: |
    server:
      port: 8080
      metrics_port: 9090
      log_level: info
      log_format: json

    discovery:
      interval: 5m
      namespaces:
        - monitoring
        - observability
        - default
      detectors:
        prometheus: true
        grafana: true
        jaeger: true
        elasticsearch: true
        custom: true

    configmap:
      name: kubernaut-toolset-config
      namespace: kubernaut-system
      reconciliation_interval: 30s

    authentication:
      enabled: true
      token_review_enabled: true
      public_endpoints:
        - /health
        - /ready
```

### Discovery Tuning

#### Interval Guidelines

| Interval | Use Case | API Load | Discovery Latency |
|----------|----------|----------|-------------------|
| **30s** | Development, rapid testing | High (120 calls/hour) | 0-30s |
| **1m** | Staging, frequent changes | Medium (60 calls/hour) | 0-60s |
| **5m** | Production (recommended) | Low (12 calls/hour) | 0-5min |
| **10m** | Large clusters, stable workloads | Very Low (6 calls/hour) | 0-10min |

**Recommendation**: Use 5-minute interval for production. Discovery latency of 0-5 minutes is acceptable for toolset updates.

#### Namespace Filtering

**Best Practice**: Limit discovery to specific namespaces to reduce API load and improve performance.

```bash
# Monitor only specific namespaces
export NAMESPACES="monitoring,observability,default"
```

**Benefits**:
- Reduced Kubernetes API load
- Faster discovery cycles
- Lower memory usage
- More predictable behavior

---

## üõ†Ô∏è Advanced Configuration

### Custom Detector Configuration

Add custom service detection via annotations:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-custom-service
  namespace: default
  annotations:
    kubernaut.io/discoverable: "true"
    kubernaut.io/tool-type: "custom_api"
    kubernaut.io/health-check: "/health"
spec:
  ports:
  - port: 8080
    name: http
  selector:
    app: my-custom-service
```

The service will be discovered as `custom_api` tool type with health check at `/health`.

### Override Configuration

**Use Case**: Override auto-discovered services or add manual tools

**Method**: Edit the `overrides.yaml` section in the ConfigMap

```bash
kubectl edit configmap kubernaut-toolset-config -n kubernaut-system
```

Add to `data.overrides.yaml`:
```yaml
tools:
  - name: custom_prometheus
    type: http
    description: Production Prometheus instance
    endpoint: http://prometheus.prod.example.com:9090
    parameters:
      timeout: 60s
      max_retries: 3

  - name: prometheus_query
    # This overrides the auto-discovered prometheus_query
    type: http
    endpoint: http://prometheus.prod.svc:9090
```

**Result**: Overrides take precedence over auto-discovered services. Both will be included in the toolset.

---

## üîç Troubleshooting

### Comprehensive Troubleshooting Guide

#### Issue 1: Service Not Discovering Any Services

**Symptoms**:
```bash
kubectl logs -n kubernaut-system -l app=dynamic-toolset
# Output: "discovered_count":0
```

**Diagnostic Steps**:

1. **Check if services exist**:
```bash
kubectl get svc --all-namespaces | grep -E "prometheus|grafana|jaeger|elasticsearch"
```

2. **Verify service labels/annotations**:
```bash
# For Prometheus
kubectl get svc prometheus-server -n monitoring -o yaml | grep -A10 "labels:"

# Expected label:
# labels:
#   app: prometheus
```

3. **Check RBAC permissions**:
```bash
kubectl auth can-i list services \
  --as=system:serviceaccount:kubernaut-system:dynamic-toolset \
  --all-namespaces

# Expected: yes
```

4. **Verify namespace filtering**:
```bash
# Check if NAMESPACES env var is limiting discovery
kubectl get deployment dynamic-toolset -n kubernaut-system -o yaml | grep NAMESPACES
```

5. **Test service health check**:
```bash
# Forward port and test health endpoint
kubectl port-forward -n monitoring svc/prometheus-server 9090:9090
curl http://localhost:9090/api/v1/query?query=up

# Should return valid Prometheus response
```

**Solutions**:
- Add required labels to services (`app: prometheus`, `app: grafana`, etc.)
- Grant RBAC permissions (see RBAC section)
- Add namespace to NAMESPACES filter
- Fix service health check endpoint

---

#### Issue 2: ConfigMap Not Being Created

**Symptoms**: ConfigMap `kubernaut-toolset-config` doesn't exist

**Diagnostic Steps**:

1. **Check ConfigMap existence**:
```bash
kubectl get configmap -n kubernaut-system
```

2. **Check service logs for errors**:
```bash
kubectl logs -n kubernaut-system -l app=dynamic-toolset | grep -i error
```

3. **Verify RBAC for ConfigMap operations**:
```bash
kubectl auth can-i create configmaps \
  --as=system:serviceaccount:kubernaut-system:dynamic-toolset \
  -n kubernaut-system

# Expected: yes
```

**Solutions**:
- Grant ConfigMap create/update permissions
- Check for namespace typos in configuration
- Verify service has discovered at least one service (required for ConfigMap creation)

---

#### Issue 3: ConfigMap Keeps Getting Reset (Manual Edits Lost)

**Symptoms**: Manual ConfigMap edits are overwritten after ~30 seconds

**Root Cause**: Editing auto-generated sections (`toolset.yaml`) instead of overrides section

**Solution**: Use `overrides.yaml` section for manual configurations

```bash
# Get current ConfigMap
kubectl get configmap kubernaut-toolset-config -n kubernaut-system -o yaml > cm.yaml

# Edit cm.yaml - add your tools to data.overrides.yaml (NOT data.toolset.yaml)

# Apply
kubectl apply -f cm.yaml
```

**Correct Structure**:
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubernaut-toolset-config
data:
  toolset.yaml: |
    # ‚ö†Ô∏è DO NOT EDIT - Auto-generated, will be overwritten
    tools:
      - name: prometheus_query
        # ... auto-discovered

  overrides.yaml: |
    # ‚úÖ EDIT HERE - Manual tools preserved
    tools:
      - name: custom_datadog
        type: http
        endpoint: http://datadog.monitoring:8080
```

---

#### Issue 4: API Returns 401 Unauthorized

**Symptoms**:
```bash
curl http://localhost:8080/api/v1/services
# Response: {"error":"unauthorized"}
```

**Diagnostic Steps**:

1. **Check if token is provided**:
```bash
# Token must be in Authorization header
curl -H "Authorization: Bearer $TOKEN" http://localhost:8080/api/v1/services
```

2. **Verify token is valid**:
```bash
# Create fresh token
kubectl create token dynamic-toolset -n kubernaut-system --duration=1h

# Test with new token
TOKEN=$(kubectl create token dynamic-toolset -n kubernaut-system)
curl -H "Authorization: Bearer $TOKEN" http://localhost:8080/api/v1/services
```

3. **Check ServiceAccount exists**:
```bash
kubectl get sa dynamic-toolset -n kubernaut-system
```

4. **Verify TokenReview is working**:
```bash
# Check service logs for TokenReview errors
kubectl logs -n kubernaut-system -l app=dynamic-toolset | grep TokenReview
```

**Solutions**:
- Always include `Authorization: Bearer $TOKEN` header
- Use fresh tokens (tokens expire after specified duration)
- Verify ServiceAccount exists
- Check RBAC for TokenReview permissions

---

#### Issue 5: High Memory Usage (> 256MB)

**Symptoms**:
```bash
kubectl top pod -n kubernaut-system -l app=dynamic-toolset
# Output: NAME CPU(cores) MEMORY(bytes)
#         dynamic-toolset-xxx 100m 300Mi
```

**Diagnostic Steps**:

1. **Check discovery cache size**:
```bash
kubectl logs -n kubernaut-system -l app=dynamic-toolset | grep cache_size
```

2. **Check number of discovered services**:
```bash
kubectl logs -n kubernaut-system -l app=dynamic-toolset | grep discovered_count
```

3. **Check discovery interval**:
```bash
kubectl get deployment dynamic-toolset -n kubernaut-system -o yaml | grep DISCOVERY_INTERVAL
```

**Solutions**:

1. **Reduce discovery scope**:
```bash
# Limit namespaces
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  NAMESPACES=monitoring,observability
```

2. **Increase discovery interval**:
```bash
# Reduce discovery frequency
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  DISCOVERY_INTERVAL=10m
```

3. **Adjust memory limits** (if justified):
```bash
kubectl set resources deployment/dynamic-toolset \
  -n kubernaut-system \
  --limits=memory=512Mi \
  --requests=memory=256Mi
```

---

#### Issue 6: Discovery Taking Too Long (> 5 seconds)

**Symptoms**: Discovery cycle duration > 5 seconds for < 100 services

**Diagnostic Steps**:

1. **Check discovery duration metric**:
```bash
curl http://localhost:9090/metrics | grep discovery_duration
```

2. **Check number of services**:
```bash
kubectl get svc --all-namespaces | wc -l
```

3. **Check health check timeout**:
```bash
kubectl get deployment dynamic-toolset -n kubernaut-system -o yaml | grep HEALTH_CHECK_TIMEOUT
```

**Solutions**:

1. **Reduce health check timeout**:
```bash
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  HEALTH_CHECK_TIMEOUT=2s
```

2. **Limit namespaces**:
```bash
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  NAMESPACES=monitoring,observability
```

3. **Increase max concurrent detectors**:
```bash
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  MAX_CONCURRENT_DETECTORS=10
```

---

### Debugging Techniques

#### Enable Debug Logging

```bash
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  LOG_LEVEL=debug

# Watch logs
kubectl logs -f -n kubernaut-system -l app=dynamic-toolset
```

**Debug Log Output**:
```json
{"level":"debug","msg":"Starting discovery cycle","cycle":42}
{"level":"debug","msg":"Running detector","detector":"prometheus","namespace":"monitoring"}
{"level":"debug","msg":"Service detected","service":"prometheus-server","endpoint":"http://prometheus-server.monitoring.svc.cluster.local:9090"}
{"level":"debug","msg":"Health check passed","service":"prometheus-server","duration_ms":23}
{"level":"debug","msg":"Discovery cycle complete","discovered":2,"duration_ms":1234}
```

#### Check Prometheus Metrics

```bash
# Port-forward metrics port
kubectl port-forward -n kubernaut-system svc/dynamic-toolset 9090:9090

# Check discovery metrics
curl http://localhost:9090/metrics | grep dynamictoolset_discovery

# Check error rates
curl http://localhost:9090/metrics | grep dynamictoolset_discovery_errors_total
```

#### Trace API Requests

```bash
# Enable request tracing
kubectl set env deployment/dynamic-toolset \
  -n kubernaut-system \
  LOG_LEVEL=debug \
  TRACE_REQUESTS=true

# Watch API request logs
kubectl logs -f -n kubernaut-system -l app=dynamic-toolset | grep "method="
```

---

## üìö Documentation Index

### Getting Started (You Are Here)
- ‚úÖ Installation and prerequisites
- ‚úÖ First discovery example
- ‚úÖ Common workflows
- ‚úÖ Complete API reference (6 endpoints)
- ‚úÖ Configuration (30+ environment variables)
- ‚úÖ Troubleshooting (6 detailed scenarios)

### Core Documentation
1. **[Implementation Plan](./implementation/IMPLEMENTATION_PLAN_ENHANCED.md)** - 12-day implementation timeline
2. **[BR Coverage Matrix](./BR_COVERAGE_MATRIX.md)** - Business requirement traceability (8/8 BRs, 232 tests)
3. **[Testing Strategy](./implementation/testing/TESTING_STRATEGY.md)** - Comprehensive test approach (100% pass rate)
4. **[Production Readiness](./implementation/PRODUCTION_READINESS_REPORT.md)** - 101/109 points (92.7%)
5. **[Handoff Summary](./implementation/00-HANDOFF-SUMMARY.md)** - Complete implementation summary

### Design Decisions
- **[DD-TOOLSET-001](./implementation/design/01-detector-interface-design.md)** - Detector interface design
- **[DD-TOOLSET-002](./implementation/design/DD-TOOLSET-002-discovery-loop-architecture.md)** - Discovery loop (periodic vs. watch)
- **[DD-TOOLSET-003](./implementation/design/DD-TOOLSET-003-reconciliation-strategy.md)** - Reconciliation strategy
- **[ConfigMap Schema](./implementation/design/02-configmap-schema-validation.md)** - Schema validation

### Testing Documentation
- **[Integration-First Rationale](./implementation/testing/01-integration-first-rationale.md)** - Why integration tests first
- **[E2E Test Plan (V2)](./implementation/testing/03-e2e-test-plan.md)** - E2E test plan for in-cluster deployment
- **[Testing Strategy](./implementation/testing/TESTING_STRATEGY.md)** - Comprehensive testing approach

### Implementation Tracking
- **[Day 7 Complete](./implementation/phase0/07-day7-complete.md)** - Schema validation & testing infrastructure
- **[Implementation Plan](./implementation/IMPLEMENTATION_PLAN_ENHANCED.md)** - Detailed 12-day timeline
- **[Deployment Manifests](../../deploy/dynamic-toolset/)** - Kubernetes YAML files (V1 ready)

---

## üìû Quick Links

- **Parent**: [../README.md](../README.md) - All stateless services
- **Consumer**: [../holmesgpt-api/](../holmesgpt-api/) - Uses generated toolsets
- **Architecture**: [../../architecture/](../../architecture/)

---

**Document Maintainer**: Kubernaut Documentation Team
**Last Updated**: 2025-10-06
**Status**: ‚úÖ Complete

