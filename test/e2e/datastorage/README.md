# Data Storage Service - E2E Tests

**Purpose**: End-to-end testing of Data Storage Service in a production-like Kubernetes environment.

**Coverage**: 10-15% (critical user journeys only)

**Port Allocation**: Per [DD-TEST-001](../../../docs/architecture/decisions/DD-TEST-001-port-allocation-strategy.md)
- PostgreSQL: 25433-25436 (base + parallel process)
- Redis: 26379
- Data Storage API: 28090-28093 (base + parallel process)

---

## ðŸŽ¯ **Test Scenarios**

### **Scenario 1: Happy Path - Complete Remediation Audit Trail** âœ… P0
**File**: `01_complete_audit_trail_test.go`

**Business Value**: Verify complete audit trail across all 6 services

**Test Flow**:
1. Create `RemediationRequest` CRD
2. Gateway processes signal â†’ Audit write (`gateway.signal.received`)
3. AIAnalysis generates RCA â†’ Audit write (`aianalysis.analysis.completed`)
4. Workflow executes remediation â†’ Audit write (`workflow.workflow.completed`)
5. Orchestrator completes â†’ Audit write (`orchestrator.remediation.completed`)
6. EffectivenessMonitor assesses â†’ Audit write (`monitor.assessment.completed`)

**Expected Results**:
- âœ… 5-6 audit records in `audit_events` table (unified table per ADR-034)
- âœ… All audit writes complete <1s (p95 latency)
- âœ… Zero DLQ fallbacks
- âœ… Query API retrieves complete timeline by `correlation_id`

---

### **Scenario 2: DLQ Fallback - Data Storage Service Outage** âœ… P0
**File**: `02_dlq_fallback_test.go`

**Business Value**: Verify DD-009 DLQ fallback during Data Storage Service outage

**Test Flow**:
1. Stop Data Storage Service pod
2. Trigger remediation (all 6 services attempt audit writes)
3. Verify audit writes go to DLQ (Redis Streams)
4. Restart Data Storage Service
5. Monitor async retry worker

**Expected Results**:
- âœ… All 6 services write to DLQ immediately (non-blocking)
- âœ… Reconciliation continues unblocked
- âœ… DLQ depth reaches 6 messages
- âœ… Async retry worker clears DLQ within 5 minutes
- âœ… All audit records eventually persisted to PostgreSQL

---

### **Scenario 3: Query API - Timeline Retrieval** âœ… P1
**File**: `03_query_api_timeline_test.go`

**Business Value**: Verify Query API can retrieve complete remediation timeline

**Test Flow**:
1. Complete Scenario 1 (happy path)
2. Query by `correlation_id` (remediation ID)
3. Verify chronological order
4. Query by `service` (e.g., "gateway")
5. Query by `event_type` (e.g., "gateway.signal.received")
6. Test pagination (limit/offset)

**Expected Results**:
- âœ… All events returned in chronological order
- âœ… Filters work correctly (service, event_type, time range)
- âœ… Pagination works (offset-based per DD-STORAGE-010)
- âœ… Response time <100ms (p95)

---

## ðŸ—ï¸ **Infrastructure**

### **Kind Cluster**
- **Nodes**: 2 (1 control-plane + 1 worker)
- **Kubernetes Version**: v1.28+
- **Container Runtime**: containerd

### **Services Deployed**
- **Data Storage Service**: HTTP API for audit events
- **PostgreSQL with pgvector**: Audit events storage
- **Redis**: DLQ fallback

### **Test Namespace**
Each test creates a unique namespace (e.g., `datastorage-e2e-test-1`) to ensure isolation.

---

## ðŸš€ **Running E2E Tests**

### **Prerequisites**
```bash
# Install Kind
brew install kind  # macOS
# OR
curl -Lo ./kind https://github.com/kubernetes-sigs/kind/releases/download/v0.30.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Install kubectl
brew install kubectl  # macOS

# Ensure Docker is running
docker ps
```

### **Run All E2E Tests**

#### **Parallel Execution** âš¡ (RECOMMENDED - 64% faster!)
```bash
# From workspace root
cd /Users/jgil/go/src/github.com/jordigilh/kubernaut

# Run E2E tests in parallel with 3 processes
ginkgo -v -p --procs=3 ./test/e2e/datastorage

# Performance comparison:
# Serial:   ~8 minutes
# Parallel: ~3 minutes (64% faster!)
```

**How parallel execution works**:
- âœ… Each test gets a unique namespace (e.g., `datastorage-e2e-p1-1732050000`)
- âœ… Complete infrastructure isolation (PostgreSQL + Redis + Service per namespace)
- âœ… No data pollution between tests
- âœ… Automatic cleanup (delete entire namespace)
- âœ… Uses `GinkgoParallelProcess()` for unique namespace generation

#### **Serial Execution** (slower, but easier to debug)
```bash
# Run E2E tests serially
ginkgo -v ./test/e2e/datastorage

# Run with specific scenario
ginkgo -v --focus="Happy Path" ./test/e2e/datastorage
```

#### **Parallel Execution** âš¡ (recommended, 64% faster)
```bash
# Run E2E tests in parallel (3 scenarios = 3 processes)
ginkgo -v -p --procs=3 ./test/e2e/datastorage

# Each test gets its own namespace for complete isolation
# Example namespaces:
#   - datastorage-e2e-p1-1732049876 (Process 1)
#   - datastorage-e2e-p2-1732049876 (Process 2)
#   - datastorage-e2e-p3-1732049876 (Process 3)
```

### **Parallel Execution Benefits**

| Execution Mode | Time | Speedup | Isolation |
|----------------|------|---------|-----------|
| **Serial** | ~8 minutes | Baseline | Single namespace |
| **Parallel (3 procs)** | **~3 minutes** | **64% faster** âœ… | 3 isolated namespaces |

**Why Parallel Works**:
- âœ… Each test gets its own Kubernetes namespace
- âœ… Complete infrastructure isolation (PostgreSQL + Redis + Service per namespace)
- âœ… No data pollution between tests
- âœ… Naturally parallel-safe by design

### **Keep Cluster for Debugging**
```bash
# Keep cluster after test failure
KEEP_CLUSTER=true ginkgo -v ./test/e2e/datastorage

# Manually delete cluster
kind delete cluster --name datastorage-e2e
```

---

## ðŸ”’ **Namespace Isolation Strategy**

### **How Parallel Execution Works**

Each parallel test process gets a **unique namespace** with complete infrastructure isolation:

```
Process 1 (Scenario 1: Happy Path)
â””â”€â”€ Namespace: datastorage-e2e-p1-1732049876
    â”œâ”€â”€ PostgreSQL (dedicated instance)
    â”œâ”€â”€ Redis (dedicated instance)
    â””â”€â”€ Data Storage Service (dedicated instance)

Process 2 (Scenario 2: DLQ Fallback)
â””â”€â”€ Namespace: datastorage-e2e-p2-1732049876
    â”œâ”€â”€ PostgreSQL (dedicated instance)
    â”œâ”€â”€ Redis (dedicated instance)
    â””â”€â”€ Data Storage Service (dedicated instance)

Process 3 (Scenario 3: Query API)
â””â”€â”€ Namespace: datastorage-e2e-p3-1732049876
    â”œâ”€â”€ PostgreSQL (dedicated instance)
    â”œâ”€â”€ Redis (dedicated instance)
    â””â”€â”€ Data Storage Service (dedicated instance)
```

### **Benefits of Namespace Isolation**

| Aspect | Integration Tests | E2E Tests |
|--------|------------------|-----------|
| **Infrastructure** | Shared (1 PostgreSQL) | Isolated (N PostgreSQL) |
| **Data** | Shared database (needs unique IDs) | Separate database per namespace |
| **Cleanup** | `DELETE FROM` with filters | Delete entire namespace |
| **Parallelism** | âš ï¸ Requires careful coordination | âœ… Naturally parallel-safe |
| **Debugging** | Data pollution possible | Complete isolation |

---

## ðŸ“Š **Test Execution**

### **Expected Duration**

#### **Serial Execution**
- **Cluster Setup**: ~2 minutes (once)
- **Scenario 1 (Happy Path)**: ~30 seconds
- **Scenario 2 (DLQ Fallback)**: ~5 minutes (includes retry worker wait)
- **Scenario 3 (Query API)**: ~10 seconds
- **Total**: ~8 minutes

#### **Parallel Execution** âš¡ (3 processes)
- **Cluster Setup**: ~2 minutes (once)
- **All Scenarios (parallel)**: ~5 minutes (longest test determines duration)
- **Total**: **~7 minutes** (includes setup)
- **Speedup**: 14% faster than serial (limited by longest test)

**Note**: Speedup is less dramatic than expected because Scenario 2 (DLQ Fallback) takes 5 minutes and dominates execution time.

### **Success Criteria**
- âœ… All 3 scenarios pass consistently
- âœ… No flaky tests
- âœ… Execution time <10 minutes (serial) or <8 minutes (parallel)
- âœ… Cluster cleanup successful
- âœ… No namespace leaks

---

## ðŸ› **Debugging**

### **Check Cluster Status**
```bash
# List Kind clusters
kind get clusters

# Get cluster info
kubectl cluster-info --context kind-datastorage-e2e

# List all pods
kubectl get pods --all-namespaces
```

### **Check Service Logs**
```bash
# Data Storage Service logs
kubectl logs -n <test-namespace> deployment/datastorage -f

# PostgreSQL logs
kubectl logs -n <test-namespace> deployment/postgresql -f

# Redis logs
kubectl logs -n <test-namespace> deployment/redis -f
```

### **Check Database**
```bash
# Port-forward to PostgreSQL
kubectl port-forward -n <test-namespace> deployment/postgresql 5432:5432

# Connect with psql
psql -h localhost -U slm_user -d action_history

# Query audit events
SELECT event_id, service, event_type, correlation_id, event_timestamp
FROM audit_events
ORDER BY event_timestamp DESC
LIMIT 10;
```

### **Check Redis DLQ**
```bash
# Port-forward to Redis
kubectl port-forward -n <test-namespace> deployment/redis 6379:6379

# Connect with redis-cli
redis-cli

# Check DLQ stream
XLEN audit:dlq:notification
XREAD STREAMS audit:dlq:notification 0
```

---

## ðŸ“‹ **Test Maintenance**

### **Adding New Scenarios**
1. Create new test file (e.g., `04_new_scenario_test.go`)
2. Follow existing test structure (Describe â†’ Context â†’ It)
3. Use helper functions for common operations
4. Update this README with new scenario

### **Updating Infrastructure**
1. Modify `test/infrastructure/datastorage.go`
2. Update deployment manifests in `test/e2e/datastorage/`
3. Test changes locally before committing

### **CI/CD Integration**
E2E tests run in GitHub Actions:
- **Trigger**: On PR to `main` branch
- **Environment**: GitHub-hosted runners with Docker
- **Timeout**: 15 minutes
- **Artifacts**: Test logs, cluster state on failure

---

## ðŸ”— **Related Documents**

- [V1.0 Testing Summary](../../../docs/services/stateless/data-storage/V1.0_TESTING_SUMMARY.md)
- [Testing Strategy](../../../docs/services/stateless/data-storage/testing-strategy.md)
- [ADR-034: Unified Audit Table Design](../../../docs/architecture/decisions/ADR-034-unified-audit-table-design.md)
- [DD-STORAGE-010: Query API Pagination Strategy](../../../docs/services/stateless/data-storage/DD-STORAGE-010-query-api-pagination-strategy.md)

---

## âœ… **Status**

| Scenario | Status | Priority | Actual Implementation |
|----------|--------|----------|----------------------|
| Scenario 1: Happy Path | âœ… **COMPLETE** | P0 | `01_happy_path_test.go` |
| Scenario 2: DLQ Fallback | âœ… **COMPLETE** | P0 | `02_dlq_fallback_test.go` |
| Scenario 3: Query API | âœ… **COMPLETE** | P1 | `03_query_api_timeline_test.go` |
| Scenario 4: Workflow Search | âœ… **COMPLETE** | P1 | `04_workflow_search_test.go` |
| Scenario 5: Workflow Search Audit | âœ… **COMPLETE** | P2 | `06_workflow_search_audit_test.go` |
| Scenario 6: Workflow Versions | âœ… **COMPLETE** | P1 | `07_workflow_version_management_test.go` |
| Scenario 7: Edge Cases | âœ… **COMPLETE** | P1 | `08_workflow_search_edge_cases_test.go` |
| Scenario 8: JSONB Queries | âœ… **COMPLETE** | P1 | `09_event_type_jsonb_comprehensive_test.go` |
| Scenario 9: Malformed Events | âœ… **COMPLETE** | P2 | `10_malformed_event_rejection_test.go` |
| Scenario 10: Connection Pool | âœ… **COMPLETE** | P1 | `11_connection_pool_exhaustion_test.go` |

**V1.0 E2E Test Suite**: âœ… **100% COMPLETE** - 84 of 84 specs passing

