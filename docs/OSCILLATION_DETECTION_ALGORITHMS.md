# Oscillation Detection Algorithms

**Objective**: Implement oscillation detection to prevent infinite loops and action thrashing
**Backend**: PostgreSQL database with optimized SQL queries for pattern detection
**Target**: Real-time detection and prevention of problematic action sequences

## Algorithm Overview

### **Core Oscillation Patterns Detected**

1. **Scale Oscillation**: Rapid scaling up/down cycles (scale_deployment)
2. **Resource Thrashing**: Constant resource adjustments (increase_resources â†” scale_deployment)
3. **Ineffective Loops**: Repeated failed actions with low effectiveness scores
4. **Cascading Failures**: Action sequences that trigger more problems than they solve
5. **Restart Loops**: Continuous pod/service restart cycles

### **Detection Architecture**
```
Real-time Action â†’ Pattern Analysis â†’ Confidence Scoring â†’ Prevention Decision
     â†“                    â†“                â†“                    â†“
Database Insert â†’ SQL Queries â†’ Statistical Analysis â†’ Block/Alert/Log
```

## ðŸ” **Pattern Detection Algorithms**

### **1. Scale Oscillation Detection**

#### **Algorithm Logic**
Detect when scaling actions alternate direction within a short time window

```sql
-- Scale Oscillation Detection Query
WITH scale_actions AS (
    SELECT
        rat.id,
        rat.action_timestamp,
        rat.action_parameters->>'replicas' as replica_count,
        LAG(rat.action_parameters->>'replicas') OVER (
            PARTITION BY ah.resource_id
            ORDER BY rat.action_timestamp
        ) as prev_replica_count,
        LAG(rat.action_timestamp) OVER (
            PARTITION BY ah.resource_id
            ORDER BY rat.action_timestamp
        ) as prev_timestamp,
        rat.effectiveness_score
    FROM resource_action_traces rat
    JOIN action_histories ah ON rat.action_history_id = ah.id
    JOIN resource_references rr ON ah.resource_id = rr.id
    WHERE rat.action_type = 'scale_deployment'
    AND rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
    AND rat.action_timestamp > NOW() - INTERVAL '$4 minutes'
),
direction_changes AS (
    SELECT
        id,
        action_timestamp,
        replica_count::int,
        prev_replica_count::int,
        prev_timestamp,
        effectiveness_score,
        CASE
            WHEN replica_count::int > prev_replica_count::int THEN 'up'
            WHEN replica_count::int < prev_replica_count::int THEN 'down'
            ELSE 'none'
        END as direction,
        LAG(CASE
            WHEN replica_count::int > prev_replica_count::int THEN 'up'
            WHEN replica_count::int < prev_replica_count::int THEN 'down'
            ELSE 'none'
        END) OVER (ORDER BY action_timestamp) as prev_direction
    FROM scale_actions
    WHERE prev_replica_count IS NOT NULL
),
oscillation_sequences AS (
    SELECT
        COUNT(*) as direction_changes,
        MIN(action_timestamp) as first_change,
        MAX(action_timestamp) as last_change,
        AVG(effectiveness_score) as avg_effectiveness,
        EXTRACT(EPOCH FROM (MAX(action_timestamp) - MIN(action_timestamp)))/60 as duration_minutes
    FROM direction_changes
    WHERE direction != prev_direction
    AND direction != 'none'
    AND prev_direction != 'none'
    AND action_timestamp - prev_timestamp < INTERVAL '30 minutes'
)
SELECT
    direction_changes,
    first_change,
    last_change,
    avg_effectiveness,
    duration_minutes,
    CASE
        WHEN direction_changes >= 4 AND duration_minutes <= 60 AND avg_effectiveness < 0.5 THEN 'critical'
        WHEN direction_changes >= 3 AND duration_minutes <= 120 AND avg_effectiveness < 0.7 THEN 'high'
        WHEN direction_changes >= 2 AND duration_minutes <= 180 THEN 'medium'
        ELSE 'low'
    END as severity
FROM oscillation_sequences
WHERE direction_changes >= 2;
```

#### **Go Implementation**

```go
// Scale Oscillation Detector
type ScaleOscillationDetector struct {
    db     *sql.DB
    logger *logrus.Logger
}

type ScaleOscillationResult struct {
    DirectionChanges  int                    `json:"direction_changes"`
    FirstChange      time.Time              `json:"first_change"`
    LastChange       time.Time              `json:"last_change"`
    AvgEffectiveness float64                `json:"avg_effectiveness"`
    DurationMinutes  float64                `json:"duration_minutes"`
    Severity         OscillationSeverity    `json:"severity"`
    ActionSequence   []ScaleActionDetail    `json:"action_sequence"`
}

type ScaleActionDetail struct {
    Timestamp    time.Time `json:"timestamp"`
    ReplicaCount int       `json:"replica_count"`
    Direction    string    `json:"direction"` // up, down, none
    Effectiveness float64  `json:"effectiveness"`
}

func (d *ScaleOscillationDetector) DetectScaleOscillation(ctx context.Context, resourceRef ResourceReference, windowMinutes int) (*ScaleOscillationResult, error) {
    query := `
        WITH scale_actions AS (
            SELECT
                rat.id,
                rat.action_timestamp,
                rat.action_parameters->>'replicas' as replica_count,
                LAG(rat.action_parameters->>'replicas') OVER (
                    PARTITION BY ah.resource_id
                    ORDER BY rat.action_timestamp
                ) as prev_replica_count,
                LAG(rat.action_timestamp) OVER (
                    PARTITION BY ah.resource_id
                    ORDER BY rat.action_timestamp
                ) as prev_timestamp,
                COALESCE(rat.effectiveness_score, 0.0) as effectiveness_score
            FROM resource_action_traces rat
            JOIN action_histories ah ON rat.action_history_id = ah.id
            JOIN resource_references rr ON ah.resource_id = rr.id
            WHERE rat.action_type = 'scale_deployment'
            AND rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
            AND rat.action_timestamp > NOW() - INTERVAL '%d minutes'
        ),
        direction_changes AS (
            SELECT
                id,
                action_timestamp,
                replica_count::int,
                prev_replica_count::int,
                prev_timestamp,
                effectiveness_score,
                CASE
                    WHEN replica_count::int > prev_replica_count::int THEN 'up'
                    WHEN replica_count::int < prev_replica_count::int THEN 'down'
                    ELSE 'none'
                END as direction,
                LAG(CASE
                    WHEN replica_count::int > prev_replica_count::int THEN 'up'
                    WHEN replica_count::int < prev_replica_count::int THEN 'down'
                    ELSE 'none'
                END) OVER (ORDER BY action_timestamp) as prev_direction
            FROM scale_actions
            WHERE prev_replica_count IS NOT NULL
        ),
        oscillation_analysis AS (
            SELECT
                COUNT(*) FILTER (WHERE direction != prev_direction AND direction != 'none' AND prev_direction != 'none') as direction_changes,
                MIN(action_timestamp) as first_change,
                MAX(action_timestamp) as last_change,
                AVG(effectiveness_score) as avg_effectiveness,
                EXTRACT(EPOCH FROM (MAX(action_timestamp) - MIN(action_timestamp)))/60 as duration_minutes,
                array_agg(
                    json_build_object(
                        'timestamp', action_timestamp,
                        'replica_count', replica_count,
                        'direction', direction,
                        'effectiveness', effectiveness_score
                    ) ORDER BY action_timestamp
                ) as action_sequence
            FROM direction_changes
        )
        SELECT
            direction_changes,
            first_change,
            last_change,
            avg_effectiveness,
            duration_minutes,
            action_sequence,
            CASE
                WHEN direction_changes >= 4 AND duration_minutes <= 60 AND avg_effectiveness < 0.5 THEN 'critical'
                WHEN direction_changes >= 3 AND duration_minutes <= 120 AND avg_effectiveness < 0.7 THEN 'high'
                WHEN direction_changes >= 2 AND duration_minutes <= 180 THEN 'medium'
                ELSE 'low'
            END as severity
        FROM oscillation_analysis
        WHERE direction_changes >= 2`

    formattedQuery := fmt.Sprintf(query, windowMinutes)

    var result ScaleOscillationResult
    var actionSequenceJSON []byte
    var severityStr string

    err := d.db.QueryRowContext(ctx, formattedQuery,
        resourceRef.Namespace, resourceRef.Kind, resourceRef.Name).Scan(
        &result.DirectionChanges,
        &result.FirstChange,
        &result.LastChange,
        &result.AvgEffectiveness,
        &result.DurationMinutes,
        &actionSequenceJSON,
        &severityStr,
    )

    if err != nil {
        if err == sql.ErrNoRows {
            return nil, nil // No oscillation detected
        }
        return nil, fmt.Errorf("failed to detect scale oscillation: %w", err)
    }

    // Parse action sequence JSON
    if err := json.Unmarshal(actionSequenceJSON, &result.ActionSequence); err != nil {
        return nil, fmt.Errorf("failed to parse action sequence: %w", err)
    }

    result.Severity = OscillationSeverity(severityStr)

    d.logger.WithFields(logrus.Fields{
        "resource":          resourceRef,
        "direction_changes": result.DirectionChanges,
        "severity":         result.Severity,
        "duration_minutes": result.DurationMinutes,
    }).Info("Scale oscillation detected")

    return &result, nil
}
```

### **2. Resource Thrashing Detection**

#### **Algorithm Logic**
Detect alternating resource adjustments and scaling decisions

```sql
-- Resource Thrashing Detection Query
WITH resource_actions AS (
    SELECT
        rat.id,
        rat.action_timestamp,
        rat.action_type,
        rat.action_parameters,
        rat.effectiveness_score,
        LAG(rat.action_type) OVER (
            PARTITION BY ah.resource_id
            ORDER BY rat.action_timestamp
        ) as prev_action_type,
        LAG(rat.action_timestamp) OVER (
            PARTITION BY ah.resource_id
            ORDER BY rat.action_timestamp
        ) as prev_timestamp
    FROM resource_action_traces rat
    JOIN action_histories ah ON rat.action_history_id = ah.id
    JOIN resource_references rr ON ah.resource_id = rr.id
    WHERE rat.action_type IN ('increase_resources', 'scale_deployment')
    AND rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
    AND rat.action_timestamp > NOW() - INTERVAL '$4 minutes'
),
thrashing_patterns AS (
    SELECT
        action_timestamp,
        action_type,
        prev_action_type,
        effectiveness_score,
        EXTRACT(EPOCH FROM (action_timestamp - prev_timestamp))/60 as time_gap_minutes,
        CASE
            WHEN (action_type = 'increase_resources' AND prev_action_type = 'scale_deployment') OR
                 (action_type = 'scale_deployment' AND prev_action_type = 'increase_resources')
            THEN 1 ELSE 0
        END as is_thrashing_transition
    FROM resource_actions
    WHERE prev_action_type IS NOT NULL
    AND action_timestamp - prev_timestamp < INTERVAL '45 minutes'
),
thrashing_analysis AS (
    SELECT
        COUNT(*) FILTER (WHERE is_thrashing_transition = 1) as thrashing_transitions,
        COUNT(*) as total_actions,
        MIN(action_timestamp) as first_action,
        MAX(action_timestamp) as last_action,
        AVG(effectiveness_score) as avg_effectiveness,
        AVG(time_gap_minutes) as avg_time_gap_minutes
    FROM thrashing_patterns
)
SELECT
    thrashing_transitions,
    total_actions,
    first_action,
    last_action,
    avg_effectiveness,
    avg_time_gap_minutes,
    CASE
        WHEN thrashing_transitions >= 3 AND avg_effectiveness < 0.6 THEN 'critical'
        WHEN thrashing_transitions >= 2 AND avg_effectiveness < 0.7 THEN 'high'
        WHEN thrashing_transitions >= 1 AND avg_time_gap_minutes < 15 THEN 'medium'
        ELSE 'low'
    END as severity
FROM thrashing_analysis
WHERE thrashing_transitions >= 1;
```

#### **Go Implementation**

```go
// Resource Thrashing Detector
type ResourceThrashingDetector struct {
    db     *sql.DB
    logger *logrus.Logger
}

type ResourceThrashingResult struct {
    ThrashingTransitions int                      `json:"thrashing_transitions"`
    TotalActions        int                      `json:"total_actions"`
    FirstAction         time.Time                `json:"first_action"`
    LastAction          time.Time                `json:"last_action"`
    AvgEffectiveness    float64                  `json:"avg_effectiveness"`
    AvgTimeGapMinutes   float64                  `json:"avg_time_gap_minutes"`
    Severity           OscillationSeverity       `json:"severity"`
    ActionPattern      []ResourceActionDetail    `json:"action_pattern"`
}

type ResourceActionDetail struct {
    Timestamp       time.Time              `json:"timestamp"`
    ActionType      string                 `json:"action_type"`
    Parameters      map[string]interface{} `json:"parameters"`
    Effectiveness   float64                `json:"effectiveness"`
    TimeGapMinutes  float64                `json:"time_gap_minutes"`
}

func (d *ResourceThrashingDetector) DetectResourceThrashing(ctx context.Context, resourceRef ResourceReference, windowMinutes int) (*ResourceThrashingResult, error) {
    // First get the summary analysis
    summaryQuery := fmt.Sprintf(`
        WITH resource_actions AS (
            SELECT
                rat.action_timestamp,
                rat.action_type,
                rat.action_parameters,
                rat.effectiveness_score,
                LAG(rat.action_type) OVER (
                    PARTITION BY ah.resource_id
                    ORDER BY rat.action_timestamp
                ) as prev_action_type,
                LAG(rat.action_timestamp) OVER (
                    PARTITION BY ah.resource_id
                    ORDER BY rat.action_timestamp
                ) as prev_timestamp
            FROM resource_action_traces rat
            JOIN action_histories ah ON rat.action_history_id = ah.id
            JOIN resource_references rr ON ah.resource_id = rr.id
            WHERE rat.action_type IN ('increase_resources', 'scale_deployment')
            AND rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
            AND rat.action_timestamp > NOW() - INTERVAL '%d minutes'
        ),
        thrashing_patterns AS (
            SELECT
                action_timestamp,
                action_type,
                prev_action_type,
                COALESCE(effectiveness_score, 0.0) as effectiveness_score,
                EXTRACT(EPOCH FROM (action_timestamp - prev_timestamp))/60 as time_gap_minutes,
                CASE
                    WHEN (action_type = 'increase_resources' AND prev_action_type = 'scale_deployment') OR
                         (action_type = 'scale_deployment' AND prev_action_type = 'increase_resources')
                    THEN 1 ELSE 0
                END as is_thrashing_transition
            FROM resource_actions
            WHERE prev_action_type IS NOT NULL
            AND action_timestamp - prev_timestamp < INTERVAL '45 minutes'
        ),
        thrashing_analysis AS (
            SELECT
                COUNT(*) FILTER (WHERE is_thrashing_transition = 1) as thrashing_transitions,
                COUNT(*) as total_actions,
                MIN(action_timestamp) as first_action,
                MAX(action_timestamp) as last_action,
                AVG(effectiveness_score) as avg_effectiveness,
                AVG(time_gap_minutes) as avg_time_gap_minutes
            FROM thrashing_patterns
        )
        SELECT
            thrashing_transitions,
            total_actions,
            first_action,
            last_action,
            avg_effectiveness,
            avg_time_gap_minutes,
            CASE
                WHEN thrashing_transitions >= 3 AND avg_effectiveness < 0.6 THEN 'critical'
                WHEN thrashing_transitions >= 2 AND avg_effectiveness < 0.7 THEN 'high'
                WHEN thrashing_transitions >= 1 AND avg_time_gap_minutes < 15 THEN 'medium'
                ELSE 'low'
            END as severity
        FROM thrashing_analysis
        WHERE thrashing_transitions >= 1`, windowMinutes)

    var result ResourceThrashingResult
    var severityStr string

    err := d.db.QueryRowContext(ctx, summaryQuery,
        resourceRef.Namespace, resourceRef.Kind, resourceRef.Name).Scan(
        &result.ThrashingTransitions,
        &result.TotalActions,
        &result.FirstAction,
        &result.LastAction,
        &result.AvgEffectiveness,
        &result.AvgTimeGapMinutes,
        &severityStr,
    )

    if err != nil {
        if err == sql.ErrNoRows {
            return nil, nil // No thrashing detected
        }
        return nil, fmt.Errorf("failed to detect resource thrashing: %w", err)
    }

    result.Severity = OscillationSeverity(severityStr)

    // Get detailed action pattern if thrashing detected
    if result.ThrashingTransitions > 0 {
        patterns, err := d.getDetailedActionPattern(ctx, resourceRef, windowMinutes)
        if err != nil {
            d.logger.WithError(err).Warn("Failed to get detailed action pattern")
        } else {
            result.ActionPattern = patterns
        }
    }

    d.logger.WithFields(logrus.Fields{
        "resource":             resourceRef,
        "thrashing_transitions": result.ThrashingTransitions,
        "severity":            result.Severity,
        "avg_effectiveness":   result.AvgEffectiveness,
    }).Info("Resource thrashing detected")

    return &result, nil
}

func (d *ResourceThrashingDetector) getDetailedActionPattern(ctx context.Context, resourceRef ResourceReference, windowMinutes int) ([]ResourceActionDetail, error) {
    detailQuery := fmt.Sprintf(`
        SELECT
            rat.action_timestamp,
            rat.action_type,
            rat.action_parameters,
            COALESCE(rat.effectiveness_score, 0.0) as effectiveness_score,
            COALESCE(EXTRACT(EPOCH FROM (rat.action_timestamp - LAG(rat.action_timestamp) OVER (ORDER BY rat.action_timestamp)))/60, 0) as time_gap_minutes
        FROM resource_action_traces rat
        JOIN action_histories ah ON rat.action_history_id = ah.id
        JOIN resource_references rr ON ah.resource_id = rr.id
        WHERE rat.action_type IN ('increase_resources', 'scale_deployment')
        AND rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
        AND rat.action_timestamp > NOW() - INTERVAL '%d minutes'
        ORDER BY rat.action_timestamp`, windowMinutes)

    rows, err := d.db.QueryContext(ctx, detailQuery,
        resourceRef.Namespace, resourceRef.Kind, resourceRef.Name)
    if err != nil {
        return nil, fmt.Errorf("failed to query detailed action pattern: %w", err)
    }
    defer rows.Close()

    var patterns []ResourceActionDetail
    for rows.Next() {
        var detail ResourceActionDetail
        var parametersJSON []byte

        err := rows.Scan(
            &detail.Timestamp,
            &detail.ActionType,
            &parametersJSON,
            &detail.Effectiveness,
            &detail.TimeGapMinutes,
        )
        if err != nil {
            return nil, fmt.Errorf("failed to scan action detail: %w", err)
        }

        if err := json.Unmarshal(parametersJSON, &detail.Parameters); err != nil {
            d.logger.WithError(err).Warn("Failed to unmarshal action parameters")
            detail.Parameters = make(map[string]interface{})
        }

        patterns = append(patterns, detail)
    }

    return patterns, nil
}
```

### **3. Ineffective Loop Detection**

#### **Algorithm Logic**
Detect repeated actions with consistently low effectiveness scores

```sql
-- Ineffective Loop Detection Query
WITH repeated_actions AS (
    SELECT
        rat.action_type,
        COUNT(*) as repetition_count,
        AVG(rat.effectiveness_score) as avg_effectiveness,
        STDDEV(rat.effectiveness_score) as effectiveness_stddev,
        MIN(rat.action_timestamp) as first_occurrence,
        MAX(rat.action_timestamp) as last_occurrence,
        EXTRACT(EPOCH FROM (MAX(rat.action_timestamp) - MIN(rat.action_timestamp)))/60 as span_minutes,
        array_agg(rat.effectiveness_score ORDER BY rat.action_timestamp) as effectiveness_scores,
        array_agg(rat.action_timestamp ORDER BY rat.action_timestamp) as timestamps
    FROM resource_action_traces rat
    JOIN action_histories ah ON rat.action_history_id = ah.id
    JOIN resource_references rr ON ah.resource_id = rr.id
    WHERE rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
    AND rat.action_timestamp > NOW() - INTERVAL '$4 minutes'
    AND rat.effectiveness_score IS NOT NULL
    GROUP BY rat.action_type
),
ineffective_patterns AS (
    SELECT
        action_type,
        repetition_count,
        avg_effectiveness,
        effectiveness_stddev,
        first_occurrence,
        last_occurrence,
        span_minutes,
        effectiveness_scores,
        timestamps,
        CASE
            WHEN repetition_count >= 5 AND avg_effectiveness < 0.3 THEN 'critical'
            WHEN repetition_count >= 4 AND avg_effectiveness < 0.5 THEN 'high'
            WHEN repetition_count >= 3 AND avg_effectiveness < 0.6 THEN 'medium'
            WHEN repetition_count >= 2 AND avg_effectiveness < 0.4 THEN 'low'
            ELSE 'none'
        END as severity,
        -- Calculate trend (are things getting worse?)
        CASE
            WHEN repetition_count >= 3 THEN
                (effectiveness_scores[array_length(effectiveness_scores, 1)] - effectiveness_scores[1]) /
                GREATEST(effectiveness_scores[1], 0.1)
            ELSE 0
        END as effectiveness_trend
    FROM repeated_actions
    WHERE repetition_count >= 2
)
SELECT
    action_type,
    repetition_count,
    avg_effectiveness,
    effectiveness_stddev,
    first_occurrence,
    last_occurrence,
    span_minutes,
    severity,
    effectiveness_trend,
    effectiveness_scores,
    timestamps
FROM ineffective_patterns
WHERE severity != 'none'
ORDER BY
    CASE severity
        WHEN 'critical' THEN 1
        WHEN 'high' THEN 2
        WHEN 'medium' THEN 3
        ELSE 4
    END,
    avg_effectiveness ASC;
```

#### **Go Implementation**

```go
// Ineffective Loop Detector
type IneffectiveLoopDetector struct {
    db     *sql.DB
    logger *logrus.Logger
}

type IneffectiveLoopResult struct {
    ActionType           string                  `json:"action_type"`
    RepetitionCount     int                     `json:"repetition_count"`
    AvgEffectiveness    float64                 `json:"avg_effectiveness"`
    EffectivenessStddev float64                 `json:"effectiveness_stddev"`
    FirstOccurrence     time.Time               `json:"first_occurrence"`
    LastOccurrence      time.Time               `json:"last_occurrence"`
    SpanMinutes         float64                 `json:"span_minutes"`
    Severity           OscillationSeverity      `json:"severity"`
    EffectivenessTrend float64                 `json:"effectiveness_trend"`
    EffectivenessScores []float64               `json:"effectiveness_scores"`
    Timestamps         []time.Time              `json:"timestamps"`
}

func (d *IneffectiveLoopDetector) DetectIneffectiveLoops(ctx context.Context, resourceRef ResourceReference, windowMinutes int) ([]IneffectiveLoopResult, error) {
    query := fmt.Sprintf(`
        WITH repeated_actions AS (
            SELECT
                rat.action_type,
                COUNT(*) as repetition_count,
                AVG(COALESCE(rat.effectiveness_score, 0.0)) as avg_effectiveness,
                STDDEV(COALESCE(rat.effectiveness_score, 0.0)) as effectiveness_stddev,
                MIN(rat.action_timestamp) as first_occurrence,
                MAX(rat.action_timestamp) as last_occurrence,
                EXTRACT(EPOCH FROM (MAX(rat.action_timestamp) - MIN(rat.action_timestamp)))/60 as span_minutes,
                array_agg(COALESCE(rat.effectiveness_score, 0.0) ORDER BY rat.action_timestamp) as effectiveness_scores,
                array_agg(rat.action_timestamp ORDER BY rat.action_timestamp) as timestamps
            FROM resource_action_traces rat
            JOIN action_histories ah ON rat.action_history_id = ah.id
            JOIN resource_references rr ON ah.resource_id = rr.id
            WHERE rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
            AND rat.action_timestamp > NOW() - INTERVAL '%d minutes'
            GROUP BY rat.action_type
        ),
        ineffective_patterns AS (
            SELECT
                action_type,
                repetition_count,
                avg_effectiveness,
                COALESCE(effectiveness_stddev, 0.0) as effectiveness_stddev,
                first_occurrence,
                last_occurrence,
                span_minutes,
                effectiveness_scores,
                timestamps,
                CASE
                    WHEN repetition_count >= 5 AND avg_effectiveness < 0.3 THEN 'critical'
                    WHEN repetition_count >= 4 AND avg_effectiveness < 0.5 THEN 'high'
                    WHEN repetition_count >= 3 AND avg_effectiveness < 0.6 THEN 'medium'
                    WHEN repetition_count >= 2 AND avg_effectiveness < 0.4 THEN 'low'
                    ELSE 'none'
                END as severity,
                CASE
                    WHEN repetition_count >= 3 THEN
                        (effectiveness_scores[array_length(effectiveness_scores, 1)] - effectiveness_scores[1]) /
                        GREATEST(effectiveness_scores[1], 0.1)
                    ELSE 0
                END as effectiveness_trend
            FROM repeated_actions
            WHERE repetition_count >= 2
        )
        SELECT
            action_type,
            repetition_count,
            avg_effectiveness,
            effectiveness_stddev,
            first_occurrence,
            last_occurrence,
            span_minutes,
            severity,
            effectiveness_trend,
            effectiveness_scores,
            timestamps
        FROM ineffective_patterns
        WHERE severity != 'none'
        ORDER BY
            CASE severity
                WHEN 'critical' THEN 1
                WHEN 'high' THEN 2
                WHEN 'medium' THEN 3
                ELSE 4
            END,
            avg_effectiveness ASC`, windowMinutes)

    rows, err := d.db.QueryContext(ctx, query,
        resourceRef.Namespace, resourceRef.Kind, resourceRef.Name)
    if err != nil {
        return nil, fmt.Errorf("failed to detect ineffective loops: %w", err)
    }
    defer rows.Close()

    var results []IneffectiveLoopResult
    for rows.Next() {
        var result IneffectiveLoopResult
        var severityStr string
        var effectivenessScoresArray pq.Float64Array
        var timestampsArray pq.StringArray

        err := rows.Scan(
            &result.ActionType,
            &result.RepetitionCount,
            &result.AvgEffectiveness,
            &result.EffectivenessStddev,
            &result.FirstOccurrence,
            &result.LastOccurrence,
            &result.SpanMinutes,
            &severityStr,
            &result.EffectivenessTrend,
            &effectivenessScoresArray,
            &timestampsArray,
        )
        if err != nil {
            return nil, fmt.Errorf("failed to scan ineffective loop result: %w", err)
        }

        result.Severity = OscillationSeverity(severityStr)
        result.EffectivenessScores = []float64(effectivenessScoresArray)

        // Parse timestamps
        result.Timestamps = make([]time.Time, len(timestampsArray))
        for i, timestampStr := range timestampsArray {
            if timestamp, err := time.Parse(time.RFC3339, timestampStr); err == nil {
                result.Timestamps[i] = timestamp
            }
        }

        results = append(results, result)

        d.logger.WithFields(logrus.Fields{
            "resource":          resourceRef,
            "action_type":       result.ActionType,
            "repetition_count":  result.RepetitionCount,
            "avg_effectiveness": result.AvgEffectiveness,
            "severity":          result.Severity,
        }).Warn("Ineffective loop detected")
    }

    return results, nil
}
```

### **4. Cascading Failure Detection**

#### **Algorithm Logic**
Detect when actions trigger more alerts than they resolve

```sql
-- Cascading Failure Detection Query
WITH action_outcomes AS (
    SELECT
        rat.id,
        rat.action_timestamp,
        rat.action_type,
        rat.alert_name as original_alert,
        rat.effectiveness_score,
        -- Look for new alerts in the 30 minutes after action
        (
            SELECT COUNT(DISTINCT rat2.alert_name)
            FROM resource_action_traces rat2
            JOIN action_histories ah2 ON rat2.action_history_id = ah2.id
            WHERE ah2.resource_id = ah.resource_id
            AND rat2.action_timestamp BETWEEN rat.action_timestamp AND rat.action_timestamp + INTERVAL '30 minutes'
            AND rat2.alert_name != rat.alert_name
        ) as new_alerts_triggered,
        -- Check if original alert resolved
        (
            SELECT COUNT(*)
            FROM resource_action_traces rat3
            JOIN action_histories ah3 ON rat3.action_history_id = ah3.id
            WHERE ah3.resource_id = ah.resource_id
            AND rat3.action_timestamp > rat.action_timestamp
            AND rat3.alert_name = rat.alert_name
            LIMIT 1
        ) as original_alert_recurred
    FROM resource_action_traces rat
    JOIN action_histories ah ON rat.action_history_id = ah.id
    JOIN resource_references rr ON ah.resource_id = rr.id
    WHERE rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
    AND rat.action_timestamp > NOW() - INTERVAL '$4 minutes'
),
cascading_analysis AS (
    SELECT
        action_type,
        COUNT(*) as total_actions,
        AVG(new_alerts_triggered) as avg_new_alerts,
        AVG(CASE WHEN original_alert_recurred > 0 THEN 1.0 ELSE 0.0 END) as recurrence_rate,
        AVG(effectiveness_score) as avg_effectiveness,
        SUM(CASE WHEN new_alerts_triggered > 0 THEN 1 ELSE 0 END) as actions_causing_cascades,
        MAX(new_alerts_triggered) as max_alerts_triggered
    FROM action_outcomes
    GROUP BY action_type
)
SELECT
    action_type,
    total_actions,
    avg_new_alerts,
    recurrence_rate,
    avg_effectiveness,
    actions_causing_cascades,
    max_alerts_triggered,
    CASE
        WHEN avg_new_alerts > 2.0 AND recurrence_rate > 0.5 THEN 'critical'
        WHEN avg_new_alerts > 1.5 OR recurrence_rate > 0.7 THEN 'high'
        WHEN avg_new_alerts > 1.0 OR recurrence_rate > 0.4 THEN 'medium'
        WHEN actions_causing_cascades > 0 THEN 'low'
        ELSE 'none'
    END as severity
FROM cascading_analysis
WHERE actions_causing_cascades > 0
ORDER BY avg_new_alerts DESC, recurrence_rate DESC;
```

#### **Go Implementation**

```go
// Cascading Failure Detector
type CascadingFailureDetector struct {
    db     *sql.DB
    logger *logrus.Logger
}

type CascadingFailureResult struct {
    ActionType            string              `json:"action_type"`
    TotalActions         int                 `json:"total_actions"`
    AvgNewAlerts         float64             `json:"avg_new_alerts"`
    RecurrenceRate       float64             `json:"recurrence_rate"`
    AvgEffectiveness     float64             `json:"avg_effectiveness"`
    ActionsCausingCascades int               `json:"actions_causing_cascades"`
    MaxAlertsTriggered   int                 `json:"max_alerts_triggered"`
    Severity            OscillationSeverity  `json:"severity"`
}

func (d *CascadingFailureDetector) DetectCascadingFailures(ctx context.Context, resourceRef ResourceReference, windowMinutes int) ([]CascadingFailureResult, error) {
    query := fmt.Sprintf(`
        WITH action_outcomes AS (
            SELECT
                rat.id,
                rat.action_timestamp,
                rat.action_type,
                rat.alert_name as original_alert,
                COALESCE(rat.effectiveness_score, 0.0) as effectiveness_score,
                (
                    SELECT COUNT(DISTINCT rat2.alert_name)
                    FROM resource_action_traces rat2
                    JOIN action_histories ah2 ON rat2.action_history_id = ah2.id
                    WHERE ah2.resource_id = ah.resource_id
                    AND rat2.action_timestamp BETWEEN rat.action_timestamp AND rat.action_timestamp + INTERVAL '30 minutes'
                    AND rat2.alert_name != rat.alert_name
                ) as new_alerts_triggered,
                (
                    SELECT COUNT(*)
                    FROM resource_action_traces rat3
                    JOIN action_histories ah3 ON rat3.action_history_id = ah3.id
                    WHERE ah3.resource_id = ah.resource_id
                    AND rat3.action_timestamp > rat.action_timestamp
                    AND rat3.alert_name = rat.alert_name
                    LIMIT 1
                ) as original_alert_recurred
            FROM resource_action_traces rat
            JOIN action_histories ah ON rat.action_history_id = ah.id
            JOIN resource_references rr ON ah.resource_id = rr.id
            WHERE rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
            AND rat.action_timestamp > NOW() - INTERVAL '%d minutes'
        ),
        cascading_analysis AS (
            SELECT
                action_type,
                COUNT(*) as total_actions,
                AVG(new_alerts_triggered::float) as avg_new_alerts,
                AVG(CASE WHEN original_alert_recurred > 0 THEN 1.0 ELSE 0.0 END) as recurrence_rate,
                AVG(effectiveness_score) as avg_effectiveness,
                SUM(CASE WHEN new_alerts_triggered > 0 THEN 1 ELSE 0 END) as actions_causing_cascades,
                MAX(new_alerts_triggered) as max_alerts_triggered
            FROM action_outcomes
            GROUP BY action_type
        )
        SELECT
            action_type,
            total_actions,
            avg_new_alerts,
            recurrence_rate,
            avg_effectiveness,
            actions_causing_cascades,
            max_alerts_triggered,
            CASE
                WHEN avg_new_alerts > 2.0 AND recurrence_rate > 0.5 THEN 'critical'
                WHEN avg_new_alerts > 1.5 OR recurrence_rate > 0.7 THEN 'high'
                WHEN avg_new_alerts > 1.0 OR recurrence_rate > 0.4 THEN 'medium'
                WHEN actions_causing_cascades > 0 THEN 'low'
                ELSE 'none'
            END as severity
        FROM cascading_analysis
        WHERE actions_causing_cascades > 0
        ORDER BY avg_new_alerts DESC, recurrence_rate DESC`, windowMinutes)

    rows, err := d.db.QueryContext(ctx, query,
        resourceRef.Namespace, resourceRef.Kind, resourceRef.Name)
    if err != nil {
        return nil, fmt.Errorf("failed to detect cascading failures: %w", err)
    }
    defer rows.Close()

    var results []CascadingFailureResult
    for rows.Next() {
        var result CascadingFailureResult
        var severityStr string

        err := rows.Scan(
            &result.ActionType,
            &result.TotalActions,
            &result.AvgNewAlerts,
            &result.RecurrenceRate,
            &result.AvgEffectiveness,
            &result.ActionsCausingCascades,
            &result.MaxAlertsTriggered,
            &severityStr,
        )
        if err != nil {
            return nil, fmt.Errorf("failed to scan cascading failure result: %w", err)
        }

        result.Severity = OscillationSeverity(severityStr)
        results = append(results, result)

        d.logger.WithFields(logrus.Fields{
            "resource":                 resourceRef,
            "action_type":              result.ActionType,
            "avg_new_alerts":          result.AvgNewAlerts,
            "recurrence_rate":         result.RecurrenceRate,
            "actions_causing_cascades": result.ActionsCausingCascades,
            "severity":                result.Severity,
        }).Warn("Cascading failure pattern detected")
    }

    return results, nil
}
```

## Unified Oscillation Detection Engine

### **Main Detection Coordinator**

```go
// Main oscillation detection engine
type OscillationDetectionEngine struct {
    scaleDetector     *ScaleOscillationDetector
    thrashingDetector *ResourceThrashingDetector
    loopDetector     *IneffectiveLoopDetector
    cascadeDetector  *CascadingFailureDetector
    db              *sql.DB
    logger          *logrus.Logger
}

type OscillationAnalysisResult struct {
    ResourceReference  ResourceReference                `json:"resource_reference"`
    AnalysisTimestamp time.Time                        `json:"analysis_timestamp"`
    WindowMinutes     int                              `json:"window_minutes"`

    // Detection results
    ScaleOscillation   *ScaleOscillationResult         `json:"scale_oscillation,omitempty"`
    ResourceThrashing  *ResourceThrashingResult        `json:"resource_thrashing,omitempty"`
    IneffectiveLoops   []IneffectiveLoopResult         `json:"ineffective_loops,omitempty"`
    CascadingFailures  []CascadingFailureResult        `json:"cascading_failures,omitempty"`

    // Overall assessment
    OverallSeverity    OscillationSeverity             `json:"overall_severity"`
    RecommendedAction  PreventionAction                `json:"recommended_action"`
    Confidence        float64                          `json:"confidence"`

    // Prevention history
    PreviousPrevention *PreventionRecord               `json:"previous_prevention,omitempty"`
}

type PreventionAction string

const (
    PreventionNone          PreventionAction = "none"
    PreventionBlock         PreventionAction = "block"
    PreventionEscalate      PreventionAction = "escalate"
    PreventionAlternative   PreventionAction = "alternative"
    PreventionCoolingPeriod PreventionAction = "cooling_period"
)

type PreventionRecord struct {
    Timestamp     time.Time        `json:"timestamp"`
    Action        PreventionAction `json:"action"`
    Reason        string           `json:"reason"`
    EffectiveTime time.Duration    `json:"effective_time"`
    Successful    bool             `json:"successful"`
}

func NewOscillationDetectionEngine(db *sql.DB, logger *logrus.Logger) *OscillationDetectionEngine {
    return &OscillationDetectionEngine{
        scaleDetector:     &ScaleOscillationDetector{db: db, logger: logger},
        thrashingDetector: &ResourceThrashingDetector{db: db, logger: logger},
        loopDetector:     &IneffectiveLoopDetector{db: db, logger: logger},
        cascadeDetector:  &CascadingFailureDetector{db: db, logger: logger},
        db:              db,
        logger:          logger,
    }
}

func (e *OscillationDetectionEngine) AnalyzeResource(ctx context.Context, resourceRef ResourceReference, windowMinutes int) (*OscillationAnalysisResult, error) {
    result := &OscillationAnalysisResult{
        ResourceReference: resourceRef,
        AnalysisTimestamp: time.Now(),
        WindowMinutes:     windowMinutes,
        OverallSeverity:   "none",
    }

    // Run all detectors in parallel
    var wg sync.WaitGroup
    var mu sync.Mutex
    var detectionErrors []error

    // Scale oscillation detection
    wg.Add(1)
    go func() {
        defer wg.Done()
        scaleResult, err := e.scaleDetector.DetectScaleOscillation(ctx, resourceRef, windowMinutes)
        mu.Lock()
        defer mu.Unlock()
        if err != nil {
            detectionErrors = append(detectionErrors, fmt.Errorf("scale detection failed: %w", err))
        } else if scaleResult != nil {
            result.ScaleOscillation = scaleResult
            result.OverallSeverity = maxSeverity(result.OverallSeverity, scaleResult.Severity)
        }
    }()

    // Resource thrashing detection
    wg.Add(1)
    go func() {
        defer wg.Done()
        thrashingResult, err := e.thrashingDetector.DetectResourceThrashing(ctx, resourceRef, windowMinutes)
        mu.Lock()
        defer mu.Unlock()
        if err != nil {
            detectionErrors = append(detectionErrors, fmt.Errorf("thrashing detection failed: %w", err))
        } else if thrashingResult != nil {
            result.ResourceThrashing = thrashingResult
            result.OverallSeverity = maxSeverity(result.OverallSeverity, thrashingResult.Severity)
        }
    }()

    // Ineffective loop detection
    wg.Add(1)
    go func() {
        defer wg.Done()
        loopResults, err := e.loopDetector.DetectIneffectiveLoops(ctx, resourceRef, windowMinutes)
        mu.Lock()
        defer mu.Unlock()
        if err != nil {
            detectionErrors = append(detectionErrors, fmt.Errorf("loop detection failed: %w", err))
        } else if len(loopResults) > 0 {
            result.IneffectiveLoops = loopResults
            for _, loop := range loopResults {
                result.OverallSeverity = maxSeverity(result.OverallSeverity, loop.Severity)
            }
        }
    }()

    // Cascading failure detection
    wg.Add(1)
    go func() {
        defer wg.Done()
        cascadeResults, err := e.cascadeDetector.DetectCascadingFailures(ctx, resourceRef, windowMinutes)
        mu.Lock()
        defer mu.Unlock()
        if err != nil {
            detectionErrors = append(detectionErrors, fmt.Errorf("cascade detection failed: %w", err))
        } else if len(cascadeResults) > 0 {
            result.CascadingFailures = cascadeResults
            for _, cascade := range cascadeResults {
                result.OverallSeverity = maxSeverity(result.OverallSeverity, cascade.Severity)
            }
        }
    }()

    wg.Wait()

    // Handle detection errors
    if len(detectionErrors) > 0 {
        e.logger.WithField("errors", detectionErrors).Error("Some oscillation detectors failed")
        // Continue with partial results
    }

    // Determine recommended prevention action
    result.RecommendedAction, result.Confidence = e.determinePreventionAction(result)

    // Check for previous prevention attempts
    prevPrevention, err := e.getPreviousPrevention(ctx, resourceRef)
    if err != nil {
        e.logger.WithError(err).Warn("Failed to get previous prevention record")
    } else {
        result.PreviousPrevention = prevPrevention
    }

    // Store detection result in database
    if err := e.storeDetectionResult(ctx, result); err != nil {
        e.logger.WithError(err).Error("Failed to store detection result")
    }

    return result, nil
}

func (e *OscillationDetectionEngine) determinePreventionAction(result *OscillationAnalysisResult) (PreventionAction, float64) {
    // Calculate confidence based on multiple indicators
    confidence := 0.0
    detectionCount := 0

    if result.ScaleOscillation != nil {
        detectionCount++
        confidence += float64(severityToScore(result.ScaleOscillation.Severity))
    }

    if result.ResourceThrashing != nil {
        detectionCount++
        confidence += float64(severityToScore(result.ResourceThrashing.Severity))
    }

    if len(result.IneffectiveLoops) > 0 {
        detectionCount++
        for _, loop := range result.IneffectiveLoops {
            confidence += float64(severityToScore(loop.Severity))
        }
    }

    if len(result.CascadingFailures) > 0 {
        detectionCount++
        for _, cascade := range result.CascadingFailures {
            confidence += float64(severityToScore(cascade.Severity))
        }
    }

    if detectionCount > 0 {
        confidence = confidence / float64(detectionCount) / 4.0 // Normalize to 0-1
    }

    // Determine action based on severity and confidence
    switch result.OverallSeverity {
    case "critical":
        if confidence > 0.8 {
            return PreventionBlock, confidence
        }
        return PreventionEscalate, confidence

    case "high":
        if confidence > 0.7 {
            return PreventionCoolingPeriod, confidence
        }
        return PreventionAlternative, confidence

    case "medium":
        return PreventionAlternative, confidence

    case "low":
        return PreventionNone, confidence

    default:
        return PreventionNone, 0.0
    }
}

func severityToScore(severity OscillationSeverity) int {
    switch severity {
    case "critical": return 4
    case "high": return 3
    case "medium": return 2
    case "low": return 1
    default: return 0
    }
}

func maxSeverity(current, new OscillationSeverity) OscillationSeverity {
    currentScore := severityToScore(current)
    newScore := severityToScore(new)

    if newScore > currentScore {
        return new
    }
    return current
}

func (e *OscillationDetectionEngine) storeDetectionResult(ctx context.Context, result *OscillationAnalysisResult) error {
    // Store oscillation detection in database for audit trail and learning
    query := `
        INSERT INTO oscillation_detections (
            pattern_id, resource_id, detected_at, confidence, action_count,
            time_span_minutes, pattern_evidence, prevention_applied,
            prevention_action, prevention_details
        ) VALUES (
            $1, $2, $3, $4, $5, $6, $7, $8, $9, $10
        )`

    // Get resource ID
    resourceID, err := e.getResourceID(ctx, result.ResourceReference)
    if err != nil {
        return fmt.Errorf("failed to get resource ID: %w", err)
    }

    // Convert result to JSON for evidence storage
    evidenceJSON, err := json.Marshal(result)
    if err != nil {
        return fmt.Errorf("failed to marshal evidence: %w", err)
    }

    actionCount := 0
    if result.ScaleOscillation != nil {
        actionCount += result.ScaleOscillation.DirectionChanges
    }
    if result.ResourceThrashing != nil {
        actionCount += result.ResourceThrashing.ThrashingTransitions
    }

    _, err = e.db.ExecContext(ctx, query,
        1, // Default pattern ID - in production, this would be dynamic
        resourceID,
        result.AnalysisTimestamp,
        result.Confidence,
        actionCount,
        result.WindowMinutes,
        evidenceJSON,
        result.RecommendedAction != PreventionNone,
        string(result.RecommendedAction),
        nil, // prevention_details - would be populated when action is taken
    )

    return err
}

func (e *OscillationDetectionEngine) getResourceID(ctx context.Context, resourceRef ResourceReference) (int64, error) {
    var resourceID int64
    query := `
        SELECT id FROM resource_references
        WHERE namespace = $1 AND kind = $2 AND name = $3
        LIMIT 1`

    err := e.db.QueryRowContext(ctx, query,
        resourceRef.Namespace, resourceRef.Kind, resourceRef.Name).Scan(&resourceID)

    if err == sql.ErrNoRows {
        return 0, fmt.Errorf("resource not found: %+v", resourceRef)
    }

    return resourceID, err
}

func (e *OscillationDetectionEngine) getPreviousPrevention(ctx context.Context, resourceRef ResourceReference) (*PreventionRecord, error) {
    query := `
        SELECT detected_at, prevention_action, prevention_successful
        FROM oscillation_detections od
        JOIN resource_references rr ON od.resource_id = rr.id
        WHERE rr.namespace = $1 AND rr.kind = $2 AND rr.name = $3
        AND od.prevention_applied = true
        ORDER BY od.detected_at DESC
        LIMIT 1`

    var record PreventionRecord
    var actionStr string

    err := e.db.QueryRowContext(ctx, query,
        resourceRef.Namespace, resourceRef.Kind, resourceRef.Name).Scan(
        &record.Timestamp,
        &actionStr,
        &record.Successful,
    )

    if err == sql.ErrNoRows {
        return nil, nil // No previous prevention
    }

    if err != nil {
        return nil, fmt.Errorf("failed to query previous prevention: %w", err)
    }

    record.Action = PreventionAction(actionStr)
    record.EffectiveTime = time.Since(record.Timestamp)

    return &record, nil
}
```

## Prevention Integration

### **MCP Tool for AI Models**

```go
// MCP tool for oscillation checking
func (server *ActionHistoryMCPServer) ValidateActionSafety(params map[string]interface{}) (interface{}, error) {
    namespace := params["namespace"].(string)
    resourceName := params["resource_name"].(string)
    proposedAction := params["proposed_action"].(string)
    resourceKind := params["resource_kind"].(string)

    resourceRef := ResourceReference{
        Namespace: namespace,
        Kind:      resourceKind,
        Name:      resourceName,
    }

    // Run oscillation analysis
    analysis, err := server.oscillationEngine.AnalyzeResource(context.Background(), resourceRef, 120) // 2 hour window
    if err != nil {
        return nil, fmt.Errorf("failed to analyze oscillation patterns: %w", err)
    }

    // Determine safety
    isSafe := analysis.OverallSeverity == "none" || analysis.OverallSeverity == "low"

    response := map[string]interface{}{
        "is_safe": isSafe,
        "severity": string(analysis.OverallSeverity),
        "confidence": analysis.Confidence,
        "recommended_action": string(analysis.RecommendedAction),
        "patterns_detected": map[string]interface{}{
            "scale_oscillation": analysis.ScaleOscillation != nil,
            "resource_thrashing": analysis.ResourceThrashing != nil,
            "ineffective_loops": len(analysis.IneffectiveLoops) > 0,
            "cascading_failures": len(analysis.CascadingFailures) > 0,
        },
        "reasoning": generateSafetyReasoning(analysis),
    }

    if analysis.PreviousPrevention != nil {
        response["previous_prevention"] = map[string]interface{}{
            "action": string(analysis.PreviousPrevention.Action),
            "timestamp": analysis.PreviousPrevention.Timestamp,
            "successful": analysis.PreviousPrevention.Successful,
            "time_since": analysis.PreviousPrevention.EffectiveTime.String(),
        }
    }

    return response, nil
}

func generateSafetyReasoning(analysis *OscillationAnalysisResult) string {
    if analysis.OverallSeverity == "none" {
        return "No oscillation patterns detected. Action appears safe to proceed."
    }

    var reasons []string

    if analysis.ScaleOscillation != nil {
        reasons = append(reasons, fmt.Sprintf(
            "Scale oscillation detected: %d direction changes with %.1f%% effectiveness",
            analysis.ScaleOscillation.DirectionChanges,
            analysis.ScaleOscillation.AvgEffectiveness*100,
        ))
    }

    if analysis.ResourceThrashing != nil {
        reasons = append(reasons, fmt.Sprintf(
            "Resource thrashing detected: %d transitions between resource/scale actions",
            analysis.ResourceThrashing.ThrashingTransitions,
        ))
    }

    if len(analysis.IneffectiveLoops) > 0 {
        for _, loop := range analysis.IneffectiveLoops {
            reasons = append(reasons, fmt.Sprintf(
                "Ineffective loop: %s action repeated %d times with %.1f%% effectiveness",
                loop.ActionType, loop.RepetitionCount, loop.AvgEffectiveness*100,
            ))
        }
    }

    if len(analysis.CascadingFailures) > 0 {
        for _, cascade := range analysis.CascadingFailures {
            reasons = append(reasons, fmt.Sprintf(
                "Cascading failure risk: %s actions trigger %.1f new alerts on average",
                cascade.ActionType, cascade.AvgNewAlerts,
            ))
        }
    }

    return fmt.Sprintf("CAUTION: %s. Recommended action: %s",
        strings.Join(reasons, "; "), analysis.RecommendedAction)
}
```

## Next Steps

The oscillation detection algorithms are now complete with:

**Scale Oscillation Detection** - SQL + Go implementation
**Resource Thrashing Detection** - Cross-action pattern analysis
**Ineffective Loop Detection** - Statistical effectiveness analysis
**Cascading Failure Detection** - Multi-alert correlation
**Unified Detection Engine** - Parallel analysis with confidence scoring
**MCP Integration** - AI model safety validation

**Ready for implementation** with:
- Advanced SQL queries optimized for PostgreSQL
- Parallel Go implementations for performance
- Confidence scoring and prevention recommendations
- Database storage for audit trail and learning
- MCP tool integration for real-time AI model guidance

The system can now detect and prevent infinite loops before they damage production systems!

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "Create comprehensive model comparison analysis", "status": "completed", "activeForm": "Creating comprehensive model comparison analysis"}, {"content": "Update extended model comparison document with all results", "status": "completed", "activeForm": "Updating extended model comparison document with all results"}, {"content": "Begin Phase 1.1: Extended Model Comparison Study with Granite 8B baseline", "status": "completed", "activeForm": "Beginning Phase 1.1: Extended Model Comparison Study with Granite 8B baseline"}, {"content": "Test Granite 3.3:2b model for multi-modal routing", "status": "completed", "activeForm": "Testing Granite 3.3:2b model for multi-modal routing"}, {"content": "Test Gemma2:2b model for multi-modal routing", "status": "completed", "activeForm": "Testing Gemma2:2b model for multi-modal routing"}, {"content": "Create comprehensive multi-modal routing model comparison", "status": "completed", "activeForm": "Creating comprehensive multi-modal routing model comparison"}, {"content": "Design Kubernetes CRD storage for persistent action tracking", "status": "completed", "activeForm": "Designing Kubernetes CRD storage for persistent action tracking"}, {"content": "Create oscillation detection algorithms (scale, resource, ineffective patterns)", "status": "completed", "activeForm": "Creating oscillation detection algorithms"}]