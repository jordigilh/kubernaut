# E2E Disk Space Optimization Strategy

**Date**: January 3, 2026 15:30 PST
**Context**: AI Analysis E2E tests failing due to disk space exhaustion
**Goal**: Aggressive disk space management with tracking at each stage

---

## ğŸ¯ **PROBLEM STATEMENT**

### **Current Issues**:
- âŒ AI Analysis E2E tests fail with "no space left on device"
- âŒ Image builds consume ~10-15 GB total (3 services Ã— 3-5 GB each)
- âŒ Duplicate storage: Podman cache + Kind images = 2x disk usage
- âŒ GitHub Actions runners have limited disk space (~14 GB available)

### **Current Fixes Applied**:
1. âœ… Podman image cleanup after Kind load (commits 2db193760, 47e4fc784)
2. âœ… `.tar` file deletion after Kind load

### **Remaining Challenge**:
- âš ï¸ **Podman build cache** still consumes significant space during parallel builds
- âš ï¸ **No visibility** into disk space at each stage for diagnostics

---

## ğŸ’¡ **PROPOSED SOLUTION**

### **Strategy: Aggressive Cleanup + Disk Space Tracking**

```
PHASE 1: Build images (parallel)         â†’ Track disk space
PHASE 2: Export images to .tar files     â†’ Track disk space
PHASE 3: Podman system prune (AGGRESSIVE) â†’ Track disk space freed
PHASE 4: Create Kind cluster              â†’ Track disk space
PHASE 5: Load images from .tar into Kind  â†’ Track disk space
PHASE 6: Delete .tar files                â†’ Track disk space
```

**Key Innovation**: `podman system prune -a` AFTER builds but BEFORE Kind starts

**Benefits**:
1. âœ… **Removes build cache** (~3-5 GB freed)
2. âœ… **Removes intermediate layers** (~2-4 GB freed)
3. âœ… **Keeps final images as .tar files** (safe for Kind load)
4. âœ… **Total savings**: ~5-9 GB (enough to prevent failures)
5. âœ… **Diagnostic visibility**: Track disk space at every stage

---

## ğŸ› ï¸ **IMPLEMENTATION**

### **Helper Function: Disk Space Tracker**

```go
// getDiskSpaceInfo returns disk space info in human-readable format
func getDiskSpaceInfo() (total, used, available string, err error) {
	// Use 'df -h /' to get root filesystem stats
	cmd := exec.Command("df", "-h", "/")
	output, err := cmd.CombinedOutput()
	if err != nil {
		return "", "", "", fmt.Errorf("failed to get disk space: %w", err)
	}

	// Parse output (skip header line)
	lines := strings.Split(string(output), "\n")
	if len(lines) < 2 {
		return "", "", "", fmt.Errorf("unexpected df output")
	}

	// Example output:
	// Filesystem      Size  Used Avail Use% Mounted on
	// /dev/sda1        50G   35G   15G  70% /
	fields := strings.Fields(lines[1])
	if len(fields) < 4 {
		return "", "", "", fmt.Errorf("unexpected df fields")
	}

	return fields[1], fields[2], fields[3], nil
}

// logDiskSpace logs disk space at a specific stage
func logDiskSpace(stage string, writer io.Writer) {
	total, used, available, err := getDiskSpaceInfo()
	if err != nil {
		fmt.Fprintf(writer, "  âš ï¸  [%s] Failed to get disk space: %v\n", stage, err)
		return
	}

	fmt.Fprintf(writer, "  ğŸ’¾ [%s] Disk: %s total, %s used, %s available\n",
		stage, total, used, available)
}
```

### **Modified CreateAIAnalysisClusterHybrid Flow**

```go
func CreateAIAnalysisClusterHybrid(clusterName, kubeconfigPath string, writer io.Writer) error {
	ctx := context.Background()
	namespace := "kubernaut-system"

	fmt.Fprintln(writer, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Fprintln(writer, "ğŸš€ AIAnalysis E2E Infrastructure (HYBRID PARALLEL + DISK OPTIMIZATION)")
	fmt.Fprintln(writer, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// STAGE 0: Initial disk space
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	logDiskSpace("START", writer)

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 1: Build images IN PARALLEL
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ“¦ PHASE 1: Building images in parallel...")

	// ... existing parallel build code ...

	fmt.Fprintln(writer, "\nâœ… All images built!")
	logDiskSpace("IMAGES_BUILT", writer)

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 2: Export images to .tar files (prepare for Kind load)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ“¦ PHASE 2: Exporting images to .tar files...")

	tarFiles := make(map[string]string)
	for name, image := range builtImages {
		tarPath := fmt.Sprintf("/tmp/%s-e2e.tar", name)
		tarFiles[name] = tarPath

		fmt.Fprintf(writer, "  ğŸ“¦ Exporting %s...\n", name)
		saveCmd := exec.Command("podman", "save", "-o", tarPath, image)
		saveCmd.Stdout = writer
		saveCmd.Stderr = writer
		if err := saveCmd.Run(); err != nil {
			return fmt.Errorf("failed to export %s image: %w", name, err)
		}
		fmt.Fprintf(writer, "  âœ… %s exported to %s\n", name, tarPath)
	}

	logDiskSpace("TAR_EXTRACTED", writer)

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 3: AGGRESSIVE PODMAN CLEANUP (before Kind starts)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ—‘ï¸  PHASE 3: Aggressive Podman cleanup (before Kind)...")
	fmt.Fprintln(writer, "  âš ï¸  This removes ALL Podman data (images, cache, layers)")
	fmt.Fprintln(writer, "  âœ… Safe: Final images are preserved as .tar files")

	// Run podman system prune -a (removes everything except running containers)
	pruneCmd := exec.Command("podman", "system", "prune", "-a", "-f")
	pruneCmd.Stdout = writer
	pruneCmd.Stderr = writer
	if err := pruneCmd.Run(); err != nil {
		fmt.Fprintf(writer, "  âš ï¸  Prune failed (non-fatal): %v\n", err)
	} else {
		fmt.Fprintln(writer, "  âœ… Podman cache cleared")
	}

	logDiskSpace("AFTER_PRUNE", writer)

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 4: Create Kind cluster (AFTER cleanup)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ“¦ PHASE 4: Creating Kind cluster...")
	if err := createAIAnalysisKindCluster(clusterName, kubeconfigPath, writer); err != nil {
		return fmt.Errorf("failed to create Kind cluster: %w", err)
	}

	fmt.Fprintln(writer, "ğŸ“ Creating namespace...")
	// ... existing namespace creation code ...

	fmt.Fprintln(writer, "ğŸ“‹ Installing AIAnalysis CRD...")
	// ... existing CRD installation code ...

	logDiskSpace("KIND_STARTED", writer)

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 5: Load images from .tar files into Kind
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ“¦ PHASE 5: Loading images into Kind cluster...")

	for name, tarPath := range tarFiles {
		fmt.Fprintf(writer, "  ğŸ“¦ Loading %s from .tar...\n", name)
		loadCmd := exec.Command("kind", "load", "image-archive", tarPath, "--name", clusterName)
		loadCmd.Env = append(os.Environ(), "KIND_EXPERIMENTAL_PROVIDER=podman")
		loadCmd.Stdout = writer
		loadCmd.Stderr = writer
		if err := loadCmd.Run(); err != nil {
			return fmt.Errorf("failed to load %s into Kind: %w", name, err)
		}
		fmt.Fprintf(writer, "  âœ… %s loaded into Kind\n", name)
	}

	logDiskSpace("IMAGES_LOADED", writer)

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 6: Delete .tar files (final cleanup)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ—‘ï¸  PHASE 6: Cleaning up .tar files...")
	for name, tarPath := range tarFiles {
		if err := os.Remove(tarPath); err != nil {
			fmt.Fprintf(writer, "  âš ï¸  Failed to remove %s (non-fatal): %v\n", tarPath, err)
		} else {
			fmt.Fprintf(writer, "  âœ… Removed %s\n", tarPath)
		}
	}

	logDiskSpace("END", writer)

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 7: Deploy infrastructure (PostgreSQL, Redis)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ˜ Deploying PostgreSQL...")
	// ... existing PostgreSQL deployment ...

	fmt.Fprintln(writer, "ğŸ”´ Deploying Redis...")
	// ... existing Redis deployment ...

	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	// PHASE 8: Deploy services (Data Storage, HolmesGPT-API, AIAnalysis)
	// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	fmt.Fprintln(writer, "\nğŸ’¾ Deploying Data Storage...")
	// ... existing deployment code ...

	fmt.Fprintln(writer, "ğŸ¤– Deploying HolmesGPT-API...")
	// ... existing deployment code ...

	fmt.Fprintln(writer, "ğŸ§  Deploying AIAnalysis controller...")
	// ... existing deployment code ...

	fmt.Fprintln(writer, "â³ Waiting for all services to be ready...")
	if err := waitForAllServicesReady(ctx, namespace, kubeconfigPath, writer); err != nil {
		return fmt.Errorf("services not ready: %w", err)
	}

	fmt.Fprintln(writer, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Fprintln(writer, "âœ… AIAnalysis E2E cluster ready!")
	logDiskSpace("FINAL", writer)
	fmt.Fprintln(writer, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	return nil
}
```

---

## ğŸ“Š **EXPECTED DISK SPACE REPORT**

### **Example Output**:
```
ğŸ’¾ [START] Disk: 50G total, 30G used, 20G available

ğŸ“¦ PHASE 1: Building images in parallel...
  âœ… datastorage image built
  âœ… holmesgpt-api image built
  âœ… aianalysis image built
ğŸ’¾ [IMAGES_BUILT] Disk: 50G total, 42G used, 8G available

ğŸ“¦ PHASE 2: Exporting images to .tar files...
  âœ… datastorage exported to /tmp/datastorage-e2e.tar
  âœ… holmesgpt-api exported to /tmp/holmesgpt-api-e2e.tar
  âœ… aianalysis exported to /tmp/aianalysis-e2e.tar
ğŸ’¾ [TAR_EXTRACTED] Disk: 50G total, 45G used, 5G available

ğŸ—‘ï¸  PHASE 3: Aggressive Podman cleanup...
  âœ… Podman cache cleared
ğŸ’¾ [AFTER_PRUNE] Disk: 50G total, 36G used, 14G available  â† 9G freed!

ğŸ“¦ PHASE 4: Creating Kind cluster...
ğŸ’¾ [KIND_STARTED] Disk: 50G total, 37G used, 13G available

ğŸ“¦ PHASE 5: Loading images into Kind cluster...
  âœ… datastorage loaded into Kind
  âœ… holmesgpt-api loaded into Kind
  âœ… aianalysis loaded into Kind
ğŸ’¾ [IMAGES_LOADED] Disk: 50G total, 42G used, 8G available

ğŸ—‘ï¸  PHASE 6: Cleaning up .tar files...
  âœ… Removed /tmp/datastorage-e2e.tar
  âœ… Removed /tmp/holmesgpt-api-e2e.tar
  âœ… Removed /tmp/aianalysis-e2e.tar
ğŸ’¾ [END] Disk: 50G total, 36G used, 14G available  â† Back to post-prune level

âœ… AIAnalysis E2E cluster ready!
ğŸ’¾ [FINAL] Disk: 50G total, 37G used, 13G available
```

---

## ğŸ¯ **DISK SPACE SAVINGS BREAKDOWN**

| Stage | Action | Space Freed | Cumulative Savings |
|-------|--------|-------------|-------------------|
| **IMAGES_BUILT** | 3 images built | -12G | -12G (used) |
| **TAR_EXTRACTED** | 3 .tar files created | -3G | -15G (used) |
| **AFTER_PRUNE** | `podman system prune -a` | +9G | -6G (net) |
| **IMAGES_LOADED** | Images in Kind | -5G | -11G (used) |
| **END** | .tar files deleted | +6G | -5G (final) |

**Net Result**: ~5-6 GB final usage (vs ~15 GB without optimization)

---

## âš ï¸ **RISKS & MITIGATIONS**

### **Risk 1: `podman system prune -a` removes ALL images**
- **Impact**: If .tar export fails, we lose the images
- **Mitigation**: Verify .tar files exist before pruning
- **Fallback**: Check .tar file sizes (should be > 100 MB)

### **Risk 2: .tar files consume 3-6 GB during PHASE 3-6**
- **Impact**: Temporary disk pressure during image load
- **Mitigation**: Aggressive prune first (frees 9 GB buffer)
- **Fallback**: Load images one-by-one, delete .tar after each

### **Risk 3: `df -h` parsing might fail on different systems**
- **Impact**: No disk space tracking
- **Mitigation**: Non-fatal error handling
- **Fallback**: Tests still run, just no visibility

---

## ğŸš€ **IMPLEMENTATION STEPS**

### **Step 1**: Add helper functions to `test/infrastructure/aianalysis.go`
```bash
# Add getDiskSpaceInfo() and logDiskSpace() functions
```

### **Step 2**: Modify `CreateAIAnalysisClusterHybrid()` with new flow
```bash
# Integrate PHASE 2 (tar export), PHASE 3 (prune), PHASE 6 (tar cleanup)
```

### **Step 3**: Test locally
```bash
make test-e2e-aianalysis
# Verify disk space tracking in output
```

### **Step 4**: Validate in GitHub Actions
```bash
# Push changes and monitor E2E run logs
# Confirm disk space reports at each stage
```

---

## ğŸ“ˆ **SUCCESS CRITERIA**

- âœ… AI Analysis E2E tests pass consistently (no disk space failures)
- âœ… Disk space report shows 9+ GB freed after prune
- âœ… Final disk usage < 40% of total capacity
- âœ… No manual intervention required (fully automated)

---

## ğŸ”— **ALTERNATIVE APPROACHES CONSIDERED**

### **Option A: Serial builds** (REJECTED)
- âŒ Slower (9-10 min vs 4 min parallel)
- âœ… Uses less peak disk space
- **Verdict**: Speed is more important in CI/CD

### **Option B: Prune AFTER each build** (REJECTED)
- âœ… Lower peak disk usage
- âŒ Removes images before export (breaks flow)
- **Verdict**: Need images for .tar export

### **Option C: Stream .tar directly to Kind** (FUTURE)
- âœ… No .tar files on disk
- âŒ Requires custom Kind load logic
- **Verdict**: Too complex for V1.0, consider for V2.0

---

## ğŸ“ **NEXT STEPS**

1. **Implement helper functions** (getDiskSpaceInfo, logDiskSpace)
2. **Modify CreateAIAnalysisClusterHybrid** with new flow
3. **Test locally** to validate disk space tracking
4. **Push and validate** in GitHub Actions
5. **Monitor E2E success rate** (expect 100% after fix)

---

**Document Status**: âœ… Ready for Implementation
**Estimated Implementation Time**: 1-2 hours
**Estimated Testing Time**: 30 minutes (local + CI/CD)
**Risk Level**: LOW (non-breaking change, existing cleanup + tracking)


