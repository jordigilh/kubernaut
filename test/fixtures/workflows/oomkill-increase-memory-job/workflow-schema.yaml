# OOMKill Increase Memory Workflow Schema - Job Backend (BR-WORKFLOW-004)
# Used by: FullPipeline E2E (execution.engine: job)
metadata:
  workflowId: oomkill-increase-memory-v1
  version: "1.0.0"
  description:
    what: "Increases memory limits for pods experiencing OOMKill events"
    whenToUse: "When pods are OOMKilled due to insufficient memory limits"
    whenNotToUse: "When OOM is caused by a memory leak requiring code fix"
    preconditions: "Pod is managed by a Deployment or StatefulSet"

actionType: IncreaseMemoryLimits

labels:
  signalType: OOMKilled
  severity: [critical, high]
  environment: [production, staging, test]
  component: "*"
  priority: "*"

execution:
  engine: job
  bundle: ghcr.io/kubernaut/workflows/oomkill-increase-memory-job@sha256:a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5f6a1b2

parameters:
  - name: TARGET_RESOURCE_KIND
    type: string
    required: true
    description: "Kubernetes resource kind (Deployment, StatefulSet, DaemonSet)"
  - name: TARGET_RESOURCE_NAME
    type: string
    required: true
    description: "Name of the resource to patch"
  - name: TARGET_NAMESPACE
    type: string
    required: true
    description: "Namespace of the resource"
  - name: MEMORY_LIMIT_NEW
    type: string
    required: true
    description: "New memory limit to apply (e.g., 128Mi, 256Mi, 1Gi)"
