---
globs: "*_test.go,test/**/*"
description: "Testing strategy and patterns for kubernaut's three-tier approach"
---

# Testing Strategy for Kubernaut

## Pyramid Testing Approach
Kubernaut implements a **pyramid testing strategy** with **90% overall confidence** through extensive unit test coverage:

### Unit Tests (70%+ - AT LEAST 70% of ALL BRs) - **MAXIMUM COVERAGE FOUNDATION LAYER**
**Location**: [test/unit/](mdc:test/unit/)
**Purpose**: **EXTENSIVE business logic validation covering ALL unit-testable business requirements**
**Coverage Mandate**: **AT LEAST 70% of total business requirements, extended to 100% of unit-testable BRs**
**Confidence**: 85-90%
**Execution**: `make test`
**Strategy**: **Use real business logic with mocks ONLY for external dependencies - MAXIMIZE unit test coverage**

**CRITICAL EXPANSION PRINCIPLE**: Unit tests should cover **ALL business requirements that can be unit tested with external mock dependencies**, even if some requirements are also tested in integration or e2e testing (defense-in-depth). The 70% minimum is a floor, not a ceiling.

```go
// Example: Comprehensive business logic testing with real components
Describe("BR-WORKFLOW-001: Intelligent Workflow Generation", func() {
    var (
        // Mock ONLY external dependencies
        mockLLMProvider *mocks.MockLLMProvider
        mockK8sClient   *mocks.MockKubernetesClient
        mockVectorDB    *mocks.MockVectorDatabase

        // Use REAL business logic components
        workflowBuilder *engine.IntelligentWorkflowBuilder
        safetyFramework *platform.SafetyFramework
        analyticsEngine *insights.AnalyticsEngine
    )

    BeforeEach(func() {
        // Mock external/infrastructure dependencies ONLY
        mockLLMProvider = mocks.NewMockLLMProvider()
        mockK8sClient = mocks.NewMockKubernetesClient()
        mockVectorDB = mocks.NewMockVectorDatabase()

        // Create REAL business components
        safetyFramework = platform.NewSafetyFramework(realConfig)
        analyticsEngine = insights.NewAnalyticsEngine(realConfig)
        workflowBuilder = engine.NewIntelligentWorkflowBuilder(
            mockLLMProvider,    // External: AI service
            mockK8sClient,      // External: Infrastructure
            safetyFramework,    // Real: Business safety logic
            analyticsEngine,    // Real: Business analytics logic
        )
    })

    It("should generate workflows with comprehensive business validation", func() {
        // Test REAL business logic integration and algorithms
        workflow, err := workflowBuilder.CreateWorkflowFromAlert(ctx, alert)

        // Validate REAL business outcomes and logic
        Expect(workflow.Template.SafetyValidation).ToNot(BeNil())
        Expect(safetyFramework.ValidateWorkflow(workflow)).To(Succeed())
        Expect(analyticsEngine.AssessWorkflowRisk(workflow)).To(BeNumerically("<", 0.3))
    })
})
```

### Integration Tests (20% - 40-60 BRs) - **INTERACTION LAYER**
**Location**: [test/integration/](mdc:test/integration/)
**Purpose**: **Cross-component behavior and data flow validation**
**Confidence**: 80-85%
**Execution**: `make test-integration-kind` (Kind cluster) or `make test-integration-kind-ci` (CI with mocked LLM)
**Strategy**: **Focus on component interactions with real business logic**

```go
// Example: Cross-component integration with real business logic
Describe("BR-INTEGRATION-001: Workflow Engine Integration", func() {
    It("should integrate workflow generation with execution pipeline", func() {
        // Test real component integration
        workflow := workflowEngine.CreateWorkflow(ctx, alert)
        executionResult := executionEngine.ExecuteWorkflow(ctx, workflow)

        // Validate cross-component business outcomes
        Expect(executionResult.Status).To(Equal("completed"))
        Expect(executionResult.BusinessMetrics.SuccessRate).To(BeNumerically(">", 0.9))
    })
})
```

### E2E Tests (10% - 15-25 BRs) - **BUSINESS WORKFLOW LAYER**
**Location**: [test/e2e/](mdc:test/e2e/)
**Purpose**: **Complete end-to-end business workflow validation**
**Confidence**: 90-95%
**Execution**: `make test-e2e-ocp` (OpenShift) or `make test-e2e-kind` (Kind cluster)
**Strategy**: **Complete business scenarios with minimal mocking**

## Defense in Depth Testing Strategy - EXPANDED UNIT COVERAGE WITH PYRAMID APPROACH

### **🛡️ Core Principle: MAXIMUM Unit Coverage with Strategic Multi-Layer Defense**

Kubernaut implements **defense in depth** testing with **EXPANDED unit test foundation** where business functionality is validated comprehensively at the unit level AND strategically at integration/e2e levels for critical scenarios. The expanded pyramid approach ensures **MAXIMUM coverage at the unit level** (70%+ minimum, extending to ALL unit-testable BRs) while maintaining defense layers for scenarios requiring real system integration.

**EXPANSION MANDATE**: Unit tests should cover **EVERY business requirement that can be tested with external mocks**, not just the 70% minimum. This creates a comprehensive foundation layer with strategic overlapping coverage at higher levels.

### **📊 Pyramid Defense Distribution - EXPANDED UNIT COVERAGE**

| **Layer** | **Coverage** | **Defense Focus** | **Business Logic** | **External Dependencies** |
|-----------|--------------|-------------------|-------------------|---------------------------|
| **Unit Tests (70%+ MINIMUM)** | **MAXIMUM - ALL Unit-Testable BRs** | Individual functions, algorithms, business rules | **100% Real** | **100% Mocked** |
| **Integration Tests (selective)** | **Focused** | Cross-component interactions, system integration | **100% Real** | **Selective Mocking** |
| **E2E Tests (critical only)** | **Essential Workflows** | Complete business scenarios | **100% Real** | **Minimal Mocking** |

**EXPANSION PRINCIPLE**: Unit tests should cover **EVERY business requirement that can be tested with mocked external dependencies**. Only requirements that inherently require real external systems should be relegated to integration/e2e tiers.

#### **Real-World Example: Workflow Generation Validation (EXPANDED Pyramid Defense)**

**Business Scenario**: Invalid action types in generated workflows could cause production failures.

**EXPANDED Pyramid Defense Strategy** (Maximum Unit Coverage + Strategic Overlap):

1. **Unit Test Layer (70%+ Coverage - MAXIMUM EXPANDED Primary Defense)**:
   ```go
   // COMPREHENSIVE unit testing with REAL business logic
   Describe("BR-WORKFLOW-VALIDATION-001: Action Type Generation", func() {
       var (
           // Mock ONLY external dependencies
           mockLLMProvider *mocks.MockLLMProvider
           mockK8sClient   *mocks.MockKubernetesClient

           // Use REAL business logic components
           workflowBuilder *engine.IntelligentWorkflowBuilder
           safetyFramework *platform.SafetyFramework
           templateEngine  *engine.TemplateEngine
       )

       BeforeEach(func() {
           mockLLMProvider = mocks.NewMockLLMProvider()
           mockK8sClient = mocks.NewMockKubernetesClient()

           // Create REAL business components
           safetyFramework = platform.NewSafetyFramework(realConfig)
           templateEngine = engine.NewTemplateEngine(realConfig)
           workflowBuilder = engine.NewIntelligentWorkflowBuilder(
               mockLLMProvider,    // External: AI service
               mockK8sClient,      // External: Infrastructure
               safetyFramework,    // Real: Business safety logic
               templateEngine,     // Real: Business template logic
           )
       })

       It("should generate only valid action types in all scenarios", func() {
           // Test REAL business logic with comprehensive scenarios
           scenarios := []AlertScenario{
               createHighMemoryAlert(),
               createPodCrashAlert(),
               createNetworkAlert(),
               createStorageAlert(),
           }

           for _, scenario := range scenarios {
               template := &engine.ExecutableTemplate{}

               // Test REAL business function
               workflowBuilder.AddValidationSteps(template, scenario)

               // Validate REAL business logic outcomes
               validActionTypes := safetyFramework.GetValidActionTypes()
               for _, step := range template.Steps {
                   if step.Action != nil {
                       Expect(validActionTypes).To(ContainElement(step.Action.Type),
                           "BR-WORKFLOW-VALIDATION-001: All generated action types must be valid for scenario %s", scenario.Type)
                   }
               }
           }
       })

       It("should handle edge cases in action type generation", func() {
           // Test REAL business logic edge cases - COMPREHENSIVE coverage
           edgeCases := []EdgeCase{
               createEmptyAlert(),
               createMalformedAlert(),
               createUnknownAlertType(),
               createMaxComplexityAlert(),
               createMinimalAlert(),
               createConflictingRequirementsAlert(),
           }

           for _, edgeCase := range edgeCases {
               template := &engine.ExecutableTemplate{}

               // Test REAL business logic resilience
               err := workflowBuilder.AddValidationSteps(template, edgeCase.Alert)

               if edgeCase.ShouldSucceed {
                   Expect(err).ToNot(HaveOccurred())
                   // Validate business logic handles edge case properly
                   Expect(len(template.Steps)).To(BeNumerically(">", 0))

                   // EXPANDED unit testing - test ALL related business logic
                   businessValidation := safetyFramework.ValidateTemplateBusinessRules(template)
                   Expect(businessValidation.IsValid).To(BeTrue())

                   performanceMetrics := templateEngine.CalculatePerformanceMetrics(template)
                   Expect(performanceMetrics.EstimatedExecutionTime).To(BeNumerically("<", 300))
               } else {
                   // Validate business logic fails gracefully
                   Expect(err).To(HaveOccurred())
                   Expect(template.Steps).To(BeEmpty())

                   // EXPANDED error handling validation
                   errorHandling := workflowBuilder.GetErrorHandlingStrategy(edgeCase.Alert)
                   Expect(errorHandling.FallbackAvailable).To(BeTrue())
               }
           }
       })

       // ADDITIONAL comprehensive unit tests - MAXIMIZE coverage
       It("should validate ALL action types meet business requirements", func() {
           // Test EVERY action type that can be unit tested
           actionTypes := safetyFramework.GetAllSupportedActionTypes()

           for _, actionType := range actionTypes {
               template := &engine.ExecutableTemplate{}
               alert := createAlertForActionType(actionType)

               err := workflowBuilder.AddValidationSteps(template, alert)
               Expect(err).ToNot(HaveOccurred())

               // Test business requirement validation for each type
               hasActionType := false
               for _, step := range template.Steps {
                   if step.Action != nil && step.Action.Type == actionType {
                       hasActionType = true

                       // Test business logic for this specific action type
                       businessValidation := safetyFramework.ValidateActionBusinessRules(step.Action)
                       Expect(businessValidation.IsValid).To(BeTrue())

                       complianceCheck := safetyFramework.CheckActionCompliance(step.Action)
                       Expect(complianceCheck.IsCompliant).To(BeTrue())
                   }
               }

               Expect(hasActionType).To(BeTrue(),
                   "Template should contain action type %s for appropriate alert", actionType)
           }
       })
   })
   ```

2. **Integration Test Layer (Selective Coverage - Focused Secondary Defense)**:
   ```go
   // FOCUSED integration testing for cross-component validation
   It("should integrate workflow generation with validation pipeline", func() {
       // Test REAL component integration (fewer scenarios, deeper integration)
       workflow, err := workflowEngine.CreateWorkflowFromAlert(ctx, criticalAlert)
       Expect(err).ToNot(HaveOccurred())

       validationReport := validationEngine.ValidateWorkflow(ctx, workflow.Template)

       // Verify cross-component business outcomes
       Expect(validationReport.TechnicalErrors).To(BeZero(),
           "BR-INTEGRATION-001: Cross-component validation must prevent technical errors")
       Expect(validationReport.BusinessPolicyViolations).To(BeZero(),
           "BR-INTEGRATION-001: Integration must enforce business policies")
   })
   ```

3. **E2E Test Layer (Essential Coverage - Critical Workflow Defense)**:
   ```go
   // MINIMAL e2e testing for complete business workflows
   It("should execute complete alert-to-resolution workflow", func() {
       // Test complete business scenario (minimal scenarios, maximum realism)
       alertEvent := receiveProductionAlert()

       // Complete workflow: Alert → Analysis → Generation → Validation → Execution → Resolution
       result := kubernautSystem.ProcessAlert(alertEvent)

       // Validate complete business outcome
       Expect(result.Status).To(Equal("resolved"),
           "BR-E2E-001: Complete workflow must resolve production alerts")
       Expect(result.ActionTypes).To(ConsistOf(validProductionActionTypes),
           "BR-E2E-001: Production workflow must use only valid action types")
   })
   ```

### **📊 EXPANDED Pyramid Defense Coverage Analysis**

| **Scenario** | **Unit Tests (70%+ EXPANDED)** | **Integration Tests (Selective)** | **E2E Tests (Essential)** |
|---|---|---|---|
| **Invalid Action Type in Generation** | ✅ **MAXIMUM** - ALL scenarios, edge cases, business rules | ✅ **FOCUSED** - Critical cross-component integration | ✅ **ESSENTIAL** - Production workflow validation |
| **Missing Retry Policy** | ✅ **MAXIMUM** - ALL safety algorithms, configurations, edge cases | ✅ **FOCUSED** - Policy framework integration only | ✅ **ESSENTIAL** - Runtime policy enforcement |
| **AI Fallback Failures** | ✅ **MAXIMUM** - ALL fallback logic, error scenarios, business rules | ✅ **FOCUSED** - AI→Business integration paths | ✅ **ESSENTIAL** - Production AI scenarios |
| **Business Policy Violations** | ✅ **MAXIMUM** - ALL policy algorithms, rules, configurations | ✅ **FOCUSED** - Cross-component policy enforcement | ✅ **ESSENTIAL** - Real policy violation handling |
| **Nil Pointer Safety Issues** | ✅ **MAXIMUM** - ALL edge cases, boundary conditions, error paths | ✅ **FOCUSED** - Cross-component data flow | ✅ **ESSENTIAL** - Production crash prevention |
| **Performance Requirements** | ✅ **MAXIMUM** - Algorithm performance, resource usage, optimization | ✅ **FOCUSED** - Cross-component performance | ✅ **ESSENTIAL** - Production load scenarios |
| **Security Validations** | ✅ **MAXIMUM** - Input validation, encryption, access control logic | ✅ **FOCUSED** - Security framework integration | ✅ **ESSENTIAL** - Production security scenarios |

### **🎯 EXPANDED Pyramid Defense Benefits**

#### **Unit Test Layer (70%+ EXPANDED - MAXIMUM Coverage)**
- **Catches 85-95% of issues** during development with expanded coverage
- **Fast feedback** (<10ms per test)
- **COMPREHENSIVE scenarios** with real business logic - ALL unit-testable BRs
- **ALL edge cases and business rules** covered with mocked external dependencies
- **MAXIMUM ROI** - highest issue detection per test effort with expanded coverage
- **Defense-in-depth foundation** - comprehensive baseline for all business requirements

#### **Integration Test Layer (Selective - Focused Coverage)**
- **Catches 5-10% additional issues** in component interactions that unit tests cannot cover
- **Medium execution time** (100-1000ms per test)
- **FOCUSED scenarios** on critical integration points that require real system interaction
- **Real component interactions** with strategic mocking - only for integration-specific requirements

#### **E2E Test Layer (Essential - Critical Coverage)**
- **Catches 2-5% remaining issues** in complete workflows requiring production-like environments
- **Slower execution** (1-10s per test)
- **ESSENTIAL scenarios** covering critical business workflows that require complete system integration
- **Maximum realism** with minimal mocking - only for workflow-critical requirements

### **🔍 Defense in Depth Benefits Proven**

#### **Case Study 1: Invalid Action Type Issue**

**What Happened**:
- `addValidationSteps()` function generated workflows with invalid `"validate"` action type
- Systemic issue affected multiple workflow generation paths
- Could have caused production workflow validation failures

**How Defense in Depth Would Work**:

1. **Unit Tests** (Primary - SHOULD have caught):
   - **Gap**: Unit tests used mocked workflows instead of testing actual generation
   - **Fix**: Direct testing of `addValidationSteps()` function with action type validation
   - **Prevention**: 100% - Would catch issue immediately during development

2. **Integration Tests** (Secondary - DID catch):
   - **Success**: Integration tests detected validation failures in cross-module scenarios
   - **Detection**: Workflow generation → validation pipeline revealed invalid action types
   - **Limitation**: Only caught after integration, not during unit development

3. **E2E Tests** (Final - WOULD catch):
   - **Coverage**: Full workflow execution would fail on invalid action types
   - **Business Impact**: Would prevent production deployment with broken workflows
   - **Cost**: Higher cost to fix issues discovered at E2E level

#### **Case Study 2: Nil Pointer Safety Issue**

**What Happened**:
```go
// ORIGINAL CODE (unsafe - potential nil pointer dereference)
if step.Action.Parameters != nil && len(step.Action.Parameters) > 3 {
    complexActionCount++
}

// FIXED CODE (safe - nil check eliminated by linter warning)
if len(step.Action.Parameters) > 3 {
    complexActionCount++
}
```

**The Issue**: The original code had redundant nil checking that could mask potential nil pointer dereferences if `step.Action` itself was nil.

**How Defense in Depth Would Catch This**:

1. **Unit Tests** (Primary Defense - WOULD catch):
   ```go
   It("should handle nil action parameters safely", func() {
       // Test edge cases with nil values
       step := &ExecutableWorkflowStep{
           Action: nil, // This would cause panic in unsafe code
       }

       // This test would fail with original code, pass with fixed code
       Expect(func() {
           complexCount := builder.CalculateComplexActionCount([]*ExecutableWorkflowStep{step})
           Expect(complexCount).To(Equal(0))
       }).ToNot(Panic(), "Should handle nil actions safely")
   })

   It("should handle nil parameters safely", func() {
       step := &ExecutableWorkflowStep{
           Action: &StepAction{
               Type: "test_action",
               Parameters: nil, // Nil parameters should be handled safely
           },
       }

       complexCount := builder.CalculateComplexActionCount([]*ExecutableWorkflowStep{step})
       Expect(complexCount).To(Equal(0), "Nil parameters should not count as complex")
   })
   ```

2. **Integration Tests** (Secondary Defense - WOULD catch):
   ```go
   It("should generate robust workflows under edge conditions", func() {
       // Test workflow generation with incomplete data
       alertWithMissingData := types.Alert{
           Name: "incomplete-alert",
           // Missing some fields that might lead to nil actions
       }

       workflow, err := builder.CreateWorkflowFromAlert(ctx, alertWithMissingData)
       Expect(err).ToNot(HaveOccurred())

       // Validate all steps are properly formed (no nil actions)
       for _, step := range workflow.Template.Steps {
           if step.Action != nil {
               // This would expose nil parameter handling issues
               paramCount := len(step.Action.Parameters)
               Expect(paramCount).To(BeNumerically(">=", 0))
           }
       }
   })
   ```

3. **E2E Tests** (Final Defense - WOULD catch):
   ```go
   It("should handle malformed alerts without system crashes", func() {
       // Test complete workflow with real malformed alert data
       // This would catch nil pointer panics in production scenarios
       malformedAlert := receiveMalformedAlertFromPrometheus()

       Expect(func() {
           workflow := processCompleteAlertWorkflow(malformedAlert)
           Expect(workflow).ToNot(BeNil())
       }).ToNot(Panic(), "System should handle malformed alerts gracefully")
   })
   ```

**Defense in Depth Value**:
- **Unit Test**: Catches nil safety issues during development with specific edge case testing
- **Integration Test**: Validates nil handling in cross-component scenarios
- **E2E Test**: Ensures production scenarios with malformed data don't crash the system
- **Linter Integration**: Static analysis (go vet) provides additional safety net

**Prevention Timeline**:
- **Development**: Unit tests catch during coding (immediate feedback)
- **Integration**: Cross-component testing catches interaction edge cases
- **Pre-deployment**: E2E tests prevent production nil pointer crashes
- **Static Analysis**: Linter warnings guide safer code patterns

### **📋 EXPANDED Overlapping Scenarios - MAXIMUM Unit Coverage**

#### **Scenario 1: Business Logic Generation (EXPANDED COVERAGE)**

**Unit Test Focus**: COMPREHENSIVE function and business rule behavior
```go
// Test ALL generation functions that can be unit tested
builder.AddValidationSteps(template)
builder.GenerateFallbackWorkflowResponse(input)
builder.ValidateBusinessRules(template)
builder.OptimizePerformance(template)
builder.ApplySafetyConstraints(template)
builder.CalculateRiskMetrics(template)
// EXPANDED: Test ALL business logic components with mocked externals
```

**Integration Test Focus**: SELECTIVE cross-component interaction (only when unit testing insufficient)
```go
// Test generation → validation → execution pipeline ONLY for integration-specific scenarios
workflow := builder.CreateWorkflowFromAlert(ctx, alert)
validationReport := builder.ValidateWorkflow(ctx, workflow.Template)
// FOCUSED: Only test what requires real component integration
```

**E2E Test Focus**: ESSENTIAL complete business workflow (only when integration testing insufficient)
```go
// Test alert reception → analysis → workflow → action execution → completion
// ESSENTIAL: Only test complete workflows requiring production-like environments
```

#### **Scenario 2: Safety and Validation (EXPANDED COVERAGE)**

**Unit Test Focus**: COMPREHENSIVE validation rules and business logic
```go
// Test ALL safety validation logic that can be unit tested
Expect(builder.ShouldHaveRetryPolicy(step)).To(BeTrue())
Expect(step.RetryPolicy).ToNot(BeNil())
Expect(builder.ValidateResourceLimits(step)).To(Succeed())
Expect(builder.CheckSecurityConstraints(step)).To(BeTrue())
Expect(builder.CalculateRiskScore(step)).To(BeNumerically("<", 0.3))
Expect(builder.ApplyComplianceRules(step)).To(Succeed())
// EXPANDED: Test ALL safety business logic with mocked external dependencies
```

**Integration Test Focus**: SELECTIVE validation framework integration (only when required)
```go
// Test safety validation across workflow generation pipeline ONLY for integration-specific scenarios
validationReport := builder.ValidateWorkflow(ctx, template)
Expect(countSafetyViolations(validationReport)).To(BeZero())
// FOCUSED: Only test cross-component safety interactions
```

**E2E Test Focus**: ESSENTIAL runtime safety enforcement (only when critical)
```go
// Test safety policies prevent dangerous operations in production
// ESSENTIAL: Only test production-specific safety scenarios
```

#### **Scenario 3: Business Policy Enforcement (EXPANDED COVERAGE)**

**Unit Test Focus**: COMPREHENSIVE policy logic and business algorithms
```go
// Test ALL business policy calculations that can be unit tested
riskLevel := builder.AssessRiskLevel(workflow)
Expect(riskLevel).To(Equal("high"))
complianceScore := builder.CalculateComplianceScore(workflow)
Expect(complianceScore).To(BeNumerically(">=", 0.8))
policyViolations := builder.DetectPolicyViolations(workflow)
Expect(policyViolations).To(BeEmpty())
auditRequirements := builder.DetermineAuditRequirements(workflow)
Expect(auditRequirements.Level).To(Equal("standard"))
// EXPANDED: Test ALL policy business logic with comprehensive scenarios
```

**Integration Test Focus**: SELECTIVE policy framework integration (only when required)
```go
// Test business policies applied during workflow validation ONLY for cross-component scenarios
Expect(validationReport.Status).To(BeElementOf([]string{"passed", "warning", "failed"}))
// FOCUSED: Only test policy enforcement requiring real component integration
```

**E2E Test Focus**: ESSENTIAL real business policy impact (only when critical)
```go
// Test high-risk workflows properly require manual approval
// ESSENTIAL: Only test complete policy workflows requiring production-like validation
```

### **⚡ EXPANDED Efficiency Guidelines for Maximum Unit Coverage**

#### **MAXIMUM Unit Coverage Strategy**

1. **Unit Tests**: Test **ALL business logic that can be unit tested**
   - Fast execution (<10ms per test)
   - COMPREHENSIVE coverage of ALL business logic, algorithms, rules, validations
   - Mock ALL external dependencies (databases, APIs, file I/O, network calls)
   - Test ALL edge cases, error conditions, business scenarios
   - **DEFAULT CHOICE**: Unless requirement inherently needs real integration

2. **Integration Tests**: Test **ONLY integration-specific requirements**
   - Medium execution (100-1000ms per test)
   - Real component integration ONLY when unit testing insufficient
   - Validate cross-module contracts that cannot be unit tested
   - **SELECTIVE USE**: Only for scenarios requiring real component interaction

3. **E2E Tests**: Test **ONLY complete workflow requirements**
   - Slower execution (1-10s per test)
   - Production-like environment for complete business workflows
   - End-to-end business validation requiring real infrastructure
   - **ESSENTIAL USE**: Only for workflows requiring complete system integration

#### **EXPANDED Unit Test Coverage vs. Redundant Overlap**

**❌ INEFFICIENT**:
```go
// Unit test testing full integration scenario without business value
It("should handle complete alert workflow", func() {
    // WRONG: This is integration testing without business logic focus
    alert := createComplexAlert()
    workflow := builder.CreateWorkflowFromAlert(ctx, alert)
    result := executor.ExecuteWorkflow(ctx, workflow)
    // Too much integration, not enough business logic validation
})
```

**✅ EFFICIENT - MAXIMUM UNIT COVERAGE**:
```go
// Unit test covers ALL business logic that can be unit tested
It("should generate valid action types with comprehensive business validation", func() {
    // RIGHT: Tests specific function AND all related business logic
    template := &engine.ExecutableTemplate{}
    alert := createComplexAlert()

    // Test ALL business logic components that can be unit tested
    builder.AddValidationSteps(template, alert)
    validateAllActionTypesAreValid(template.Steps)

    // EXPANDED: Test ALL related business rules with mocked externals
    businessValidation := safetyFramework.ValidateTemplate(template)
    Expect(businessValidation.IsValid).To(BeTrue())

    performanceMetrics := templateEngine.CalculateMetrics(template)
    Expect(performanceMetrics.EstimatedTime).To(BeNumerically("<", 300))

    complianceCheck := policyEngine.CheckCompliance(template)
    Expect(complianceCheck.Level).To(Equal("approved"))

    // Test error scenarios and edge cases
    errorCases := builder.GenerateErrorScenarios(alert)
    for _, errorCase := range errorCases {
        errorHandling := builder.HandleError(errorCase)
        Expect(errorHandling.Strategy).ToNot(BeEmpty())
    }
})

// ADDITIONAL comprehensive unit test - test MORE business requirements
It("should optimize workflow performance with business constraints", func() {
    // Test performance optimization business logic
    workflow := createBaselineWorkflow()

    optimizedWorkflow := optimizer.OptimizeWorkflow(workflow, businessConstraints)
    Expect(optimizedWorkflow.PerformanceGain).To(BeNumerically(">", 0.15))

    // Test business constraint compliance
    constraintValidation := optimizer.ValidateBusinessConstraints(optimizedWorkflow)
    Expect(constraintValidation.IsValid).To(BeTrue())
})
```

**EXPANSION PRINCIPLE**: Instead of avoiding unit tests, EXPAND them to cover MORE business logic that can be tested with mocked external dependencies.

### **🎯 EXPANDED Defense in Depth Success Metrics**

#### **Coverage Targets - MAXIMUM UNIT EMPHASIS**

- **Critical Business Functions**: 100% coverage with MAXIMUM unit test foundation + strategic overlap
- **Safety-Critical Operations**: 95% coverage with comprehensive unit tests + selective integration/e2e
- **Business Policy Enforcement**: 90% coverage with extensive unit validation + focused higher-tier validation
- **Error Scenarios**: 90% coverage with comprehensive unit test failure simulation + real scenario validation
- **ALL Unit-Testable Business Requirements**: 100% coverage in unit tests (with external mocks)

#### **Quality Gates - EXPANDED UNIT FOCUS**

1. **EXPANDED Unit Test Gate**: ALL business logic functions that can be unit tested must pass comprehensive testing
2. **SELECTIVE Integration Test Gate**: Critical cross-module scenarios requiring real integration must pass validation
3. **ESSENTIAL E2E Test Gate**: Critical business workflows requiring complete system integration must complete successfully

#### **Failure Prevention Evidence - EXPANDED UNIT COVERAGE**

- **Development Stage**: EXPANDED unit tests catch 85-95% of issues with comprehensive coverage
- **Integration Stage**: SELECTIVE integration tests catch 3-8% additional issues in integration-specific scenarios
- **E2E Stage**: ESSENTIAL e2e tests catch 2-5% remaining issues in complete workflow scenarios
- **Production**: <1% issues reach production (target: 0%) with expanded unit test foundation

### **🚨 EXPANDED Mandatory Defense Patterns**

#### **Pattern 1: MAXIMUM Unit Coverage → Selective Higher Tier Chain**
```go
// EXPANDED: Maximize unit coverage, selective higher tiers
Unit:        TestALLGenerationLogic() → TestALLValidationLogic() → TestALLBusinessRules()
Integration: TestGenerationPipeline() → ONLY when integration-specific
E2E:         TestCompleteWorkflow() → ONLY when production-validation required
```

#### **Pattern 2: Comprehensive Safety → Focused Enforcement Chain**
```go
// EXPANDED: Comprehensive unit safety testing, focused higher tiers
Unit:        TestALLSafetyLogic() → TestALLValidationRules() → TestALLErrorScenarios()
Integration: TestSafetyFramework() → ONLY when cross-component safety required
E2E:         TestSafetyInProduction() → ONLY when production safety scenarios required
```

#### **Pattern 3: Maximum Business Logic → Selective Integration Chain**
```go
// EXPANDED: Maximum business logic in unit tests, selective higher tiers
Unit:        TestALLBusinessLogic() → TestALLAlgorithms() → TestALLBusinessRules()
Integration: TestBusinessIntegration() → ONLY when cross-component business logic required
E2E:         TestBusinessWorkflow() → ONLY when complete workflow business value required
```

#### **Pattern 4: Unit-First Decision Pattern**
```go
// NEW: Default to unit testing unless integration/e2e inherently required
Question:    CanThisBeUnitTested(requirement)
Answer:      If YES → Unit Test (with mocks)
             If NO → Integration/E2E Test (justify why unit testing insufficient)
```

**This EXPANDED defense in depth approach is MANDATORY for kubernaut because production failures in Kubernetes automation can have severe business impact. The MAXIMUM unit test coverage ensures that critical issues are caught at the earliest possible stage with comprehensive business logic validation, while providing strategic backup detection at integration and e2e levels for scenarios that inherently require real system interaction or complete workflow validation.**

## 🧪 **Test-Driven Development (TDD) - MANDATORY COMPLETE CYCLE**

### TDD Workflow - REQUIRED COMPLETE RED-GREEN-REFACTOR CYCLE
**CRITICAL**: TDD is INCOMPLETE without all three phases. ALL phases are MANDATORY.

## 🎯 **MANDATORY TDD BUSINESS REQUIREMENTS COMPLETENESS**

### **COMPLETENESS RULE - NO EXCEPTIONS**
**MANDATORY**: When implementing functionality for specific business requirements X, Y, Z → ALL of those targeted X, Y, Z MUST be covered by TDD

**NOT**: Cover all business requirements in the project
**YES**: Cover all business requirements targeted for this implementation

**Formula**: `Implementation(Targeted: BR-001, BR-002, BR-003) = TDD_Coverage(BR-001 + BR-002 + BR-003)`

### **COMPLETENESS VALIDATION - CRYSTAL CLEAR**
```bash
# MANDATORY CHECK: Before completing any TDD cycle
TARGETED_BRS="BR-AI-001,BR-AI-002,BR-AI-003"  # ONLY the BRs you're implementing THIS cycle
COVERED_BRS=$(grep -r "BR-AI-001\|BR-AI-002\|BR-AI-003" test/ --include="*_test.go" | cut -d: -f1 | sort -u)

if [ "$(echo $COVERED_BRS | wc -w)" -ne "$(echo $TARGETED_BRS | tr ',' ' ' | wc -w)" ]; then
    echo "❌ TDD COMPLETENESS VIOLATION: Not all targeted BRs for THIS implementation covered"
    echo "Targeted for this implementation: $TARGETED_BRS"
    echo "Actually covered in tests: $COVERED_BRS"
    echo "RULE: EVERY business requirement you're implementing MUST have corresponding tests"
    exit 1
fi
```

### **COMPLETENESS EXAMPLES**

#### **✅ CORRECT: Complete TDD Coverage for Targeted BRs**
```go
// THIS TDD CYCLE: Implementing ONLY BR-CONTEXT-OPT-001, BR-CONTEXT-OPT-002, BR-CONTEXT-OPT-003
// (Note: Project may have BR-CONTEXT-OPT-004, BR-WORKFLOW-001, etc. but NOT implementing those now)

// Test for BR-CONTEXT-OPT-001: Context quality analysis
It("should analyze context quality per BR-CONTEXT-OPT-001", func() {
    analysis := optimizer.AnalyzeContext(ctx, content)
    Expect(analysis.Quality).To(BeNumerically(">", 0.8)) // BR-CONTEXT-OPT-001 requirement
})

// Test for BR-CONTEXT-OPT-002: Context size optimization
It("should optimize context size per BR-CONTEXT-OPT-002", func() {
    result := optimizer.OptimizeContext(ctx, largeContent)
    Expect(len(result.Content)).To(BeNumerically("<", len(largeContent))) // BR-CONTEXT-OPT-002 requirement
})

// Test for BR-CONTEXT-OPT-003: Fallback handling
It("should handle LLM failures per BR-CONTEXT-OPT-003", func() {
    llmClient.SetError(errors.New("service unavailable"))
    result := optimizer.OptimizeContext(ctx, content)
    Expect(result.Source).To(Equal("fallback")) // BR-CONTEXT-OPT-003 requirement
})

// RESULT: ALL 3 targeted business requirements have corresponding tests ✅
```

#### **❌ WRONG: Incomplete TDD Coverage for Targeted BRs**
```go
// THIS TDD CYCLE: Implementing BR-CONTEXT-OPT-001, BR-CONTEXT-OPT-002, BR-CONTEXT-OPT-003

// Test for BR-CONTEXT-OPT-001: Context quality analysis
It("should analyze context quality per BR-CONTEXT-OPT-001", func() {
    analysis := optimizer.AnalyzeContext(ctx, content)
    Expect(analysis.Quality).To(BeNumerically(">", 0.8))
})

// Test for BR-CONTEXT-OPT-002: Context size optimization
It("should optimize context size per BR-CONTEXT-OPT-002", func() {
    result := optimizer.OptimizeContext(ctx, largeContent)
    Expect(len(result.Content)).To(BeNumerically("<", len(largeContent)))
})

// ❌ MISSING: No test for BR-CONTEXT-OPT-003 - VIOLATION!
// RESULT: Only 2 of 3 targeted business requirements covered ❌
```

#### **Phase 1: RED - Write Failing Tests (MANDATORY)**
1. **FIRST**: Identify existing business interfaces in pkg/ or cmd/
   - **MANDATORY CHECK**: `find pkg/ cmd/ -name "*.go" | xargs grep -l "interface.*{"`
   - **VALIDATION**: Tests MUST import and call actual business interfaces
   - **FORBIDDEN**: Creating new business logic that only exists in tests

2. **SECOND**: Write tests that call actual business interfaces
   - **MANDATORY**: Import business packages: `github.com/jordigilh/kubernaut/pkg/...`
   - **FORBIDDEN**: Testing libraries (logrus, context, os packages)
   - **FORBIDDEN**: Testing static data or hardcoded values

3. **NEVER**: Use `Skip()` to avoid test failures
4. **VALIDATION**: All tests MUST fail initially (RED phase)

#### **Phase 2: GREEN - Implement Minimum Business Logic (MANDATORY)**
5. **THEN**: Implement minimum business logic to make ALL tests pass
6. **VALIDATION**: All tests MUST pass after implementation (GREEN phase)
7. **FORBIDDEN**: Over-engineering - implement only what's needed to pass tests

#### **Phase 3: REFACTOR - Optimize and Enhance (MANDATORY)**
8. **ALWAYS**: Perform REFACTOR phase after GREEN phase

## 🔴 **MANDATORY REFACTOR PHASE - CRYSTAL CLEAR SCOPE**

### **REFACTOR DEFINITION - NO AMBIGUITY**
**REFACTOR MEANS**: Enhance the EXACT SAME code that tests are calling
**REFACTOR NEVER MEANS**: Create new parallel/additional code

### **REFACTOR SCOPE VALIDATION - MANDATORY**
**Before REFACTOR phase:**
```bash
# MANDATORY: Identify exact code under test
grep -r "YourBusinessMethod" test/ --include="*_test.go"
# Find: pkg/component/file.go:123 - ExistingMethod()

# MANDATORY: REFACTOR applies ONLY to that exact method
# FORBIDDEN: Creating new types, new files, or new methods
```

### **REFACTOR ACTIVITIES - SPECIFIC EXAMPLES**

#### ✅ **CORRECT REFACTOR Examples:**
```go
// BEFORE REFACTOR: Simple implementation
func (c *ClientImpl) AnalyzeContext(ctx context.Context, content string) (*ContextAnalysis, error) {
    return &ContextAnalysis{Quality: 0.8}, nil
}

// AFTER REFACTOR: Enhanced SAME method
func (c *ClientImpl) AnalyzeContext(ctx context.Context, content string) (*ContextAnalysis, error) {
    // ADDED: Sophisticated caching
    if cached := c.cache.Get(content); cached != nil {
        return cached, nil
    }

    // ADDED: Complex algorithm
    analysis := c.performAdvancedAnalysis(content)
    c.cache.Set(content, analysis)
    return analysis, nil
}
// SAME method signature, SAME integration, ENHANCED implementation
```

#### ❌ **FORBIDDEN REFACTOR Examples:**
```go
// WRONG: Creating new component during REFACTOR
type ContextOptimizer struct { // ❌ NEW TYPE = NOT REFACTOR
    sophisticatedFeatures...
}

// WRONG: Adding parallel methods during REFACTOR
func (c *ClientImpl) NewSophisticatedMethod() { // ❌ NEW METHOD = NOT REFACTOR
}

// WRONG: Creating new files during REFACTOR
// optimizer.go // ❌ NEW FILE = NOT REFACTOR
```

### **REFACTOR PHASE VIOLATIONS - AUTO-DETECTION**
```bash
#!/bin/bash
# Run during REFACTOR phase to detect violations
echo "🔍 Validating REFACTOR phase compliance..."

# Detect new types created during REFACTOR
NEW_TYPES=$(git diff --name-only HEAD~1 | xargs grep -l "type.*struct" | grep -v "_test.go")
if [ ! -z "$NEW_TYPES" ]; then
    echo "❌ REFACTOR VIOLATION: New types created during REFACTOR phase"
    echo "Files: $NEW_TYPES"
    echo "RULE: REFACTOR enhances existing code, never creates new types"
    exit 1
fi

# Detect new methods added during REFACTOR
NEW_METHODS=$(git diff HEAD~1 | grep "^+func " | grep -v "_test.go")
if [ ! -z "$NEW_METHODS" ]; then
    echo "❌ REFACTOR VIOLATION: New methods created during REFACTOR phase"
    echo "RULE: REFACTOR enhances existing methods, never creates new ones"
    exit 1
fi

echo "✅ REFACTOR phase compliance verified"
```

9. **MANDATORY REFACTOR ACTIVITIES** (Applied to existing code only):
   - **Performance Optimization**: Improve algorithms, add caching, optimize data structures
   - **Code Quality**: Extract common patterns, improve error handling, enhance maintainability
   - **Business Logic Enhancement**: Implement sophisticated business rules and calculations
   - **Architecture Improvement**: Apply design patterns, improve separation of concerns
10. **VALIDATION**: All tests MUST remain GREEN throughout refactoring
11. **FORBIDDEN**: Skipping REFACTOR phase - TDD is incomplete without it

#### **TDD Completion Verification (MANDATORY)**
12. **VALIDATION REQUIREMENT**: Every test must call business logic from main application
    - **CHECK**: Business logic must exist in main application startup sequence
    - **FORBIDDEN**: Business functions that exist only in test files
13. **REFACTOR COMPLETION**: Verify performance improvements and code quality enhancements
14. **BUSINESS VALUE**: Confirm enhanced business logic delivers improved outcomes

### **🔬 MANDATORY BUSINESS LOGIC VALIDATION**

#### Pre-Test Requirements - ENFORCED
Before writing ANY test, complete this validation:

1. **Business Interface Discovery (MANDATORY)**:
   ```bash
   # STEP 1: Identify actual business interfaces
   find pkg/ cmd/ -name "*.go" | xargs grep -l "interface.*{" > business_interfaces.txt

   # STEP 2: Verify interfaces are used in main application
   grep -r "New.*Service\|New.*Client\|New.*Manager" cmd/ > main_app_business.txt

   # STEP 3: Tests MUST call interfaces from these files
   ```

2. **Business Logic Call Validation (MANDATORY)**:
   - **RULE**: Every test MUST call business logic from main application
   - **DETECTION**: `grep "github.com/jordigilh/kubernaut/pkg/" test_file.go`
   - **VALIDATION**: Business functions MUST exist in cmd/ or pkg/ (not just tests)

3. **Anti-Pattern Detection (AUTOMATED)**:
   ```bash
   # FORBIDDEN PATTERNS - Auto-reject:
   ./scripts/cursor-rule-validator.sh
   # Checks for:
   # - ToNot(BeEmpty())|ToNot(BeNil()) patterns
   # - Static data testing (appName := "string")
   # - Library testing (logrus.New(), os.Setenv())
   # - Missing business logic imports
   ```

#### Static Analysis Requirements - ENFORCED
- **PRE-COMMIT HOOK**: Run cursor rule validation before any commit
- **BUILD INTEGRATION**: Tests with violations MUST NOT compile
- **CI/CD GATE**: Cursor rule violations block deployment

## Testing Framework
- **BDD Framework**: Ginkgo/Gomega for behavior-driven development (MANDATORY)
- **TDD Workflow**: Complete RED-GREEN-REFACTOR cycle as detailed above
- **Business Requirements**: ALL tests must map to specific business requirements (BR-XXX-XXX format)
- **Test Organization**: Follow package structure with `_test.go` suffix
- **Suite Organization**: ALL `*_suite_test.go` files MUST contain ONLY RunSpecs function (see Test File Organization section)
- **Mock Strategy**: Prefer real business logic over mocks for non-external dependencies; use [pkg/testutil/mock_factory.go](mdc:pkg/testutil/mock_factory.go) only when scenario requires it
- **Test Data**: Use [pkg/testutil/test_data_factory.go](mdc:pkg/testutil/test_data_factory.go) for fixture generation

### Test Requirements - ENHANCED WITH AUTOMATED DETECTION
- **PREFER REAL BUSINESS LOGIC**: Integrate with actual business components from pkg/ and cmd/ over mocks for non-external dependencies
- Use mocks selectively from [pkg/testutil/](mdc:pkg/testutil/) only when scenario requires it (external services, error simulation, performance)
- **AUTOMATED ANTI-PATTERN DETECTION**: Use `scripts/cursor-rule-validator.sh` before any commit
- **FORBIDDEN PATTERNS** (Auto-detected and rejected):
  - `ToNot(BeEmpty())`, `ToNot(BeNil())`, `ToNot(BeZero())` - null-testing anti-pattern
  - `appName := "hardcoded"` followed by `Expect(appName)` - static data testing
  - `logrus.New()`, `testLogger.`, `os.Setenv()` - library testing instead of business logic
- **ENSURE** assertions validate business outcomes with BR-XXX-XXX references
- **MANDATORY**: Business logic imports from pkg/ or cmd/ in every test file
- Run golang tests with -race flag to capture race conditions

### Mock Usage Guidelines - MANDATORY
- **PREFER REAL BUSINESS LOGIC**: Tests should integrate with actual business components from pkg/ and cmd/ whenever possible
- **USE MOCKS SELECTIVELY**: Only use mocks for:
  - **External Dependencies**: Third-party services, databases, APIs (when integration test infrastructure unavailable)
  - **Slow Operations**: Network calls, file I/O, expensive computations (when speed is critical)
  - **Error Simulation**: Testing specific failure scenarios that are difficult to reproduce with real components
  - **Isolation Requirements**: When testing component behavior in isolation from specific dependencies
- **AVOID MOCKS FOR**: Internal business logic, service orchestration, data transformations, business rule validation
- **MOCK FACTORY USAGE**: When mocks are needed, use centralized mock factory from [pkg/testutil/mock_factory.go](mdc:pkg/testutil/mock_factory.go)

### Automated Detection Patterns - ENFORCED
```regex
# NULL-TESTING PATTERNS (FORBIDDEN)
ToNot\(Be(Empty|Nil|Zero)\(\)\)
\.NotTo\(Be(Empty|Nil|Zero)\(\)\)
len\(.*\) > 0.*Expect
.*!= nil.*Expect

# STATIC DATA PATTERNS (FORBIDDEN)
\w+\s*:=\s*"[^"]*".*\n.*Expect\(\w+\)
appName.*:=.*".*"
expectedVersion.*:=.*".*"

# LIBRARY TESTING PATTERNS (FORBIDDEN)
logrus\.New\(\).*\n.*Expect
testLogger\.
context\.With.*\n.*Expect
os\.(Setenv|Getenv).*\n.*Expect

# MISSING BUSINESS LOGIC (FORBIDDEN)
# Test files without business imports
^package.*\n.*import.*\n(?!.*github\.com/jordigilh/kubernaut/pkg/)
```

## Mock Usage Strategy - PYRAMID APPROACH MANDATORY

### 🎯 **Core Principle: Extensive Unit Testing with Real Business Logic**

**PYRAMID MANDATE**: Unit tests (70% of all tests) should use **100% real business logic** with mocks **ONLY** for external dependencies (databases, LLMs, K8s). This maximizes business logic coverage while maintaining fast execution.

### Pyramid Mock Strategy - LAYER-SPECIFIC REQUIREMENTS

#### ✅ **Unit Tests (70%) - Mock ONLY External Dependencies:**

1. **External Infrastructure** (Always mock in unit tests):
   ```go
   // ALWAYS mock external/infrastructure dependencies in unit tests
   mockK8sClient := mocks.NewMockKubernetesClient()     // Kubernetes API
   mockVectorDB := mocks.NewMockVectorDatabase()        // PostgreSQL/pgvector
   mockLLMProvider := mocks.NewMockLLMProvider()        // AI/LLM services
   mockMetricsClient := mocks.NewMockMetricsClient()    // Prometheus/monitoring

   // Use REAL business logic components
   workflowEngine := engine.NewIntelligentWorkflowBuilder(
       mockLLMProvider,    // External: Mock
       mockK8sClient,      // External: Mock
       realSafetyFramework,    // Business Logic: Real
       realAnalyticsEngine,    // Business Logic: Real
   )
   ```

2. **Error Simulation** (Controlled failure testing):
   ```go
   // Mock external services to simulate specific failures
   mockLLMProvider.EXPECT().GenerateWorkflow(gomock.Any()).
       Return(nil, errors.New("AI service unavailable"))

   // Test REAL business logic error handling
   workflow, err := workflowBuilder.CreateWorkflowWithFallback(ctx, alert)
   Expect(err).ToNot(HaveOccurred()) // Real fallback logic should handle this
   Expect(workflow.Source).To(Equal("fallback")) // Real business logic outcome
   ```

3. **Performance Requirements** (Fast unit test execution):
   ```go
   // Mock slow external operations for unit test speed
   mockSlowVectorDB := mocks.NewMockVectorDatabase()
   mockSlowVectorDB.EXPECT().SearchSimilar(gomock.Any()).
       Return(testVectors, nil) // Instant response vs 500ms real call

   // Test REAL business logic with fast mocked dependencies
   patterns := patternEngine.DiscoverPatterns(ctx, alerts) // Real algorithm
   ```

#### ✅ **Integration Tests (20%) - Selective Mocking:**

1. **Infrastructure When Unavailable**:
   ```go
   // Mock infrastructure only when not available in test environment
   if !testEnv.HasRealK8sCluster() {
       mockK8sClient := mocks.NewMockKubernetesClient()
   } else {
       realK8sClient := k8s.NewClient(testEnv.KubeConfig)
   }

   // ALWAYS use real business logic
   workflowEngine := engine.NewWorkflowEngine(k8sClient, realBusinessComponents...)
   ```

#### ✅ **E2E Tests (10%) - Minimal Mocking:**

1. **Only External APIs Outside Control**:
   ```go
   // Mock ONLY third-party services outside our control
   mockExternalAPI := mocks.NewMockExternalWeatherAPI() // External service

   // Use REAL everything else
   realK8sCluster := testEnv.RealKindCluster
   realDatabase := testEnv.RealPostgreSQL
   realLLMService := testEnv.RealLocalLLM
   ```

#### ❌ **PYRAMID ANTI-PATTERNS - NEVER DO THESE:**

1. **Mocking Internal Business Logic** (Violates pyramid principle):
   ```go
   // ❌ WRONG: Mocking business logic reduces coverage
   mockWorkflowEngine := mocks.NewMockWorkflowEngine()
   mockSafetyFramework := mocks.NewMockSafetyFramework()

   // This test provides NO business logic coverage!
   mockWorkflowEngine.EXPECT().CreateWorkflow().Return(fakeWorkflow)

   // ✅ RIGHT: Test REAL business logic extensively
   safetyFramework := platform.NewSafetyFramework(realConfig)
   workflowEngine := engine.NewIntelligentWorkflowBuilder(
       mockExternalDeps..., // Only external dependencies mocked
       safetyFramework,     // Real business logic
   )

   // This test validates REAL business algorithms and logic
   workflow, err := workflowEngine.CreateWorkflow(ctx, alert)
   Expect(safetyFramework.ValidateWorkflow(workflow)).To(Succeed())
   ```

2. **Over-Mocking in Unit Tests** (Reduces pyramid effectiveness):
   ```go
   // ❌ WRONG: Mocking everything makes unit tests worthless
   mockEverything := &AllMockedDependencies{
       MockWorkflowEngine: mocks.NewMockWorkflowEngine(),
       MockSafetyFramework: mocks.NewMockSafetyFramework(),
       MockAnalyticsEngine: mocks.NewMockAnalyticsEngine(),
       MockOrchestrator: mocks.NewMockOrchestrator(),
   }

   // No real business logic tested = wasted test effort

   // ✅ RIGHT: Mock only external, test real business logic
   realBusinessComponents := &RealBusinessLogic{
       WorkflowEngine: engine.NewIntelligentWorkflowBuilder(...),
       SafetyFramework: platform.NewSafetyFramework(...),
       AnalyticsEngine: insights.NewAnalyticsEngine(...),
       Orchestrator: orchestration.NewAdaptiveOrchestrator(...),
   }

   // Maximum business logic coverage in unit tests
   ```

3. **Insufficient Unit Test Coverage** (Violates pyramid base):
   ```go
   // ❌ WRONG: Minimal unit tests, heavy integration tests
   // Unit Tests: 20% coverage (too small pyramid base)
   // Integration Tests: 60% coverage (inverted pyramid)
   // E2E Tests: 20% coverage

   // This is expensive, slow, and catches issues late

   // ✅ RIGHT: Extensive unit tests, focused integration/e2e
   // Unit Tests: 70% coverage (solid pyramid base)
   // Integration Tests: 20% coverage (focused interactions)
   // E2E Tests: 10% coverage (critical workflows only)

   // This is fast, cheap, and catches issues early
   ```

### Pyramid Test Tier Mock Guidelines

#### **Unit Tests (70%+ MINIMUM - MAXIMUM COVERAGE FOUNDATION)**
- **Mock External Dependencies**: Database, K8s API, LLM services, monitoring systems, file I/O
- **Use Real Business Logic**: ALL internal pkg/ components, algorithms, business rules, validation logic
- **Focus**: **MAXIMUM business logic coverage** with fast execution - cover ALL unit-testable BRs
- **Coverage Target**: **AT LEAST 70% of total BRs, EXTENDED to 100% of unit-testable requirements**
- **Expansion Principle**: Test EVERY business requirement that can be validated with external mocks

#### **Integration Tests (Selective - FOCUSED INTERACTIONS)**
- **Mock Infrastructure**: Only when not available in test environment or external systems
- **Use Real Components**: ALL business logic integration and cross-component behavior
- **Focus**: **Component interactions that REQUIRE real integration** - cannot be unit tested
- **Coverage Target**: Business requirements that inherently need cross-component or external system integration

#### **E2E Tests (Essential Only - CRITICAL WORKFLOWS)**
- **Mock Only External APIs**: Third-party services completely outside our control
- **Use Real Everything Else**: Complete business workflow with real infrastructure
- **Focus**: **Essential end-to-end business scenarios** requiring production-like validation
- **Coverage Target**: Business requirements that REQUIRE complete system integration and real infrastructure

### Mock Decision Tree - UNIT TEST MAXIMIZATION

```
Need to test business requirement BR-XXX-XXX?
│
├─ Can it be unit tested with external mocks?
│  └─ YES → MANDATORY Unit Test (maximize coverage)
│
├─ Requires real external integration?
│  ├─ Critical interaction? → Integration Test
│  └─ Non-critical? → Consider unit test with mocks
│
├─ Requires complete system workflow?
│  ├─ Essential business scenario? → E2E Test
│  └─ Can be decomposed? → Unit Test components separately
│
└─ Component type decision:
   ├─ External dependency (K8s, DB, API, File I/O)? → MOCK in unit tests
   ├─ Internal business logic (pkg/)? → REAL in all tests
   ├─ Error scenario simulation? → MOCK for controlled testing
   └─ Performance critical (<10ms)? → MOCK for speed, real for accuracy
```

**UNIT TEST MAXIMIZATION PRINCIPLE**: Default to unit testing with mocks unless the requirement INHERENTLY needs real external systems or complete workflow integration.

### 🎯 **PERFECT EXAMPLE: Database Mock vs Real Business Logic**

This is the **gold standard** for critical mock/real decisions in kubernaut:

#### **✅ PERFECT DECISION: Database as External Dependency**

```go
// ✅ PERFECT: Mock external database dependency
realStateStorage = mocks.NewMockStateStorage()  // Database = External dependency

// ✅ PERFECT: Real business logic components
resilientEngine = engine.NewResilientWorkflowEngine(...)  // Our business logic
mockFailureHandler = mocks.NewMockFailureHandler()        // Mock for controlled scenarios
```

**Why This is Perfect**:
- **Database**: External system, not our business logic → **MOCK**
- **WorkflowEngine**: Our core business logic → **REAL**
- **FailureHandler**: Mock for controlled test scenarios → **STRATEGIC MOCK**

**Business Impact**:
- **Fast tests** (no I/O overhead)
- **Reliable tests** (no external dependencies)
- **Real BR validation** (actual business requirements tested)
- **Controlled scenarios** (predictable failure simulation)

**Decision Framework Applied**:
```
Database Storage?
├─ Is it external dependency? → YES (PostgreSQL/SQLite)
├─ Do we control the logic? → NO (SQL database engine)
├─ Is it infrastructure? → YES (persistence layer)
└─ Decision: MOCK ✅

Workflow Engine?
├─ Is it external dependency? → NO (our pkg/workflow/engine)
├─ Do we control the logic? → YES (our business rules)
├─ Is it infrastructure? → NO (business logic layer)
└─ Decision: REAL ✅
```

**Use This Example For All Future Critical Decisions**:
- **External = Mock**: Database, K8s API, LLM services, network calls
- **Internal = Real**: Business logic, algorithms, validation rules, orchestration

### Examples of Correct Mock Usage

#### ✅ **Unit Test with Selective Mocking**
```go
var _ = Describe("BR-WORKFLOW-001: Intelligent Workflow Generation", func() {
    var (
        // Mock external dependencies only
        mockLLMProvider *mocks.MockLLMProvider
        mockK8sClient   *mocks.MockKubernetesClient

        // Use real business logic
        workflowBuilder *engine.IntelligentWorkflowBuilder
        safetyFramework *platform.SafetyFramework
        analyticsEngine *insights.AnalyticsEngine
    )

    BeforeEach(func() {
        // Mock only external/infrastructure dependencies
        mockLLMProvider = mocks.NewMockLLMProvider()
        mockK8sClient = mocks.NewMockKubernetesClient()

        // Create real business components
        safetyFramework = platform.NewSafetyFramework(realConfig)
        analyticsEngine = insights.NewAnalyticsEngine(realConfig)
        workflowBuilder = engine.NewIntelligentWorkflowBuilder(
            mockLLMProvider,    // Mock: External AI service
            mockK8sClient,      // Mock: External infrastructure
            safetyFramework,    // Real: Business safety logic
            analyticsEngine,    // Real: Business analytics logic
        )
    })

    It("should generate workflows with real business validation", func() {
        // Test real business logic integration
        workflow, err := workflowBuilder.CreateWorkflowFromAlert(ctx, alert)

        // Validate real business outcomes
        Expect(workflow.Template.SafetyValidation).ToNot(BeNil())
        Expect(safetyFramework.ValidateWorkflow(workflow)).To(Succeed())
    })
})
```

#### ❌ **Over-Mocking Anti-Pattern**
```go
// ❌ WRONG: Mocking internal business logic
var _ = Describe("Workflow Generation", func() {
    var (
        mockWorkflowBuilder *mocks.MockWorkflowBuilder  // ❌ Internal business logic
        mockSafetyFramework *mocks.MockSafetyFramework  // ❌ Internal business logic
        mockAnalyticsEngine *mocks.MockAnalyticsEngine  // ❌ Internal business logic
    )

    It("should generate workflows", func() {
        // ❌ Testing mock interactions, not real business logic
        mockWorkflowBuilder.EXPECT().CreateWorkflow().Return(fakeWorkflow)
        // No real business validation happening
    })
})
```

### Validation and Enforcement

#### **EXPANDED Automated Unit Test Coverage Detection**
```bash
# Add to cursor-rule-validator.sh
# Detect under-utilization of unit testing opportunities
find test/ -name "*_test.go" -exec grep -l "mock.*Engine\|mock.*Service\|mock.*Builder" {} \; | \
while read file; do
    if ! grep -q "external\|infrastructure\|slow\|error" "$file"; then
        echo "VIOLATION: Potential over-mocking in $file - could be unit tested with external mocks"
    fi
done

# NEW: Detect missed unit testing opportunities
find test/integration/ test/e2e/ -name "*_test.go" | \
while read file; do
    # Check if this test could be unit tested instead
    if grep -q "business.*logic\|algorithm\|validation\|calculation" "$file"; then
        if ! grep -q "real.*database\|real.*cluster\|real.*external" "$file"; then
            echo "OPPORTUNITY: $file might be unit testable with external mocks"
        fi
    fi
done

# NEW: Validate unit test coverage maximization
unit_test_count=$(find test/unit/ -name "*_test.go" | wc -l)
integration_test_count=$(find test/integration/ -name "*_test.go" | wc -l)
e2e_test_count=$(find test/e2e/ -name "*_test.go" | wc -l)

total_tests=$((unit_test_count + integration_test_count + e2e_test_count))
unit_percentage=$((unit_test_count * 100 / total_tests))

if [ $unit_percentage -lt 70 ]; then
    echo "WARNING: Unit test percentage ($unit_percentage%) below 70% minimum"
    echo "RECOMMENDATION: Review integration/e2e tests for unit testing opportunities"
fi
```

#### **EXPANDED Code Review Guidelines - UNIT TEST MAXIMIZATION**
- **Question Every Integration/E2E Test**: Why isn't this a unit test with external mocks?
- **Validate Higher Tier Justification**: Does this REQUIRE real integration or complete workflow?
- **Maximize Unit Coverage**: Can we test more business logic in unit tests?
- **Default to Unit Testing**: Integration/E2E only when unit testing insufficient
- **Challenge Non-Unit Tests**: Require explicit justification for non-unit testing choices
- **Prefer Business Logic Coverage**: Can we decompose complex scenarios into unit-testable components?

## Test File Organization - MANDATORY

### 🚨 **MANDATORY RULE: Test Suite File Organization**

All `*_suite_test.go` files **MUST** contain ONLY:

1. **Package declaration** and **imports**
2. **Business requirement documentation** (BR-XXX-XXX format)
3. **TestXXX function** with `RunSpecs` call
4. **NOTHING ELSE** - No business logic, no test implementations, no variables

#### Required Suite File Structure - ENFORCED

```go
package packagename

import (
    "testing"

    . "github.com/onsi/ginkgo/v2"
    . "github.com/onsi/gomega"
)

// BR-COMPONENT-SUITE-001: Component Business Test Suite Organization
// Business Impact: [Business impact description]
// Stakeholder Value: [Stakeholder value description]

func TestComponentName(t *testing.T) {
    RegisterFailHandler(Fail)
    RunSpecs(t, "Component Unit Tests Suite")
}
```

#### Implementation Files - SEPARATE AND REQUIRED

All test implementations **MUST** be in separate files:
- `*_test.go` files contain all test business logic
- `*_suite_test.go` files contain ONLY the `RunSpecs` function

### ✅ **CORRECT EXAMPLES**

#### ✅ Correct Suite File (`api_suite_test.go`)
```go
package api

import (
    "testing"

    . "github.com/onsi/ginkgo/v2"
    . "github.com/onsi/gomega"
)

func TestAPI(t *testing.T) {
    RegisterFailHandler(Fail)
    RunSpecs(t, "API Unit Tests Suite")
}
```

#### ✅ Separate Implementation File (`api_test.go`)
```go
package api

import (
    . "github.com/onsi/ginkgo/v2"
    . "github.com/onsi/gomega"

    "github.com/jordigilh/kubernaut/pkg/testutil"
)

// BR-API-001: API Business Operations
var _ = Describe("API Business Operations", func() {
    var (
        tddHelper *testutil.TDDConversionHelper
        testCtx   *testutil.StandardTestContext
    )

    BeforeEach(func() {
        tddHelper = testutil.NewTDDConversionHelper()
        testCtx = tddHelper.CreateStandardTestContext()
    })

    Context("When validating API business requirements", func() {
        It("should support business operations", func() {
            // Business test implementation here
        })
    })
})
```

### ❌ **FORBIDDEN PATTERNS - WILL BE REJECTED**

#### ❌ Business Logic in Suite File
```go
// WRONG: Contains business logic and variables
func TestWorkflow(t *testing.T) {
    RegisterFailHandler(Fail)
    RunSpecs(t, "Workflow Unit Tests Suite")
}

// ❌ FORBIDDEN: Business logic in suite file
var _ = Describe("Workflow Unit Tests", func() {
    var (
        workflowEngine engine.WorkflowEngine
        ctx            context.Context
    )

    BeforeEach(func() {
        // Business setup logic - FORBIDDEN in suite file
    })

    It("should do something", func() {
        // Test implementation - FORBIDDEN in suite file
    })
})
```

### Automated Suite Organization Validation

Use the validation script to enforce suite organization:

```bash
# Run suite organization validation
./scripts/test-suite-organization-check.sh

# Patterns automatically detected and rejected:
# - var _ = Describe|BeforeEach|AfterEach|Context|It in suite files
# - Variable declarations outside functions in suite files
# - Business logic imports in suite files
# - Missing RunSpecs function in suite files
```

## Test Environment Setup
### Development Environment
```bash
make bootstrap-dev     # Setup complete environment
make test-integration-dev  # Run tests
make cleanup-dev       # Clean up when done
```

### CI/CD Environment
```bash
make test-ci          # Run CI test suite with mocked LLM
```

## Testing Best Practices
1. **Business Outcome Focus**: Test business requirements, not implementation details (MANDATORY)
2. **Business Requirement Mapping**: All tests MUST reference specific BR-XXX-XXX requirements
3. **TDD Compliance**: Follow mandatory complete RED-GREEN-REFACTOR cycle
4. **Isolation**: Each test should be independent and repeatable
5. **Clear Naming**: Use descriptive test names that reflect business requirements
6. **Realistic Data**: Use realistic test data that mirrors production scenarios
7. **Error Scenarios**: Test both happy path and error conditions
8. **Performance**: Include performance assertions for critical paths
9. **Interface Validation**: Follow [09-interface-method-validation.mdc](mdc:.cursor/rules/09-interface-method-validation.mdc) before ANY interface usage
10. **Compilation Verification**: Run `go build` and `golangci-lint` on all modified files
11. **Type Safety**: Validate all type conversions, constructor usage, and method signatures

## Testing Anti-Patterns to AVOID

### **CRITICAL: Panic-Only Testing Anti-Pattern**
**❌ NEVER DO THIS:**
```go
// WRONG: Only tests function doesn't crash - provides NO business validation
Expect(func() {
    serviceDiscovery.TrackEventMetrics(eventType, processingTime, successful)
}).NotTo(Panic(), "Event tracking should be reliable")
```

**✅ CORRECT APPROACH:**
```go
// RIGHT: Tests actual business outcomes and requirements
initialMetrics := serviceDiscovery.GetEventMetrics()

serviceDiscovery.TrackEventMetrics(eventType, processingTime, successful)

finalMetrics := serviceDiscovery.GetEventMetrics()

// Business Requirement Validation: Operations team must see increased event counts
Expect(finalMetrics.TotalEventsProcessed).To(BeNumerically(">", initialMetrics.TotalEventsProcessed),
    "BR-HOLMES-029: Operations team should see increased total events for business visibility")

Expect(finalMetrics.SuccessfulEvents).To(BeNumerically(">", initialMetrics.SuccessfulEvents),
    "BR-HOLMES-029: Operations team should see increased successful events for performance monitoring")
```

**Why Panic-Only Testing is Dangerous:**
- ❌ **No Business Validation**: Test passes even if business requirement completely fails
- ❌ **False Confidence**: Provides illusion of testing without actual verification
- ❌ **Operations Risk**: Business users get no value, but tests show "green"
- ❌ **Cursor Rules Violation**: Violates mandatory business outcome focus

### **Comprehensive Testing Anti-Patterns - ENFORCED WITH REGEX DETECTION**

#### **PANIC-ONLY TESTING**: Testing only that functions don't crash without validating business outcomes
- **FORBIDDEN**: Testing only for absence of panics without business validation
- **REQUIRED**: Test actual business outcomes and requirements

#### **NULL-TESTING**: Weak assertions (not nil, > 0, empty checks)
- **FORBIDDEN PATTERNS**: `ToNot(BeEmpty())`, `ToNot(BeNil())`, `ToNot(BeZero())`
- **FORBIDDEN PATTERNS**: `len(x) > 0`, `x != nil`, `x != ""`
- **REQUIRED REPLACEMENT**: Business outcome assertions with BR-XXX-XXX references

#### **STATIC DATA TESTING**: Testing hardcoded values instead of business logic
- **FORBIDDEN**: `appName := "hardcoded"` followed by `Expect(appName)`
- **FORBIDDEN**: Testing variables assigned with string literals in tests
- **REQUIRED**: Test actual business service responses and state changes

#### **LIBRARY TESTING**: Testing third-party libraries instead of business logic
- **FORBIDDEN**: `logrus.New()`, `context.WithTimeout()`, `os.Setenv()` in business tests
- **FORBIDDEN**: Testing third-party library functionality instead of business logic
- **REQUIRED**: Test kubernaut-specific business interfaces and services

#### **IMPLEMENTATION TESTING**: Testing how instead of what business outcome
- **FORBIDDEN**: Testing internal implementation details
- **REQUIRED**: Test business value and outcomes

#### **MOCK OVERUSE**: Prefer real business logic over mocks for non-external dependencies
- **FORBIDDEN**: Mocking internal business logic, service orchestration, data transformations
- **REQUIRED**: Use mocks only for external services, slow operations, error simulation

#### **Skip() Usage**: Never use Skip() to avoid test failures - fix tests properly

#### **Local Mocks**: Create reusable mocks in [pkg/testutil/mocks/](mdc:pkg/testutil/mocks/) instead

## Infrastructure Requirements
- **Kind Cluster**: For local development and CI testing
- **PostgreSQL**: Real database for integration tests
- **Vector Database**: Separate PostgreSQL instance with pgvector
- **LLM Service**: Local AI model at 192.168.1.169:8080 or mocked for CI
- **Redis**: For caching integration tests

## Test Execution Strategy
- **Unit**: Run frequently during development
- **Integration**: Run before commits and in CI
- **E2E**: Run before releases and for major features

## EXPANDED Pyramid Confidence Targets
- **Unit Tests (70%+ MINIMUM)**: 90-95% confidence through MAXIMUM comprehensive business logic coverage
- **Integration Tests (selective)**: 85-90% confidence for critical component interactions that require real integration
- **E2E Tests (essential)**: 95-98% confidence for complete business workflows requiring production environments
- **Overall System**: 95% confidence through EXPANDED pyramid-based maximum unit testing foundation

## Pyramid Success Metrics

### **Coverage Distribution - EXPANDED UNIT EMPHASIS**
- **Unit Tests**: **70%+ of total requirements - EXTENDED to cover ALL unit-testable business requirements**
- **Integration Tests**: **Selective coverage - Critical component interactions that require real integration**
- **E2E Tests**: **Essential coverage - Critical business workflows requiring production-like environments**

**EXPANSION MANDATE**: Unit tests should strive to cover **EVERY business requirement that can be validated with mocked external dependencies**, maximizing the foundation layer coverage beyond the 70% minimum.

### **Issue Detection Timeline**
- **Unit Tests**: Catch **80-90% of issues** during development (immediate feedback)
- **Integration Tests**: Catch **10-15% additional issues** in component interactions
- **E2E Tests**: Catch **5-10% remaining issues** in complete workflows
- **Production**: **<1% issues reach production** (target: 0%)

### **Execution Performance**
- **Unit Tests**: **<10ms per test** - Fast feedback loop for development
- **Integration Tests**: **100-1000ms per test** - Reasonable CI/CD execution time
- **E2E Tests**: **1-10s per test** - Acceptable for critical workflow validation

### **Business Logic Coverage**
- **Unit Tests**: **100% business logic coverage** with mocked external dependencies
- **Integration Tests**: **100% business logic integration** with selective infrastructure mocking
- **E2E Tests**: **100% business workflow coverage** with minimal external API mocking

## ⚡ **TDD Completion Checklist - MANDATORY VERIFICATION**

Before any code submission, verify ALL phases completed:

### **🔴 TDD RED Phase Checklist**
- [ ] Business interfaces identified in pkg/ or cmd/
- [ ] Tests import actual business packages: `github.com/jordigilh/kubernaut/pkg/...`
- [ ] Tests call real business interfaces (not mocks for internal logic)
- [ ] All tests FAIL initially (RED phase verified)
- [ ] No `Skip()` usage to avoid failures
- [ ] Business requirement mapped (BR-XXX-XXX format)

### **🟢 TDD GREEN Phase Checklist**
- [ ] Minimum business logic implemented to make tests pass
- [ ] ALL tests PASS after implementation (GREEN phase verified)
- [ ] No over-engineering - only what's needed to pass tests
- [ ] Business logic exists in main application (not just tests)
- [ ] Compilation check: `go build` passes on all modified files
- [ ] Lint check: `golangci-lint` passes with no new errors

### **🔵 TDD REFACTOR Phase Checklist**
- [ ] **Performance Optimization**: Algorithms improved, caching added, data structures optimized
- [ ] **Code Quality**: Common patterns extracted, error handling improved, maintainability enhanced
- [ ] **Business Logic Enhancement**: Sophisticated business rules and calculations implemented
- [ ] **Architecture Improvement**: Design patterns applied, separation of concerns improved
- [ ] All tests REMAIN GREEN throughout refactoring
- [ ] Performance improvements verified and documented
- [ ] Business value enhancement confirmed

### **✅ TDD Completion Verification**
- [ ] Every test calls business logic from main application
- [ ] Business logic integrated in main application startup sequence
- [ ] No business functions exist only in test files
- [ ] Interface validation completed per [09-interface-method-validation.mdc](mdc:.cursor/rules/09-interface-method-validation.mdc)
- [ ] Type safety verified for all conversions and constructors
- [ ] Business integration assessment provided
- [ ] Confidence assessment provided (60-100% with detailed justification)

**CRITICAL**: TDD is INCOMPLETE without all three phases. Skipping REFACTOR phase violates mandatory TDD requirements.