package llm

import (
	"context"
	"strings"
	"time"

	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"
	"github.com/sirupsen/logrus"

	"github.com/jordigilh/kubernaut/pkg/shared/types"
	"github.com/jordigilh/kubernaut/pkg/testutil/mocks"
)

// Suite structure moved to llm_suite_test.go - generated by ginkgo bootstrap

var _ = Describe("LLM Integration Layer - Business Requirements Testing", func() {
	var (
		logger         *logrus.Logger
		ctx            context.Context
		llmClient      *mocks.MockLLMClient
		enhancedClient *mocks.MockLLMClient
	)

	BeforeEach(func() {
		logger = logrus.New()
		logger.SetLevel(logrus.WarnLevel)
		ctx = context.Background()

		llmClient = mocks.NewMockLLMClient()
		enhancedClient = mocks.NewMockLLMClient()
	})

	// BR-LLM-001: MUST support OpenAI GPT models (GPT-3.5, GPT-4, GPT-4o)
	Context("BR-LLM-001: OpenAI GPT Models Support", func() {
		It("should support multiple OpenAI GPT model variants with appropriate configurations", func() {
			// Arrange: Create requests for different GPT models
			gptModels := []string{"gpt-3.5-turbo", "gpt-4", "gpt-4o", "gpt-4-turbo"}

			alert := &types.Alert{
				Name:        "HighCPUUsage",
				Severity:    "critical",
				Namespace:   "production",
				Description: "CPU usage exceeded 80% for 5 minutes",
			}

			for _, model := range gptModels {
				// Setup mock response specific to model capabilities
				expectedResponse := createModelSpecificResponse(model, alert)
				llmClient.SetAnalysisResponse(expectedResponse)

				// Act: Analyze alert with specific GPT model
				response, err := llmClient.AnalyzeAlertWithModel(ctx, alert, model)

				// **Business Requirement BR-LLM-001**: Validate GPT model support
				Expect(err).ToNot(HaveOccurred(),
					"Should successfully analyze alert with %s", model)
				Expect(response.RecommendedAction).ToNot(BeEmpty(),
					"BR-LLM-001: %s should provide actionable recommendations", model)
				Expect(response.Confidence).To(BeNumerically(">=", 0.7),
					"BR-LLM-001: %s should provide confident analysis (≥70%%)", model)

				// **Business Value Validation**: Verify model-specific capabilities
				validateModelCapabilities(model, response)
			}
		})

		It("should handle OpenAI API rate limiting and quota management", func() {
			// Arrange: Create scenario with rate limiting
			alert := &types.Alert{
				Name:      "DatabaseConnectionFailure",
				Severity:  "critical",
				Namespace: "production",
			}

			// Setup mock to simulate rate limiting then success
			llmClient.SetRateLimitScenario(3, 2*time.Second) // 3 retries, 2 second delay
			llmClient.SetAnalysisResponse(&mocks.AnalysisResponse{
				RecommendedAction: "restart_database_pod",
				Confidence:        0.89,
				Reasoning:         "Successful retry after rate limiting",
				ProcessingTime:    6 * time.Second, // Includes retry delays
				Metadata: map[string]interface{}{
					"retries_attempted":  2,
					"rate_limit_handled": true,
				},
			})

			// Act: Analyze with rate limiting scenario
			response, err := llmClient.AnalyzeAlertWithModel(ctx, alert, "gpt-4")

			// **Business Requirement BR-LLM-009**: Validate rate limiting handling
			Expect(err).ToNot(HaveOccurred(), "Should successfully handle rate limiting")
			Expect(response.ProcessingTime).To(BeNumerically(">=", 4*time.Second),
				"BR-LLM-009: Should account for retry delays in processing time")

			rateLimitHandled, exists := response.Metadata["rate_limit_handled"]
			Expect(exists).To(BeTrue(), "BR-LLM-009: Should track rate limit handling")
			Expect(rateLimitHandled).To(BeTrue(),
				"BR-LLM-009: Should successfully manage OpenAI rate limits")

			retriesAttempted, exists := response.Metadata["retries_attempted"]
			Expect(exists).To(BeTrue(), "BR-LLM-009: Should track retry attempts")
			Expect(retriesAttempted).To(BeNumerically(">=", 1),
				"BR-LLM-009: Should demonstrate retry mechanism")
		})
	})

	// BR-LLM-002: MUST support Anthropic Claude models (Claude-3, Claude-3.5)
	Context("BR-LLM-002: Anthropic Claude Models Support", func() {
		It("should support Claude model variants with appropriate prompt engineering", func() {
			// Arrange: Create requests for Claude models
			claudeModels := []string{"claude-3-opus", "claude-3-sonnet", "claude-3-haiku", "claude-3.5-sonnet"}

			alert := &types.Alert{
				Name:        "MemoryPressure",
				Severity:    "warning",
				Namespace:   "staging",
				Description: "Memory usage approaching 85% threshold",
			}

			for _, model := range claudeModels {
				// Setup mock response with Claude-specific characteristics
				expectedReasoning := createClaudeSpecificReasoning(model, alert)
				llmClient.SetAnalysisResponse(&mocks.AnalysisResponse{
					RecommendedAction: "increase_memory_limit",
					Confidence:        0.87,
					Reasoning:         expectedReasoning,
					ProcessingTime:    3 * time.Second,
					Metadata: map[string]interface{}{
						"model_used":      model,
						"prompt_style":    "claude_optimized",
						"reasoning_depth": getClaudeReasoningDepth(model),
					},
				})

				// Act: Analyze alert with Claude model
				response, err := llmClient.AnalyzeAlertWithModel(ctx, alert, model)

				// **Business Requirement BR-LLM-002**: Validate Claude model support
				Expect(err).ToNot(HaveOccurred(),
					"Should successfully analyze alert with %s", model)
				Expect(response.Confidence).To(BeNumerically(">=", 0.8),
					"BR-LLM-002: %s should provide high confidence analysis", model)

				// **Business Value Validation**: Verify Claude-specific reasoning
				Expect(strings.Contains(response.Reasoning, "analysis") ||
					strings.Contains(response.Reasoning, "consideration")).To(BeTrue(),
					"BR-LLM-002: Claude models should provide detailed analytical reasoning")

				reasoningDepth, exists := response.Metadata["reasoning_depth"]
				Expect(exists).To(BeTrue(), "BR-LLM-002: Should track reasoning depth")
				Expect(reasoningDepth).To(BeNumerically(">=", 0.8),
					"BR-LLM-002: Claude models should provide deep reasoning (≥80%%)")
			}
		})
	})

	// BR-LLM-006: MUST provide intelligent response parsing with error handling
	Context("BR-LLM-006: Intelligent Response Parsing", func() {
		It("should parse structured responses with comprehensive error handling", func() {
			// Arrange: Create response parsing scenarios
			testScenarios := []struct {
				name           string
				rawResponse    string
				expectedValid  bool
				expectedAction string
			}{
				{
					name: "valid_json_response",
					rawResponse: `{
						"recommended_action": "scale_deployment",
						"confidence": 0.85,
						"reasoning": "High load detected, scaling recommended",
						"parameters": {"replicas": 5}
					}`,
					expectedValid:  true,
					expectedAction: "scale_deployment",
				},
				{
					name: "malformed_json_with_recovery",
					rawResponse: `{
						"recommended_action": "restart_pod",
						"confidence": 0.78,
						"reasoning": "Pod appears to be in crash loop"
						// Missing closing brace - should be recovered
					`,
					expectedValid:  true,
					expectedAction: "restart_pod",
				},
				{
					name:           "natural_language_extraction",
					rawResponse:    `Based on the alert analysis, I recommend restarting the pod with confidence level 0.82. The reasoning is that the pod shows signs of memory leaks.`,
					expectedValid:  true,
					expectedAction: "restart_pod",
				},
			}

			for _, scenario := range testScenarios {
				// Setup mock response parser
				enhancedClient.SetRawResponse(scenario.rawResponse)

				if scenario.expectedValid {
					enhancedClient.SetParsedResponse(&mocks.AnalysisResponse{
						RecommendedAction: scenario.expectedAction,
						Confidence:        0.8,
						Reasoning:         "Parsed from response",
						Metadata: map[string]interface{}{
							"parsing_method":     determineParsingMethod(scenario.rawResponse),
							"parsing_confidence": 0.9,
							"recovery_applied":   strings.Contains(scenario.name, "recovery"),
						},
					})
				}

				// Act: Parse response
				parsed, err := enhancedClient.ParseResponse(ctx, scenario.rawResponse)

				if scenario.expectedValid {
					// **Business Requirement BR-LLM-006**: Validate intelligent parsing
					Expect(err).ToNot(HaveOccurred(),
						"Should successfully parse %s", scenario.name)
					Expect(parsed.RecommendedAction).To(Equal(scenario.expectedAction),
						"BR-LLM-006: Should extract correct action from %s", scenario.name)

					// **Business Value Validation**: Verify parsing intelligence
					parsingMethod, exists := parsed.Metadata["parsing_method"]
					Expect(exists).To(BeTrue(), "BR-LLM-006: Should track parsing method")

					// **BR-LLM-006 Compliance**: Validate correct parsing method selection
					expectedParsingMethod := determineParsingMethod(scenario.rawResponse)
					Expect(parsingMethod).To(Equal(expectedParsingMethod),
						"BR-LLM-006: Should intelligently select parsing method - expected '%s' for %s",
						expectedParsingMethod, scenario.name)

					parsingConfidence, exists := parsed.Metadata["parsing_confidence"]
					Expect(exists).To(BeTrue(), "BR-LLM-006: Should track parsing confidence")
					Expect(parsingConfidence).To(BeNumerically(">=", 0.8),
						"BR-LLM-006: Parsing should be highly confident (≥80%%)")
				} else {
					Expect(err).To(HaveOccurred(),
						"Should fail to parse invalid response for %s", scenario.name)
				}
			}
		})

		It("should validate response format and content completeness", func() {
			// Arrange: Create validation scenarios
			alert := &types.Alert{
				Name:      "ServiceUnavailable",
				Severity:  "critical",
				Namespace: "production",
			}

			// Setup comprehensive response validation
			enhancedClient.SetAnalysisResponse(&mocks.AnalysisResponse{
				RecommendedAction: "restart_deployment",
				Confidence:        0.91,
				Reasoning:         "Service is completely unresponsive, restart required",
				ProcessingTime:    2 * time.Second,
				Metadata: map[string]interface{}{
					"validation_results": map[string]interface{}{
						"action_valid":       true,
						"confidence_valid":   true,
						"reasoning_present":  true,
						"completeness_score": 0.95,
					},
					"content_checks": map[string]interface{}{
						"has_action":     true,
						"has_confidence": true,
						"has_reasoning":  true,
						"has_parameters": false, // Optional
					},
				},
			})

			// Act: Validate response completeness
			response, err := enhancedClient.AnalyzeAlertWithModel(ctx, alert, "gpt-4")

			// **Business Requirement BR-LLM-012**: Validate format and completeness
			Expect(err).ToNot(HaveOccurred(), "Should successfully validate response")

			validationResults, exists := response.Metadata["validation_results"]
			Expect(exists).To(BeTrue(), "BR-LLM-012: Should provide validation results")

			results, ok := validationResults.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-LLM-012: Validation results should be structured")

			completenessScore := results["completeness_score"]
			Expect(completenessScore).To(BeNumerically(">=", 0.9),
				"BR-LLM-012: Response should be highly complete (≥90%%)")

			// Validate required content checks
			contentChecks, exists := response.Metadata["content_checks"]
			Expect(exists).To(BeTrue(), "BR-LLM-012: Should perform content validation")

			checks, ok := contentChecks.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-LLM-012: Content checks should be structured")

			requiredFields := []string{"has_action", "has_confidence", "has_reasoning"}
			for _, field := range requiredFields {
				value, exists := checks[field]
				Expect(exists).To(BeTrue(), "BR-LLM-012: Should check %s", field)
				Expect(value).To(BeTrue(), "BR-LLM-012: Required field %s should be present", field)
			}
		})
	})

	// BR-LLM-016: MUST optimize prompts for different model capabilities and contexts
	Context("BR-LLM-016: Prompt Optimization Framework", func() {
		It("should optimize prompts for different model capabilities and alert contexts", func() {
			// Arrange: Create different alert contexts requiring prompt optimization
			alertContexts := []struct {
				alert              *types.Alert
				modelType          string
				expectedPromptType string
			}{
				{
					alert: &types.Alert{
						Name:        "ComplexNetworkIssue",
						Severity:    "critical",
						Description: "Multiple service failures with network connectivity issues",
					},
					modelType:          "gpt-4",
					expectedPromptType: "detailed_analysis",
				},
				{
					alert: &types.Alert{
						Name:        "SimpleMemoryAlert",
						Severity:    "warning",
						Description: "Memory usage at 75%",
					},
					modelType:          "gpt-3.5-turbo",
					expectedPromptType: "concise_action",
				},
				{
					alert: &types.Alert{
						Name:        "SecurityIncident",
						Severity:    "critical",
						Description: "Suspicious authentication attempts detected",
					},
					modelType:          "claude-3-opus",
					expectedPromptType: "security_focused",
				},
			}

			for _, context := range alertContexts {
				// Setup mock with optimized prompt response
				enhancedClient.SetAnalysisResponse(&mocks.AnalysisResponse{
					RecommendedAction: "context_appropriate_action",
					Confidence:        0.88,
					Reasoning:         "Analysis optimized for model capabilities and alert context",
					Metadata: map[string]interface{}{
						"prompt_optimization": map[string]interface{}{
							"model_type":         context.modelType,
							"prompt_type":        context.expectedPromptType,
							"optimization_score": 0.92,
							"context_factors": []string{
								"alert_complexity",
								"model_capabilities",
								"response_requirements",
							},
						},
						"prompt_engineering": map[string]interface{}{
							"token_efficiency":   0.87,
							"clarity_score":      0.94,
							"effectiveness_rate": 0.91,
						},
					},
				})

				// Act: Analyze with prompt optimization
				response, err := enhancedClient.AnalyzeAlertWithModel(ctx, context.alert, context.modelType)

				// **Business Requirement BR-LLM-016**: Validate prompt optimization
				Expect(err).ToNot(HaveOccurred(),
					"Should successfully optimize prompts for %s with %s", context.modelType, context.alert.Name)

				// **Business Value Validation**: Verify optimization quality
				promptOptimization, exists := response.Metadata["prompt_optimization"]
				Expect(exists).To(BeTrue(), "BR-LLM-016: Should provide prompt optimization metrics")

				optimization, ok := promptOptimization.(map[string]interface{})
				Expect(ok).To(BeTrue(), "BR-LLM-016: Optimization data should be structured")

				optimizationScore := optimization["optimization_score"]
				Expect(optimizationScore).To(BeNumerically(">=", 0.85),
					"BR-LLM-016: Prompt optimization should be highly effective (≥85%%)")

				promptType := optimization["prompt_type"]
				Expect(promptType).To(Equal(context.expectedPromptType),
					"BR-LLM-016: Should use appropriate prompt type for context")

				// **BR-LLM-017**: Validate dynamic prompt generation
				contextFactors, exists := optimization["context_factors"]
				Expect(exists).To(BeTrue(), "BR-LLM-017: Should consider context factors")
				factors, ok := contextFactors.([]string)
				Expect(ok).To(BeTrue(), "BR-LLM-017: Context factors should be structured")
				Expect(len(factors)).To(BeNumerically(">=", 2),
					"BR-LLM-017: Should consider multiple context factors")

				// Validate prompt engineering metrics
				promptEngineering, exists := response.Metadata["prompt_engineering"]
				Expect(exists).To(BeTrue(), "BR-LLM-016: Should provide engineering metrics")

				engineering, ok := promptEngineering.(map[string]interface{})
				Expect(ok).To(BeTrue(), "BR-LLM-016: Engineering metrics should be structured")

				effectivenessRate := engineering["effectiveness_rate"]
				Expect(effectivenessRate).To(BeNumerically(">=", 0.85),
					"BR-LLM-016: Prompt effectiveness should be high (≥85%%)")
			}
		})
	})

	// BR-LLM-020: MUST maintain prompt performance analytics
	Context("BR-LLM-020: Prompt Performance Analytics", func() {
		It("should track and analyze prompt performance metrics across models and contexts", func() {
			// Arrange: Create performance analytics scenario
			alert := &types.Alert{
				Name:        "PerformanceAnalyticsTest",
				Severity:    "warning",
				Namespace:   "testing",
				Description: "Test alert for prompt performance analysis",
			}

			// Setup mock with comprehensive performance analytics
			enhancedClient.SetAnalysisResponse(&mocks.AnalysisResponse{
				RecommendedAction: "monitor_and_tune",
				Confidence:        0.84,
				Reasoning:         "Performance metrics indicate optimization opportunities",
				ProcessingTime:    1500 * time.Millisecond,
				Metadata: map[string]interface{}{
					"performance_analytics": map[string]interface{}{
						"prompt_version":    "v2.1",
						"response_time_ms":  1500,
						"token_efficiency":  0.89,
						"accuracy_rate":     0.84,
						"user_satisfaction": 0.87,
						"cost_per_request":  0.045,
					},
					"comparative_metrics": map[string]interface{}{
						"vs_previous_version": map[string]interface{}{
							"speed_improvement":    0.15,
							"accuracy_improvement": 0.08,
							"cost_reduction":       0.12,
						},
						"vs_baseline": map[string]interface{}{
							"performance_gain": 0.22,
							"efficiency_gain":  0.18,
						},
					},
					"trend_analysis": map[string]interface{}{
						"7_day_trend":      "improving",
						"accuracy_trend":   "stable",
						"efficiency_trend": "improving",
						"cost_trend":       "decreasing",
					},
				},
			})

			// Act: Analyze with performance tracking
			response, err := enhancedClient.AnalyzeAlertWithModel(ctx, alert, "gpt-4")

			// **Business Requirement BR-LLM-020**: Validate performance analytics
			Expect(err).ToNot(HaveOccurred(), "Should successfully track performance analytics")

			// **Business Value Validation**: Verify comprehensive performance tracking
			performanceAnalytics, exists := response.Metadata["performance_analytics"]
			Expect(exists).To(BeTrue(), "BR-LLM-020: Should provide performance analytics")

			analytics, ok := performanceAnalytics.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-LLM-020: Performance analytics should be structured")

			// Validate key performance metrics
			requiredMetrics := []string{
				"response_time_ms", "token_efficiency",
				"accuracy_rate", "cost_per_request",
			}
			for _, metric := range requiredMetrics {
				value, exists := analytics[metric]
				Expect(exists).To(BeTrue(), "BR-LLM-020: Should track %s", metric)
				Expect(value).To(BeNumerically(">", 0), "BR-LLM-020: %s should have valid value", metric)
			}

			// **Business Value Validation**: Verify comparative analysis
			comparativeMetrics, exists := response.Metadata["comparative_metrics"]
			Expect(exists).To(BeTrue(), "BR-LLM-020: Should provide comparative analysis")

			comparative, ok := comparativeMetrics.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-LLM-020: Comparative metrics should be structured")

			// Validate improvement tracking
			vsPrevious, exists := comparative["vs_previous_version"]
			Expect(exists).To(BeTrue(), "BR-LLM-020: Should compare with previous versions")

			improvements, ok := vsPrevious.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-LLM-020: Version comparisons should be structured")

			speedImprovement := improvements["speed_improvement"]
			Expect(speedImprovement).To(BeNumerically(">=", 0),
				"BR-LLM-020: Should track speed improvements")

			// Validate trend analysis
			trendAnalysis, exists := response.Metadata["trend_analysis"]
			Expect(exists).To(BeTrue(), "BR-LLM-020: Should provide trend analysis")

			trends, ok := trendAnalysis.(map[string]interface{})
			Expect(ok).To(BeTrue(), "BR-LLM-020: Trend analysis should be structured")

			accuracyTrend := trends["accuracy_trend"]
			Expect(accuracyTrend).ToNot(BeEmpty(), "BR-LLM-020: Should identify accuracy trends")
		})
	})
})

// Helper functions for test data creation and validation
func createModelSpecificResponse(model string, alert *types.Alert) *mocks.AnalysisResponse {
	baseResponse := &mocks.AnalysisResponse{
		RecommendedAction: "increase_resources",
		Confidence:        0.85,
		Reasoning:         "High CPU usage requires resource scaling",
		ProcessingTime:    3 * time.Second,
	}

	// Adjust response based on model capabilities
	switch {
	case strings.Contains(model, "gpt-4"):
		baseResponse.Confidence = 0.92
		baseResponse.Reasoning = "Detailed analysis indicates CPU pressure with high confidence"
	case strings.Contains(model, "gpt-3.5"):
		baseResponse.ProcessingTime = 2 * time.Second
		baseResponse.Reasoning = "CPU usage high, scale recommended"
	}

	baseResponse.Metadata = map[string]interface{}{
		"model_used":   model,
		"model_family": getModelFamily(model),
		"capabilities": getModelCapabilities(model),
	}

	return baseResponse
}

func validateModelCapabilities(model string, response *mocks.AnalysisResponse) {
	modelFamily := getModelFamily(model)

	switch modelFamily {
	case "gpt-4":
		Expect(response.Confidence).To(BeNumerically(">=", 0.85),
			"GPT-4 models should provide high confidence analysis")
	case "gpt-3.5":
		Expect(response.ProcessingTime).To(BeNumerically("<=", 5*time.Second),
			"GPT-3.5 models should provide faster responses")
	}
}

func createClaudeSpecificReasoning(model string, alert *types.Alert) string {
	switch {
	case strings.Contains(model, "opus"):
		return "Comprehensive analysis of memory patterns indicates approaching threshold with detailed consideration of system impacts"
	case strings.Contains(model, "sonnet"):
		return "Memory usage analysis suggests proactive limit increase to prevent performance degradation"
	case strings.Contains(model, "haiku"):
		return "Memory analysis shows approaching limit, increase recommended for system consideration"
	default:
		return "Claude analysis recommends memory limit adjustment"
	}
}

func getClaudeReasoningDepth(model string) float64 {
	switch {
	case strings.Contains(model, "opus"):
		return 0.95
	case strings.Contains(model, "sonnet"):
		return 0.85
	case strings.Contains(model, "haiku"):
		return 0.80
	default:
		return 0.80
	}
}

func determineParsingMethod(rawResponse string) string {
	if strings.HasPrefix(strings.TrimSpace(rawResponse), "{") {
		return "json_parsing"
	}
	return "nlp_extraction"
}

func getModelFamily(model string) string {
	switch {
	case strings.Contains(model, "gpt-4"):
		return "gpt-4"
	case strings.Contains(model, "gpt-3.5"):
		return "gpt-3.5"
	case strings.Contains(model, "claude"):
		return "claude"
	default:
		return "unknown"
	}
}

func getModelCapabilities(model string) []string {
	baseCapabilities := []string{"analysis", "recommendations"}

	switch {
	case strings.Contains(model, "gpt-4"):
		return append(baseCapabilities, "complex_reasoning", "detailed_analysis", "multi_step_planning")
	case strings.Contains(model, "gpt-3.5"):
		return append(baseCapabilities, "fast_processing", "concise_responses")
	case strings.Contains(model, "claude"):
		return append(baseCapabilities, "ethical_reasoning", "detailed_explanations", "safety_focused")
	default:
		return baseCapabilities
	}
}
