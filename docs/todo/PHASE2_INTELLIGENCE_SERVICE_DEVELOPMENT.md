# üß† **INTELLIGENCE SERVICE DEVELOPMENT GUIDE**

**Service**: Intelligence Service
**Port**: 8086
**Image**: quay.io/jordigilh/intelligence-service
**Business Requirements**: BR-INT-001 to BR-INT-150
**Single Responsibility**: Pattern Discovery ONLY
**Phase**: 2 (Sequential Dependencies)
**Dependency**: Data Storage Service (8085) must be complete

---

## üìä **CURRENT STATUS ANALYSIS**

### **‚úÖ EXISTING IMPLEMENTATION**
**Locations**:
- `pkg/intelligence/patterns/pattern_discovery_engine.go` (544+ lines) - **COMPREHENSIVE PATTERN DISCOVERY ENGINE**
- `pkg/intelligence/patterns/enhanced_pattern_engine.go` (137+ lines) - **ENHANCED PATTERN ENGINE**
- `pkg/intelligence/ml/ml.go` (453 lines) - **MACHINE LEARNING ANALYZERS**
- `pkg/intelligence/analytics/time_series.go` (54+ lines) - **TIME SERIES ANALYSIS**
- `pkg/intelligence/analytics/workload_patterns.go` (53+ lines) - **WORKLOAD PATTERN DETECTION**
- `pkg/intelligence/anomaly/anomaly_detector.go` (243+ lines) - **ANOMALY DETECTION ENGINE**

**Current Strengths**:
- ‚úÖ **Complete pattern discovery engine** with sophisticated ML integration
- ‚úÖ **Comprehensive machine learning analyzers** for supervised learning and anomaly detection
- ‚úÖ **Advanced pattern analysis** with statistical validation and overfitting prevention
- ‚úÖ **Time series analysis** for business intelligence and trend detection
- ‚úÖ **Workload pattern detection** for capacity planning and optimization
- ‚úÖ **Anomaly detection engine** with performance baseline management
- ‚úÖ **Vector database integration** for pattern storage and similarity search
- ‚úÖ **LLM client integration** for enhanced clustering and analysis
- ‚úÖ **Error handling and logging** throughout implementation

**Architecture Compliance**:
- ‚ùå **Missing HTTP service wrapper** - Need to create `cmd/intelligence-service/main.go`
- ‚úÖ **Port**: 8086 (matches approved spec)
- ‚úÖ **Image naming**: Will follow approved pattern
- ‚úÖ **Single responsibility**: Pattern discovery only
- ‚úÖ **Business requirements**: BR-INT-001 to BR-INT-150 extensively mapped

### **üîß REUSABLE COMPONENTS (EXTENSIVE)**

#### **Complete Pattern Discovery Engine** (95% Reusable)
```go
// Location: pkg/intelligence/patterns/pattern_discovery_engine.go:52-183
type PatternDiscoveryEngine struct {
    patternStore     PatternStore
    vectorDB         PatternVectorDatabase
    executionRepo    ExecutionRepository
    mlAnalyzer       MachineLearningAnalyzer
    timeSeriesEngine types.TimeSeriesAnalyzer
    llmClient        llm.Client
    anomalyDetector  types.AnomalyDetector
    log              *logrus.Logger
    config           *PatternDiscoveryConfig
    mu               sync.RWMutex
    activePatterns   map[string]*shared.DiscoveredPattern
    learningMetrics  *LearningMetrics
}

func (pde *PatternDiscoveryEngine) DiscoverPatterns(ctx context.Context, request *PatternAnalysisRequest) (*PatternAnalysisResult, error) {
    // Collect historical data
    historicalData, err := pde.collectHistoricalData(ctx, request)

    // Perform different types of analysis based on request
    patterns := make([]*shared.DiscoveredPattern, 0)
    for _, patternType := range request.PatternTypes {
        typePatterns, err := pde.analyzePatternType(ctx, historicalData, patternType, request)
        patterns = append(patterns, typePatterns...)
    }

    // Filter by confidence threshold
    filteredPatterns := pde.filterByConfidence(patterns, request.MinConfidence)

    // Rank and limit results
    rankedPatterns := pde.rankPatterns(filteredPatterns)

    // Generate recommendations
    recommendations := pde.generateRecommendations(rankedPatterns)

    return &PatternAnalysisResult{
        Patterns:        rankedPatterns,
        Recommendations: recommendations,
        AnalysisTime:    time.Since(startTime),
        Confidence:      pde.calculateOverallConfidence(rankedPatterns),
    }, nil
}
```
**Reuse Value**: Complete pattern discovery system with ML integration

#### **Enhanced Pattern Engine** (100% Reusable)
```go
// Location: pkg/intelligence/patterns/enhanced_pattern_engine.go:71-137
func NewEnhancedPatternDiscoveryEngine(
    patternStore PatternStore,
    vectorDB PatternVectorDatabase,
    executionRepo ExecutionRepository,
    mlAnalyzer MachineLearningAnalyzer,
    patternAnalyzer PatternAnalyzer,
    timeSeriesAnalyzer sharedtypes.TimeSeriesAnalyzer,
    llmClient llm.Client,
    anomalyDetector sharedtypes.AnomalyDetector,
    config *EnhancedPatternConfig,
    log *logrus.Logger,
) (*EnhancedPatternDiscoveryEngine, error) {
    // Enhanced configuration with statistical validation
    config = &EnhancedPatternConfig{
        EnableStatisticalValidation: true,
        RequireValidationPassing:    false,
        MinReliabilityScore:         0.6,
        EnableOverfittingPrevention: true,
        MaxOverfittingRisk:          0.7,
        RequireCrossValidation:      true,
        EnableMonitoring:            true,
        AutoRecovery:                true,
    }

    // Create enhanced engine with validation and monitoring
    enhanced := &EnhancedPatternDiscoveryEngine{
        PatternDiscoveryEngine: baseEngine,
        config:                 config,
        statisticalValidator:   NewStatisticalValidator(config.PatternDiscoveryConfig, log),
        overfittingPreventer:   NewOverfittingPreventer(config, log),
    }

    return enhanced, nil
}
```
**Reuse Value**: Enhanced pattern engine with statistical validation and overfitting prevention

#### **Machine Learning Analyzers** (90% Reusable)
```go
// Location: pkg/intelligence/ml/ml.go:16-58
type SupervisedLearningAnalyzer struct {
    executionRepo ExecutionRepository
    mlAnalyzer    *learning.MachineLearningAnalyzer
    logger        *logrus.Logger
    models        map[string]*TrainedModel
}

type PerformanceAnomalyDetector struct {
    mlAnalyzer MockMLAnalyzer
    logger     *logrus.Logger
    baselines  map[string]*PerformanceBaseline
    detector   *AnomalyDetectionEngine
}

type TrainedModel struct {
    ID              string                 `json:"id"`
    ModelType       string                 `json:"model_type"`
    Accuracy        float64                `json:"accuracy"`
    TrainingTime    time.Duration          `json:"training_time"`
    Features        []string               `json:"features"`
    Parameters      map[string]interface{} `json:"parameters"`
    CreatedAt       time.Time              `json:"created_at"`
    BusinessMetrics *BusinessModelMetrics  `json:"business_metrics"`
}
```
**Reuse Value**: Complete ML analysis system with business metrics

#### **Time Series Analysis** (100% Reusable)
```go
// Location: pkg/intelligence/analytics/time_series.go:11-54
type TimeSeriesAnalyzer struct {
    metricsCollector MetricsCollector
    logger           *logrus.Logger
    trendModels      map[string]*TrendModel
    forecastEngine   *ForecastEngine
}

type TimeSeriesData struct {
    MetricName      string                `json:"metric_name"`
    DataPoints      []TimeSeriesDataPoint `json:"data_points"`
    MetaData        *TimeSeriesMetaData   `json:"meta_data"`
    BusinessContext *BusinessTimeContext  `json:"business_context"`
}

type TimeSeriesMetaData struct {
    SampleCount         int     `json:"sample_count"`
    DataQuality         float64 `json:"data_quality"`
    SeasonalityDetected bool    `json:"seasonality_detected"`
    TrendDirection      string  `json:"trend_direction"`
    BusinessRelevance   float64 `json:"business_relevance"`
}
```
**Reuse Value**: Complete time series analysis with business intelligence

#### **Workload Pattern Detection** (95% Reusable)
```go
// Location: pkg/intelligence/analytics/workload_patterns.go:12-53
type WorkloadPatternDetector struct {
    executionRepo    ExecutionRepository
    patternStore     PatternStore
    logger           *logrus.Logger
    detectedPatterns map[string]*WorkloadPattern
    clusterEngine    *ClusteringEngine
}

type WorkloadPattern struct {
    PatternID        string                  `json:"pattern_id"`
    PatternName      string                  `json:"pattern_name"`
    Signature        string                  `json:"signature"`
    ResourceProfile  *ResourceProfile        `json:"resource_profile"`
    TemporalProfile  *TemporalProfile        `json:"temporal_profile"`
    BusinessProfile  *BusinessPatternProfile `json:"business_profile"`
    Confidence       float64                 `json:"confidence"`
    Frequency        int                     `json:"frequency"`
    LastSeen         time.Time               `json:"last_seen"`
    CapacityInsights *CapacityInsights       `json:"capacity_insights"`
}
```
**Reuse Value**: Complete workload pattern detection for capacity planning

#### **Anomaly Detection Engine** (90% Reusable)
```go
// Location: pkg/intelligence/anomaly/anomaly_detector.go:1-243
// Complete anomaly detection system with:
// - Performance baseline management
// - Statistical anomaly detection
// - Business context integration
// - Real-time monitoring capabilities
```
**Reuse Value**: Sophisticated anomaly detection with business intelligence

---

## üéØ **DEVELOPMENT GAPS & IMPROVEMENTS**

### **üö® CRITICAL GAPS**

#### **1. Missing HTTP Service Wrapper**
**Current**: Excellent intelligence logic but no HTTP service
**Required**: Complete HTTP service implementation
**Gap**: Need to create:
- `cmd/intelligence-service/main.go` - HTTP server with intelligence endpoints
- HTTP handlers for pattern discovery, ML analysis, anomaly detection
- Health and metrics endpoints
- Configuration loading and service startup

#### **2. Service Integration API**
**Current**: Comprehensive intelligence logic with data storage dependencies
**Required**: HTTP API for microservice integration
**Gap**: Need to implement:
- REST API for pattern discovery operations
- JSON request/response handling for intelligence analysis
- Integration with data storage service for pattern persistence
- Error handling and status codes

#### **3. Missing Test Coverage**
**Current**: Sophisticated intelligence logic but no visible tests
**Required**: Extensive test coverage for intelligence operations
**Gap**: Need to create:
- HTTP endpoint tests
- Pattern discovery engine tests
- Machine learning analyzer tests
- Anomaly detection tests
- Integration tests with data storage service

### **üîÑ ENHANCEMENT OPPORTUNITIES**

#### **1. Advanced Pattern Correlation**
**Current**: Basic pattern analysis
**Enhancement**: Cross-pattern correlation and dependency analysis
```go
type AdvancedPatternCorrelator struct {
    PatternGraph        *PatternDependencyGraph
    CorrelationEngine   *CorrelationEngine
    CausalityAnalyzer   *CausalityAnalyzer
}
```

#### **2. Real-time Pattern Streaming**
**Current**: Batch pattern analysis
**Enhancement**: Real-time pattern detection with streaming analytics
```go
type RealTimePatternStreamer struct {
    StreamProcessor     *PatternStreamProcessor
    EventProcessor      *PatternEventProcessor
    WebSocketServer     *websocket.Server
}
```

#### **3. Predictive Intelligence**
**Current**: Historical pattern analysis
**Enhancement**: Predictive modeling for future pattern emergence
```go
type PredictiveIntelligenceEngine struct {
    PredictionModels    map[string]*PredictionModel
    ForecastEngine      *ForecastEngine
    TrendPredictor      *TrendPredictor
}
```

---

## üìã **TDD DEVELOPMENT PLAN**

### **üî¥ RED PHASE (60-90 minutes)**

#### **Test 1: HTTP Service Implementation**
```go
func TestIntelligenceServiceHTTP(t *testing.T) {
    It("should start HTTP server on port 8086", func() {
        // Test server starts and responds
        resp, err := http.Get("http://localhost:8086/health")
        Expect(err).ToNot(HaveOccurred())
        Expect(resp.StatusCode).To(Equal(200))
    })

    It("should handle pattern discovery requests", func() {
        // Test POST /discover endpoint
        request := PatternDiscoveryRequest{
            AnalysisType:  "workflow_patterns",
            TimeRange:     TimeRange{StartTime: time.Now().Add(-24*time.Hour), EndTime: time.Now()},
            PatternTypes:  []string{"alert_patterns", "resource_patterns"},
            MinConfidence: 0.7,
            MaxResults:    10,
        }
        // POST to /discover endpoint
        // Verify pattern discovery response
    })
}
```

#### **Test 2: Pattern Discovery Engine**
```go
func TestPatternDiscoveryEngine(t *testing.T) {
    It("should discover patterns from historical data", func() {
        engine := patterns.NewPatternDiscoveryEngine(
            patternStore, vectorDB, executionRepo, mlAnalyzer,
            timeSeriesEngine, llmClient, anomalyDetector, config, logger,
        )

        request := &patterns.PatternAnalysisRequest{
            AnalysisType:  "comprehensive",
            TimeRange:     patterns.TimeRange{StartTime: time.Now().Add(-7*24*time.Hour), EndTime: time.Now()},
            PatternTypes:  []string{"alert_patterns", "workflow_patterns", "resource_patterns"},
            MinConfidence: 0.6,
            MaxResults:    20,
        }

        result, err := engine.DiscoverPatterns(context.Background(), request)
        Expect(err).ToNot(HaveOccurred())
        Expect(result.Patterns).ToNot(BeEmpty())
        Expect(result.Confidence).To(BeNumerically(">", 0.6))
        Expect(len(result.Patterns)).To(BeNumerically("<=", 20))
    })

    It("should integrate with vector database for pattern storage", func() {
        // Test vector database integration
        // Verify pattern storage and retrieval
        // Check similarity search functionality
    })
}
```

#### **Test 3: Machine Learning Integration**
```go
func TestMachineLearningIntegration(t *testing.T) {
    It("should perform supervised learning analysis", func() {
        analyzer := ml.NewSupervisedLearningAnalyzer(executionRepo, mlAnalyzer, logger)

        trainingData := &ml.TrainingData{
            Features: [][]float64{{1.0, 2.0, 3.0}, {4.0, 5.0, 6.0}},
            Labels:   []string{"success", "failure"},
        }

        model, err := analyzer.TrainModel(context.Background(), trainingData)
        Expect(err).ToNot(HaveOccurred())
        Expect(model.Accuracy).To(BeNumerically(">", 0.7))
    })

    It("should detect performance anomalies", func() {
        detector := ml.NewPerformanceAnomalyDetector(mlAnalyzer, logger)

        metrics := map[string]float64{
            "cpu_usage":    95.0,
            "memory_usage": 85.0,
            "response_time": 2000.0,
        }

        result, err := detector.DetectAnomalies(context.Background(), metrics)
        Expect(err).ToNot(HaveOccurred())
        Expect(result.AnomaliesDetected).To(BeTrue())
    })
}
```

### **üü¢ GREEN PHASE (2-3 hours)**

#### **Implementation Priority**:
1. **Create HTTP service wrapper** (60 minutes) - Critical missing piece
2. **Implement HTTP endpoints** (45 minutes) - API for service integration
3. **Add data storage integration** (30 minutes) - Vector database client
4. **Create comprehensive tests** (60 minutes) - Test coverage
5. **Add deployment manifest** (15 minutes) - Kubernetes deployment

#### **HTTP Service Implementation**:
```go
// cmd/intelligence-service/main.go (NEW FILE)
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    "time"

    "github.com/sirupsen/logrus"
    "github.com/jordigilh/kubernaut/internal/config"
    "github.com/jordigilh/kubernaut/pkg/intelligence/patterns"
    "github.com/jordigilh/kubernaut/pkg/intelligence/ml"
    "github.com/jordigilh/kubernaut/pkg/intelligence/analytics"
    "github.com/jordigilh/kubernaut/pkg/storage/vector"
    "github.com/jordigilh/kubernaut/pkg/ai/llm"
)

func main() {
    // Initialize logger
    logger := logrus.New()
    logger.SetFormatter(&logrus.JSONFormatter{})

    // Load configuration
    cfg, err := loadIntelligenceConfiguration()
    if err != nil {
        logger.WithError(err).Fatal("Failed to load configuration")
    }

    // Create vector database client (dependency on storage service)
    vectorDBClient, err := createVectorDatabaseClient(cfg.VectorDB, logger)
    if err != nil {
        logger.WithError(err).Fatal("Failed to create vector database client")
    }

    // Create LLM client for enhanced analysis
    llmClient, err := llm.NewClient(cfg.LLM, logger)
    if err != nil {
        logger.WithError(err).Fatal("Failed to create LLM client")
    }

    // Create intelligence service components
    patternEngine := patterns.NewPatternDiscoveryEngine(
        cfg.PatternStore, vectorDBClient, cfg.ExecutionRepo,
        cfg.MLAnalyzer, cfg.TimeSeriesEngine, llmClient,
        cfg.AnomalyDetector, cfg.PatternConfig, logger,
    )

    mlAnalyzer := ml.NewSupervisedLearningAnalyzer(
        cfg.ExecutionRepo, cfg.MLAnalyzer, logger,
    )

    anomalyDetector := ml.NewPerformanceAnomalyDetector(
        cfg.MLAnalyzer, logger,
    )

    timeSeriesAnalyzer := analytics.NewTimeSeriesAnalyzer(
        cfg.MetricsCollector, logger,
    )

    // Create intelligence service
    intelligenceService := NewIntelligenceService(
        patternEngine, mlAnalyzer, anomalyDetector,
        timeSeriesAnalyzer, cfg, logger,
    )

    // Setup HTTP server
    server := setupHTTPServer(intelligenceService, cfg, logger)

    // Start server
    go func() {
        logger.WithField("port", cfg.ServicePort).Info("Starting intelligence HTTP server")
        if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            logger.WithError(err).Fatal("Failed to start HTTP server")
        }
    }()

    // Graceful shutdown
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
    sig := <-sigChan
    logger.WithField("signal", sig).Info("Received shutdown signal")

    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    if err := server.Shutdown(ctx); err != nil {
        logger.WithError(err).Error("Failed to shutdown server gracefully")
    } else {
        logger.Info("Server shutdown complete")
    }
}

func setupHTTPServer(intelligenceService *IntelligenceService, cfg *IntelligenceConfig, logger *logrus.Logger) *http.Server {
    mux := http.NewServeMux()

    // Core intelligence endpoints
    mux.HandleFunc("/discover", handlePatternDiscovery(intelligenceService, logger))
    mux.HandleFunc("/analyze", handleMLAnalysis(intelligenceService, logger))
    mux.HandleFunc("/anomalies", handleAnomalyDetection(intelligenceService, logger))
    mux.HandleFunc("/timeseries", handleTimeSeriesAnalysis(intelligenceService, logger))
    mux.HandleFunc("/workload-patterns", handleWorkloadPatterns(intelligenceService, logger))

    // Pattern management endpoints
    mux.HandleFunc("/patterns", handlePatterns(intelligenceService, logger))
    mux.HandleFunc("/patterns/", handlePatternOperations(intelligenceService, logger))

    // Model management endpoints
    mux.HandleFunc("/models", handleModels(intelligenceService, logger))
    mux.HandleFunc("/models/", handleModelOperations(intelligenceService, logger))

    // Monitoring endpoints
    mux.HandleFunc("/health", handleHealth(intelligenceService, logger))
    mux.HandleFunc("/metrics", handleMetrics(logger))

    return &http.Server{
        Addr:         fmt.Sprintf(":%d", cfg.ServicePort),
        Handler:      mux,
        ReadTimeout:  30 * time.Second,
        WriteTimeout: 120 * time.Second, // Longer timeout for ML operations
    }
}

func handlePatternDiscovery(intelligenceService *IntelligenceService, logger *logrus.Logger) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        if r.Method != http.MethodPost {
            http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
            return
        }

        var req PatternDiscoveryRequest
        if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
            http.Error(w, "Invalid request format", http.StatusBadRequest)
            return
        }

        // Perform pattern discovery
        result, err := intelligenceService.DiscoverPatterns(r.Context(), &req)
        if err != nil {
            logger.WithError(err).Error("Pattern discovery failed")
            http.Error(w, "Pattern discovery failed", http.StatusInternalServerError)
            return
        }

        response := PatternDiscoveryResponse{
            Result:    result,
            Timestamp: time.Now(),
            RequestID: req.RequestID,
        }

        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(response)
    }
}

type IntelligenceService struct {
    patternEngine       *patterns.PatternDiscoveryEngine
    mlAnalyzer          *ml.SupervisedLearningAnalyzer
    anomalyDetector     *ml.PerformanceAnomalyDetector
    timeSeriesAnalyzer  *analytics.TimeSeriesAnalyzer
    config              *IntelligenceConfig
    logger              *logrus.Logger
}

func NewIntelligenceService(
    patternEngine *patterns.PatternDiscoveryEngine,
    mlAnalyzer *ml.SupervisedLearningAnalyzer,
    anomalyDetector *ml.PerformanceAnomalyDetector,
    timeSeriesAnalyzer *analytics.TimeSeriesAnalyzer,
    config *IntelligenceConfig,
    logger *logrus.Logger,
) *IntelligenceService {
    return &IntelligenceService{
        patternEngine:       patternEngine,
        mlAnalyzer:          mlAnalyzer,
        anomalyDetector:     anomalyDetector,
        timeSeriesAnalyzer:  timeSeriesAnalyzer,
        config:              config,
        logger:              logger,
    }
}

func (is *IntelligenceService) DiscoverPatterns(ctx context.Context, req *PatternDiscoveryRequest) (*patterns.PatternAnalysisResult, error) {
    // Convert HTTP request to pattern analysis request
    analysisRequest := &patterns.PatternAnalysisRequest{
        AnalysisType:  req.AnalysisType,
        TimeRange:     req.TimeRange,
        PatternTypes:  req.PatternTypes,
        MinConfidence: req.MinConfidence,
        MaxResults:    req.MaxResults,
    }

    // Use pattern discovery engine
    result, err := is.patternEngine.DiscoverPatterns(ctx, analysisRequest)
    if err != nil {
        return nil, fmt.Errorf("pattern discovery failed: %w", err)
    }

    return result, nil
}

type IntelligenceConfig struct {
    ServicePort        int                           `yaml:"service_port" default:"8086"`
    VectorDB           VectorDBConfig                `yaml:"vector_db"`
    LLM                llm.Config                    `yaml:"llm"`
    PatternConfig      *patterns.PatternDiscoveryConfig `yaml:"pattern_config"`
    MLConfig           MLConfig                      `yaml:"ml_config"`

    // Service dependencies
    StorageServiceURL  string                        `yaml:"storage_service_url" default:"http://storage-service:8085"`
}

type PatternDiscoveryRequest struct {
    RequestID     string                    `json:"request_id"`
    AnalysisType  string                    `json:"analysis_type"`
    TimeRange     patterns.TimeRange        `json:"time_range"`
    PatternTypes  []string                  `json:"pattern_types"`
    MinConfidence float64                   `json:"min_confidence"`
    MaxResults    int                       `json:"max_results"`
}

type PatternDiscoveryResponse struct {
    Result    *patterns.PatternAnalysisResult `json:"result"`
    Timestamp time.Time                       `json:"timestamp"`
    RequestID string                          `json:"request_id"`
}
```

### **üîµ REFACTOR PHASE (30-45 minutes)**

#### **Code Organization**:
- Extract HTTP handlers to separate files
- Implement advanced pattern correlation
- Add comprehensive error handling
- Optimize performance for concurrent analysis

---

## üîó **INTEGRATION POINTS**

### **Upstream Services**
- **Alert Service** (alert-service:8081) - Provides alert patterns for analysis
- **Workflow Service** (workflow-service:8083) - Provides workflow execution data
- **K8s Executor Service** (executor-service:8084) - Provides action execution patterns

### **Downstream Services**
- **Data Storage Service** (storage-service:8085) - **CRITICAL DEPENDENCY** for pattern storage and retrieval

### **External Dependencies**
- **PostgreSQL with pgvector** - Pattern storage via storage service
- **LLM Services** - Enhanced pattern analysis
- **Prometheus** - Metrics collection for analysis

### **Configuration Dependencies**
```yaml
# config/intelligence-service.yaml
intelligence:
  service_port: 8086

  # CRITICAL: Data storage service dependency
  storage_service:
    url: "http://storage-service:8085"
    timeout: 30s
    retry_attempts: 3

  vector_db:
    enabled: true
    backend: "storage_service"  # Use storage service as backend

  llm:
    provider: "openai"
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4"
    timeout: 60s

  pattern_config:
    min_executions_for_pattern: 10
    max_history_days: 90
    sampling_interval: 1h
    similarity_threshold: 0.85
    clustering_epsilon: 0.3
    min_cluster_size: 5
    model_update_interval: 24h
    feature_window_size: 50
    prediction_confidence: 0.7
    max_concurrent_analysis: 10
    pattern_cache_size: 1000
    enable_real_time_detection: true

  ml_config:
    enable_supervised_learning: true
    enable_anomaly_detection: true
    enable_time_series_analysis: true
    model_training_interval: 12h
    anomaly_detection_threshold: 0.8
```

---

## üìÅ **FILE OWNERSHIP (EXCLUSIVE)**

### **Files You Can Modify**:
```bash
cmd/intelligence-service/              # Complete directory (NEW)
‚îú‚îÄ‚îÄ main.go                           # NEW: HTTP service implementation
‚îú‚îÄ‚îÄ main_test.go                      # NEW: HTTP server tests
‚îú‚îÄ‚îÄ handlers.go                       # NEW: HTTP request handlers
‚îú‚îÄ‚îÄ intelligence_service.go           # NEW: Intelligence service logic
‚îú‚îÄ‚îÄ config.go                         # NEW: Configuration management
‚îî‚îÄ‚îÄ *_test.go                         # All test files

pkg/intelligence/                     # Complete directory (EXTENSIVE EXISTING CODE)
‚îú‚îÄ‚îÄ patterns/                         # EXISTING: 544+ lines pattern discovery
‚îÇ   ‚îú‚îÄ‚îÄ pattern_discovery_engine.go   # EXISTING: Core pattern engine
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_pattern_engine.go    # EXISTING: Enhanced engine
‚îÇ   ‚îî‚îÄ‚îÄ *_test.go                     # NEW: Add comprehensive tests
‚îú‚îÄ‚îÄ ml/                               # EXISTING: 453 lines ML analyzers
‚îÇ   ‚îú‚îÄ‚îÄ ml.go                         # EXISTING: ML analysis system
‚îÇ   ‚îî‚îÄ‚îÄ *_test.go                     # NEW: Add ML tests
‚îú‚îÄ‚îÄ analytics/                        # EXISTING: Time series and workload analysis
‚îÇ   ‚îú‚îÄ‚îÄ time_series.go                # EXISTING: Time series analysis
‚îÇ   ‚îú‚îÄ‚îÄ workload_patterns.go          # EXISTING: Workload pattern detection
‚îÇ   ‚îî‚îÄ‚îÄ *_test.go                     # NEW: Add analytics tests
‚îú‚îÄ‚îÄ anomaly/                          # EXISTING: 243+ lines anomaly detection
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.go           # EXISTING: Anomaly detection engine
‚îÇ   ‚îî‚îÄ‚îÄ *_test.go                     # NEW: Add anomaly tests
‚îî‚îÄ‚îÄ service_integration.go            # NEW: Storage service integration

test/unit/intelligence/               # Complete test directory
‚îú‚îÄ‚îÄ intelligence_service_test.go      # NEW: Service logic tests
‚îú‚îÄ‚îÄ pattern_discovery_test.go         # NEW: Pattern discovery tests
‚îú‚îÄ‚îÄ ml_analysis_test.go               # NEW: ML analysis tests
‚îú‚îÄ‚îÄ anomaly_detection_test.go         # NEW: Anomaly detection tests
‚îî‚îÄ‚îÄ storage_integration_test.go       # NEW: Storage service integration tests

deploy/microservices/intelligence-deployment.yaml  # Deployment manifest
```

### **Files You CANNOT Modify**:
```bash
pkg/shared/types/                     # Shared type definitions
internal/config/                      # Configuration patterns
pkg/storage/vector/                   # Storage interfaces (reuse only)
pkg/ai/llm/                          # LLM interfaces (reuse only)
deploy/kustomization.yaml             # Main deployment config
```

---

## ‚ö° **QUICK START COMMANDS**

### **Development Setup**:
```bash
# PREREQUISITE: Data Storage Service must be running on port 8085
curl http://localhost:8085/health  # Verify storage service is available

# Build service (after creating main.go)
go build -o intelligence-service cmd/intelligence-service/main.go

# Run service
export OPENAI_API_KEY="your-key-here"
./intelligence-service

# Test service
curl http://localhost:8086/health
curl http://localhost:8086/metrics

# Test pattern discovery
curl -X POST http://localhost:8086/discover \
  -H "Content-Type: application/json" \
  -d '{"request_id":"test-001","analysis_type":"comprehensive","time_range":{"start_time":"2024-01-01T00:00:00Z","end_time":"2024-01-02T00:00:00Z","interval":"1h"},"pattern_types":["alert_patterns","workflow_patterns"],"min_confidence":0.7,"max_results":10}'

# Test ML analysis
curl -X POST http://localhost:8086/analyze \
  -H "Content-Type: application/json" \
  -d '{"analysis_type":"supervised_learning","training_data":{"features":[[1.0,2.0,3.0],[4.0,5.0,6.0]],"labels":["success","failure"]}}'
```

### **Testing Commands**:
```bash
# Run tests (after creating test files)
go test cmd/intelligence-service/... -v
go test pkg/intelligence/... -v
go test test/unit/intelligence/... -v

# Integration tests with storage service
INTELLIGENCE_INTEGRATION_TEST=true go test test/integration/intelligence/... -v
```

---

## üéØ **SUCCESS CRITERIA**

### **Technical Success**:
- [ ] Service builds: `go build cmd/intelligence-service/main.go` succeeds (NEED TO CREATE)
- [ ] Service starts on port 8086: `curl http://localhost:8086/health` returns 200 (NEED TO CREATE)
- [ ] Pattern discovery works: POST to `/discover` endpoint returns patterns (NEED TO IMPLEMENT)
- [ ] Storage integration: Can store and retrieve patterns from storage service ‚úÖ (LOGIC ALREADY IMPLEMENTED)
- [ ] ML analysis works: Machine learning analyzers function correctly ‚úÖ (ALREADY IMPLEMENTED)
- [ ] All tests pass: `go test cmd/intelligence-service/... -v` all green (NEED TO CREATE)

### **Business Success**:
- [ ] BR-INT-001 to BR-INT-150 implemented (CAN BE MAPPED TO EXISTING CODE)
- [ ] Pattern discovery working ‚úÖ (COMPREHENSIVE LOGIC ALREADY IMPLEMENTED)
- [ ] Machine learning analysis working ‚úÖ (ALREADY IMPLEMENTED)
- [ ] Anomaly detection working ‚úÖ (ALREADY IMPLEMENTED)
- [ ] Time series analysis working ‚úÖ (ALREADY IMPLEMENTED)
- [ ] Workload pattern detection working ‚úÖ (ALREADY IMPLEMENTED)

### **Architecture Success**:
- [ ] Uses exact service name: `intelligence-service` (NEED TO IMPLEMENT)
- [ ] Uses exact port: `8086` ‚úÖ (WILL BE CONFIGURED CORRECTLY)
- [ ] Uses exact image format: `quay.io/jordigilh/intelligence-service` (WILL FOLLOW PATTERN)
- [ ] Implements only pattern discovery responsibility ‚úÖ (ALREADY CORRECT)
- [ ] Integrates with approved microservices architecture (NEED HTTP SERVICE)

### **Dependency Success**:
- [ ] **CRITICAL**: Data Storage Service (8085) integration working
- [ ] Vector database access through storage service
- [ ] Pattern storage and retrieval functionality
- [ ] Historical data access for analysis

---

## üìä **CONFIDENCE ASSESSMENT**

```
Intelligence Service Development Confidence: 88%

Strengths:
‚úÖ EXCEPTIONAL existing foundation (1500+ lines of sophisticated intelligence code)
‚úÖ Complete pattern discovery engine with ML integration
‚úÖ Advanced machine learning analyzers for supervised learning and anomaly detection
‚úÖ Comprehensive time series analysis and workload pattern detection
‚úÖ Vector database integration already implemented
‚úÖ LLM client integration for enhanced analysis
‚úÖ Statistical validation and overfitting prevention
‚úÖ Error handling and logging throughout implementation

Critical Dependency:
‚ö†Ô∏è  REQUIRES Data Storage Service (8085) to be complete and running
‚ö†Ô∏è  Missing HTTP service wrapper (need to create cmd/intelligence-service/main.go)

Mitigation:
‚úÖ All intelligence logic already implemented and sophisticated
‚úÖ Clear patterns from other services for HTTP wrapper
‚úÖ Storage service integration patterns already established
‚úÖ Comprehensive business logic ready for immediate use

Implementation Time: 3-4 hours (HTTP service wrapper + storage integration + tests)
Integration Readiness: HIGH (comprehensive intelligence foundation)
Business Value: EXCEPTIONAL (critical pattern discovery and ML analysis)
Risk Level: MEDIUM (dependency on storage service completion)
Technical Complexity: HIGH (sophisticated ML and pattern analysis)
```

---

**Status**: ‚úÖ **READY FOR PHASE 2 DEVELOPMENT**
**Dependencies**: **CRITICAL** - Data Storage Service (8085) must be complete first
**Integration Point**: HTTP API for pattern discovery and machine learning analysis
**Primary Tasks**:
1. **Wait for Data Storage Service completion** (Phase 1 dependency)
2. Create HTTP service wrapper (1-2 hours)
3. Implement storage service integration (1 hour)
4. Add comprehensive test coverage (1 hour)
5. Create deployment manifest (15 minutes)

**Phase 2 Execution Order**: **FIRST** (after storage service dependency satisfied)
