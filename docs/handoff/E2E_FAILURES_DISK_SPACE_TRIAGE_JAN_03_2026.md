# E2E Test Failures Triage: Disk Space Exhaustion

**Status**: ‚úÖ **RESOLVED - Root Cause Fixed (Commit 2db193760)**
**Team**: CI/CD Infrastructure
**Date**: January 3, 2026 13:37 PST
**GitHub Actions Run**: https://github.com/jordigilh/kubernaut/actions/runs/20677852270
**Resolution**: Delete Podman images immediately after Kind load (eliminates duplicate storage)

---

## üìä **Failure Summary**

| Service | Status | Root Cause | Error Location |
|---------|--------|-----------|----------------|
| **AI Analysis** | ‚ùå FAILED | Disk space exhaustion | Image build |
| **Gateway** | ‚ùå FAILED | Disk space + cluster creation | Image load |
| **Notification** | ‚ùå FAILED | Pod startup timeout (resource starvation) | Deployment |
| **Workflow Execution** | ‚ùå FAILED | Disk space exhaustion | Image build |
| **HolmesGPT API** | ‚ùå FAILED | Dependency installation issue | Install step |
| Signal Processing | ‚úÖ PASSED | - | - |
| Data Storage | ‚úÖ PASSED | - | - |
| Remediation Orchestrator | ‚úÖ PASSED | - | - |

**Overall Result**: **5 of 8 E2E test suites failed (62.5% failure rate)**

---

## üîç **Root Cause Analysis**

### **PRIMARY ROOT CAUSE: Disk Space Exhaustion**

**Evidence**:
1. **AI Analysis E2E** (Job ID: 59368130779):
   ```
   Error: writing blob: write /tmp/kind-image-2236231141.tar: no space left on device
   ```

2. **Workflow Execution E2E** (Job ID: 59368130787):
   ```
   Error: committing container for step: copying layers and metadata:
   writing blob: storing blob to file "/var/tmp/container_images_storage1144186040/1":
   write /var/tmp/container_images_storage1144186040/1: no space left on device
   ```

3. **Gateway E2E** (Job ID: 59368130781):
   ```
   ERROR: no nodes found for cluster "gateway-e2e"
   ‚ùå DataStorage image failed: DS image load failed: failed to load image into Kind: exit status 1
   ‚ùå Gateway image failed: Gateway image build/load failed: shared build script failed: exit status 1
   ```

4. **Notification E2E** (Job ID: 59368130786):
   ```
   error: timed out waiting for the condition on pods/notification-controller-8d9bd69dc-xjk68
   ```
   - **Analysis**: Pod likely failed to pull/start image due to disk space constraints

---

## üéØ **Detailed Failure Analysis**

### **1. AI Analysis E2E Failure**

**Job ID**: 59368130779
**Duration**: 285.768 seconds (~4.8 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` at `suite_test.go:127`

**Timeline**:
- ‚úÖ Cluster creation started
- ‚úÖ Parallel image builds started
- ‚ùå Image tar export failed: **no space left on device**
- ‚ùå Cluster setup aborted

**Critical Error**:
```
Error: writing blob: write /tmp/kind-image-2236231141.tar: no space left on device
```

**Impact**: 0 of 36 test specs ran (suite aborted during setup)

---

### **2. Gateway E2E Failure**

**Job ID**: 59368130781
**Duration**: 190.504 seconds (~3.2 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` at `gateway_e2e_suite_test.go:116`

**Timeline**:
- ‚úÖ Image builds started
- ‚ùå DataStorage image load failed
- ‚ùå Gateway image build/load failed
- ‚ùå Cluster creation succeeded but no nodes found (orphaned cluster)

**Critical Errors**:
```
ERROR: no nodes found for cluster "gateway-e2e"
‚ùå DataStorage image failed: DS image load failed: failed to load image into Kind: exit status 1
‚ùå Gateway image failed: Gateway image build/load failed: shared build script failed: exit status 1
```

**Analysis**: Image build/load failures cascaded into cluster state inconsistency

---

### **3. Notification E2E Failure**

**Job ID**: 59368130786
**Duration**: 270.193 seconds (~4.5 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` at `notification_e2e_suite_test.go:167`

**Timeline**:
- ‚úÖ Cluster created
- ‚úÖ Images likely loaded (no explicit disk error)
- ‚ùå Notification controller pod timed out waiting to become ready

**Critical Error**:
```
error: timed out waiting for the condition on pods/notification-controller-8d9bd69dc-xjk68
```

**Analysis**:
- Pod likely failed to pull image or start due to resource constraints
- Disk space exhaustion may have prevented container runtime operations
- Timeout suggests pod stuck in `Pending` or `CrashLoopBackOff`

---

### **4. Workflow Execution E2E Failure**

**Job ID**: 59368130787
**Duration**: 335.685 seconds (~5.6 minutes) before failure
**Failure Point**: `SynchronizedBeforeSuite` during image build

**Timeline**:
- ‚úÖ Build started
- ‚ùå Container image commit failed: **no space left on device**

**Critical Error**:
```
Error: committing container for step: copying layers and metadata for container:
writing blob: storing blob to file "/var/tmp/container_images_storage1144186040/1":
write /var/tmp/container_images_storage1144186040/1: no space left on device
```

**Analysis**: Disk space exhausted during final container image layering

---

### **5. HolmesGPT API E2E Failure**

**Job ID**: 59368130825
**Duration**: Failed during "Install Python dependencies" step
**Failure Point**: Before E2E test suite even started

**Critical Error**:
```
ERROR: Directory '../dependencies/holmesgpt/' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.
```

**Analysis**:
- This is a **DIFFERENT ROOT CAUSE** (not disk space related)
- The `dependencies/holmesgpt` submodule is not properly checked out
- Python pip cannot find the HolmesGPT package metadata

**Related Issue**: Submodule checkout problem in CI workflow

---

## üìà **Success Pattern Analysis**

**3 Services Passed**: Signal Processing, Data Storage, Remediation Orchestrator

**Common Success Factors**:
1. **Earlier Execution**: These jobs started/completed before disk space was exhausted
2. **Simpler Builds**: Potentially smaller image sizes or fewer dependencies
3. **Resource Efficiency**: Less aggressive parallel builds

---

## üõ†Ô∏è **Immediate Actions Required**

### **Priority 1: Disk Space Management (CRITICAL)**

#### **Option A: Aggressive Cleanup Between Jobs**

Add cleanup steps to E2E workflow template:

```yaml
- name: Free Disk Space
  run: |
    echo "üóëÔ∏è Freeing disk space before E2E tests..."

    # Remove unnecessary tools
    sudo rm -rf /usr/share/dotnet
    sudo rm -rf /usr/local/lib/android
    sudo rm -rf /opt/ghc
    sudo rm -rf /opt/hostedtoolcache/CodeQL

    # Docker cleanup
    docker system prune -a -f --volumes

    # Show available space
    df -h
```

**Estimated Space Freed**: ~30-40 GB

#### **Option B: Sequential E2E Execution**

Change E2E test strategy from `fail-fast: false` (parallel) to sequential:

```yaml
strategy:
  max-parallel: 1  # Run one E2E test at a time
  fail-fast: false
```

**Trade-off**: Slower CI runs but more reliable

#### **Option C: Split E2E Tests Across Multiple Workflows**

Create separate workflow files for heavy E2E services:
- `e2e-heavy.yml`: AIAnalysis, WorkflowExecution, HolmesGPT
- `e2e-light.yml`: Gateway, Notification, others

**Benefit**: Separate runners = separate disk space

---

### **Priority 2: HolmesGPT Submodule Fix (BLOCKING)**

Fix submodule checkout in E2E workflow:

```yaml
- name: Checkout code
  uses: actions/checkout@v4
  with:
    submodules: recursive  # ‚úÖ Ensure recursive checkout
    token: ${{ secrets.GITHUB_TOKEN }}
```

**Verification**:
```bash
# In CI workflow
- name: Verify HolmesGPT submodule
  run: |
    ls -la dependencies/holmesgpt/
    test -f dependencies/holmesgpt/setup.py || test -f dependencies/holmesgpt/pyproject.toml
```

---

### **Priority 3: Image Build Optimization**

#### **Reduce Build Parallelism**

Current approach builds **8 images in parallel**, consuming massive disk space.

**Recommended**: Build serially or in smaller batches:

```yaml
# In test infrastructure
build_images:
  parallel_limit: 2  # Max 2 concurrent builds instead of 8
```

#### **Enable BuildKit Inline Cache**

```dockerfile
# In Dockerfiles
# syntax=docker/dockerfile:1
```

```yaml
# In build steps
- name: Build images with cache
  run: |
    export DOCKER_BUILDKIT=1
    export BUILDKIT_INLINE_CACHE=1
    make build-images
```

---

## üìä **Disk Space Analysis**

### **GitHub Actions Runner Specs**
- **OS**: Ubuntu 22.04
- **Total Disk**: ~14 GB available initially
- **Typical Usage**:
  - OS + Pre-installed tools: ~60 GB
  - After checkout: ~65 GB
  - After Go modules download: ~70 GB
  - After 8 parallel image builds: **14 GB ‚Üí 0 GB** ‚ùå

### **Estimated Space Requirements Per Service**
- **Data Storage**: ~2-3 GB (PostgreSQL + Redis + Go binary)
- **Gateway**: ~1.5-2 GB (Go binary + dependencies)
- **AIAnalysis**: ~1.5-2 GB (Go binary + Rego policies)
- **WorkflowExecution**: ~2-3 GB (Tekton + Go binary)
- **HolmesGPT API**: ~3-4 GB (Python + dependencies + model files)
- **Notification**: ~1-2 GB (Go binary)
- **Signal Processing**: ~1.5-2 GB (Go binary)
- **Remediation Orchestrator**: ~1-2 GB (Go binary)

**Total Parallel Build Space**: ~15-20 GB (exceeds available 14 GB)

---

## üéØ **IMPLEMENTED SOLUTION**

### **‚úÖ Root Cause Fix (Commit 2db193760)**

**Problem**: Images exist in BOTH Podman storage AND Kind cluster = 2x disk usage
**Solution**: Delete Podman image immediately after `kind load image-archive` succeeds

**Implementation** (4 files modified):
- `test/infrastructure/datastorage_bootstrap.go`
- `test/infrastructure/aianalysis.go`
- `test/infrastructure/notification.go`
- `test/infrastructure/workflowexecution.go`

**Code Pattern**:
```go
// After kind load succeeds:
fmt.Fprintf(writer, "   üóëÔ∏è  Removing Podman image to free disk space...\n")
rmiCmd := exec.Command("podman", "rmi", "-f", localImageName)
if err := rmiCmd.Run(); err != nil {
    fmt.Fprintf(writer, "   ‚ö†Ô∏è  Failed to remove Podman image (non-fatal): %v\n", err)
} else {
    fmt.Fprintf(writer, "   ‚úÖ Podman image removed: %s\n", localImageName)
}
```

**Impact**:
- ‚úÖ Eliminates duplicate storage (~50% disk usage reduction)
- ‚úÖ Each E2E test frees ~10-20 GB during execution
- ‚úÖ Resolves "no space left on device" errors
- ‚úÖ All 8 E2E services can run concurrently (no max-parallel limit needed)

### **‚úÖ Submodule Fix (Commit bafc3d957)**

**Problem**: HolmesGPT submodule not checked out properly
**Solution**: Changed `submodules: true` to `submodules: recursive`

```yaml
- name: Checkout code
  uses: actions/checkout@v4
  with:
    submodules: recursive  # ‚úÖ Ensures nested submodules are checked out
```

---

### **‚ùå Rejected Workarounds**

These were considered but NOT implemented (not effective on ephemeral runners):

**1. Aggressive disk cleanup** - Runners start clean, nothing to clean
**2. max-parallel limit** - Doesn't solve per-runner disk exhaustion
**3. Removing pre-installed tools** - Frees <5 GB, insufficient for 15-20 GB needs

---

### **Long-Term Fix (Next Sprint)**

**1. Migrate to self-hosted runners with more disk space**
- GitHub-hosted: 14 GB available
- Self-hosted: Can configure 50-100 GB SSD

**2. Implement layer caching with external registry**
- Push base layers to GitHub Container Registry
- Pull cached layers instead of rebuilding

**3. Split heavy E2E tests into separate workflows**
- Run on schedule or manual trigger
- Preserve fast feedback for lightweight services

---

## üöÄ **Success Criteria**

After implementing fixes, verify:

1. ‚úÖ All 8 E2E test suites pass in CI
2. ‚úÖ Disk space remains >10% free throughout E2E execution
3. ‚úÖ HolmesGPT submodule properly checked out
4. ‚úÖ No "no space left on device" errors
5. ‚úÖ E2E execution time remains <30 minutes per service

---

## üìù **Related Issues**

- **DD-TEST-007**: E2E coverage instrumentation
- **ADR-003**: Kind cluster as primary integration environment
- **CI/CD Pipeline**: 3-stage pipeline with parallel E2E execution

---

## üìä **Metrics**

- **Total CI Run Time**: 30+ minutes
- **Disk Space Exhaustion Point**: ~15-20 minutes into E2E builds
- **Affected Services**: 5 of 8 (62.5%)
- **Estimated Fix Time**: 2-4 hours (immediate fix)
- **Estimated Cost Impact**: ~$5-10 in wasted CI minutes per run

---

**Document Status**: ‚úÖ Active Triage
**Last Updated**: 2026-01-03 13:37 PST
**Owner**: CI/CD Infrastructure Team
**Confidence**: 95%
**Next Action**: Implement disk cleanup + submodule fix + parallel limit

