# coding: utf-8

"""
    Data Storage Service API

    Data Storage Service provides REST API access to audit trail persistence.  **Business Requirements**: - BR-STORAGE-001 to BR-STORAGE-020: Audit write API - BR-STORAGE-021: Incident query API (READ) - BR-STORAGE-024: RFC 7807 error responses - BR-AUDIT-006: Legal hold capability (SOC2 Gap #8)  **Design Decisions**: - ADR-031: OpenAPI 3.0+ specification for all stateless REST APIs - ADR-032: Data Access Layer Isolation (only Data Storage connects to PostgreSQL) - DD-009: Dead Letter Queue fallback on database errors - DD-AUTH-004: OAuth-proxy sidecar for authentication/authorization - DD-AUTH-005: Client authentication pattern (ServiceAccount tokens)  **Architecture**: This service is the **ONLY** service that directly accesses PostgreSQL. All other services (Context API, Effectiveness Monitor, etc.) access data through this REST API Gateway.  **Authentication & Authorization (Production/E2E)**: All requests to DataStorage are protected by an OAuth-proxy sidecar:  1. **Client Authentication**: Services authenticate with Kubernetes ServiceAccount tokens    - Token mounted at: `/var/run/secrets/kubernetes.io/serviceaccount/token`    - Clients inject: `Authorization: Bearer <token>` header    - See DD-AUTH-005 for client implementation patterns  2. **OAuth-Proxy Validation**: The sidecar validates requests    - Validates JWT token signature and expiration    - Performs Subject Access Review (SAR) to check RBAC permissions    - Injects `X-Auth-Request-User` header with authenticated user identity    - Returns HTTP 401 if token invalid, HTTP 403 if SAR fails  3. **Handler Enforcement**: DataStorage handlers extract user identity    - Legal hold operations REQUIRE `X-Auth-Request-User` header    - HTTP 401 returned if header missing (authentication failed)    - User identity stored in audit events for SOC2 compliance  **Routing Flow**: ``` Client → data-storage-service:8080 (Service)        ↓      oauth-proxy:8080 (validates token + SAR)        ↓      DataStorage:8081 (X-Auth-Request-User header) ```  **Integration Tests**: Integration tests run without oauth-proxy. Use `testutil.NewMockUserTransport()` to inject mock `X-Auth-Request-User` headers directly.  **SOC2 Compliance**: - All legal hold operations attributed to authenticated users - Audit trail captures placed_by/released_by from X-Auth-Request-User - Unauthorized access blocked at oauth-proxy layer (defense-in-depth) 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import Any, ClassVar, Dict, List, Optional, Union
from pydantic import BaseModel, StrictBool, StrictStr, field_validator
from pydantic import Field
from typing_extensions import Annotated
from datastorage.models.incident_response_data_alternative_workflows_inner import IncidentResponseDataAlternativeWorkflowsInner
from datastorage.models.incident_response_data_root_cause_analysis import IncidentResponseDataRootCauseAnalysis
from datastorage.models.incident_response_data_selected_workflow import IncidentResponseDataSelectedWorkflow
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class IncidentResponseData(BaseModel):
    """
    Complete IncidentResponse structure from HolmesGPT API (DD-AUDIT-004 - strongly typed, no additionalProperties)
    """ # noqa: E501
    incident_id: StrictStr = Field(description="Incident identifier from request")
    analysis: StrictStr = Field(description="Natural language analysis from LLM")
    root_cause_analysis: IncidentResponseDataRootCauseAnalysis
    selected_workflow: Optional[IncidentResponseDataSelectedWorkflow] = None
    confidence: Union[Annotated[float, Field(le=1.0, strict=True, ge=0.0)], Annotated[int, Field(le=1, strict=True, ge=0)]] = Field(description="Overall confidence in analysis")
    timestamp: datetime = Field(description="ISO timestamp of analysis completion")
    needs_human_review: Optional[StrictBool] = Field(default=False, description="True when AI could not produce reliable result")
    human_review_reason: Optional[StrictStr] = Field(default=None, description="Structured reason when needs_human_review=true")
    target_in_owner_chain: Optional[StrictBool] = Field(default=True, description="Whether RCA target was found in OwnerChain")
    warnings: Optional[List[StrictStr]] = Field(default=None, description="Non-fatal warnings (e.g., OwnerChain validation issues)")
    alternative_workflows: Optional[List[IncidentResponseDataAlternativeWorkflowsInner]] = Field(default=None, description="Other workflows considered but not selected")
    __properties: ClassVar[List[str]] = ["incident_id", "analysis", "root_cause_analysis", "selected_workflow", "confidence", "timestamp", "needs_human_review", "human_review_reason", "target_in_owner_chain", "warnings", "alternative_workflows"]

    @field_validator('human_review_reason')
    def human_review_reason_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in ('workflow_not_found', 'image_mismatch', 'parameter_validation_failed', 'no_matching_workflows', 'low_confidence', 'llm_parsing_error'):
            raise ValueError("must be one of enum values ('workflow_not_found', 'image_mismatch', 'parameter_validation_failed', 'no_matching_workflows', 'low_confidence', 'llm_parsing_error')")
        return value

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of IncidentResponseData from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of root_cause_analysis
        if self.root_cause_analysis:
            _dict['root_cause_analysis'] = self.root_cause_analysis.to_dict()
        # override the default output from pydantic by calling `to_dict()` of selected_workflow
        if self.selected_workflow:
            _dict['selected_workflow'] = self.selected_workflow.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in alternative_workflows (list)
        _items = []
        if self.alternative_workflows:
            for _item in self.alternative_workflows:
                if _item:
                    _items.append(_item.to_dict())
            _dict['alternative_workflows'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of IncidentResponseData from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "incident_id": obj.get("incident_id"),
            "analysis": obj.get("analysis"),
            "root_cause_analysis": IncidentResponseDataRootCauseAnalysis.from_dict(obj.get("root_cause_analysis")) if obj.get("root_cause_analysis") is not None else None,
            "selected_workflow": IncidentResponseDataSelectedWorkflow.from_dict(obj.get("selected_workflow")) if obj.get("selected_workflow") is not None else None,
            "confidence": obj.get("confidence"),
            "timestamp": obj.get("timestamp"),
            "needs_human_review": obj.get("needs_human_review") if obj.get("needs_human_review") is not None else False,
            "human_review_reason": obj.get("human_review_reason"),
            "target_in_owner_chain": obj.get("target_in_owner_chain") if obj.get("target_in_owner_chain") is not None else True,
            "warnings": obj.get("warnings"),
            "alternative_workflows": [IncidentResponseDataAlternativeWorkflowsInner.from_dict(_item) for _item in obj.get("alternative_workflows")] if obj.get("alternative_workflows") is not None else None
        })
        return _obj


