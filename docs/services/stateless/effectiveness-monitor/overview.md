# Effectiveness Monitor Service - Overview

**Version**: v1.1
**Last Updated**: October 16, 2025
**Status**: âœ… Design Complete (100%)
**Port**: 8080 (REST + Health), 9090 (Metrics)
**Prompt Format**: Self-Documenting JSON (DD-HOLMESGPT-009)

**IMPORTANT UPDATE (October 16, 2025)**: Selective AI analysis calls to HolmesGPT now use **Self-Documenting JSON format**:
- âœ… **75% token reduction** for 18K AI calls/year
- âœ… **$1,100/year cost savings** ($73/month)
- âœ… **150ms latency improvement** per post-execution analysis
- âœ… **98% parsing accuracy maintained**

**Decision Document**: `docs/architecture/decisions/DD-HOLMESGPT-009-Ultra-Compact-JSON-Format.md`

---

## Table of Contents

1. [Purpose & Scope](#purpose--scope)
2. [Architecture Overview](#architecture-overview)
3. [Assessment Processing Pipeline](#assessment-processing-pipeline)
4. [Key Architectural Decisions](#key-architectural-decisions)
5. [V1 Graceful Degradation Strategy](#v1-graceful-degradation-strategy)
6. [System Context Diagram](#system-context-diagram)
7. [Data Flow Diagram](#data-flow-diagram)
8. [Business Requirements Mapping](#business-requirements-mapping)

**ğŸ“Š Visual Documentation**:
- [Effectiveness Monitor Sequence Diagrams](../../../architecture/effectiveness-monitor-sequence-diagrams.md) - Detailed flow diagrams with real examples

---

## Purpose & Scope

### Core Purpose

Effectiveness Monitor Service is the **intelligent assessment engine** that evaluates the effectiveness of remediation actions using **multi-dimensional analysis**. It serves as the **outcome validator** that:

1. **Assesses** traditional effectiveness (success/failure rate)
2. **Correlates** environmental impact (memory, CPU, network metrics)
3. **Detects** adverse side effects from actions
4. **Analyzes** long-term trends (improving/declining/stable)
5. **Recognizes** patterns in effectiveness (temporal, environmental)
6. **Provides** confidence levels based on data quality

### Why Effectiveness Monitor Exists

**Problem**: Without Effectiveness Monitor, Kubernaut would:
- âŒ Repeat ineffective remediation actions indefinitely
- âŒ Miss adverse side effects (e.g., CPU spike after memory fix)
- âŒ Fail to detect declining action effectiveness over time
- âŒ Lack confidence metrics for AI-driven recommendations
- âŒ Have no historical basis for improvement suggestions

**Solution**: Effectiveness Monitor provides **intelligent outcome analysis** that:
- âœ… Identifies ineffective actions before they waste resources
- âœ… Detects side effects within 10 minutes of action execution
- âœ… Tracks long-term trends (90-day rolling window)
- âœ… Provides confidence-adjusted recommendations (60-95% confidence)
- âœ… Enables continuous learning and improvement

---

## Architecture Overview

### Service Characteristics

- **Type**: Stateless HTTP API server (Assessment & Analysis)
- **Deployment**: Kubernetes Deployment with horizontal scaling (2-3 replicas)
- **Data Dependencies**: Data Storage (critical), Infrastructure Monitoring (graceful degradation)
- **Integration Pattern**: On-demand assessment â†’ Multi-dimensional evaluation â†’ Result persistence

### V1 Timeline Strategy

| Week | Data Available | Capability | Confidence |
|------|---------------|------------|------------|
| **Week 5** | 0 weeks | `insufficient_data` response only | 20-30% |
| **Week 8** | 3 weeks | Basic effectiveness scoring | 40-50% |
| **Week 10** | 5 weeks | Side effect detection + trend analysis | 60-70% |
| **Week 13+** | 8+ weeks | Full multi-dimensional assessment | 80-95% |

**Week 5 Deployment**: Service is functional but returns `insufficient_data` status with estimated availability date.

**Week 13+ Goal**: Full capability with high-confidence assessments powered by 8+ weeks of historical data.

### Component Architecture (Hybrid Approach)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Effectiveness Monitor Service (Hybrid)                â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚       Kubernetes Controller (RemediationRequest Watcher)     â”‚ â”‚
â”‚  â”‚  - Watches: RemediationRequest CRDs                          â”‚ â”‚
â”‚  â”‚  - Trigger: overallPhase IN ("completed", "failed", "timeout") â”‚
â”‚  â”‚  - Idempotency: Database check (RemediationRequest.UID)      â”‚ â”‚
â”‚  â”‚  - Delay: 5-minute stabilization period                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚                                                â”‚
â”‚                   â–¼ (after 5-minute delay)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚          Data Availability Check (8+ weeks?)                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Action History Retrieval (Data Storage Client)           â”‚ â”‚
â”‚  â”‚     - 90-day rolling window                                  â”‚ â”‚
â”‚  â”‚     - Action type filtering                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Metrics Correlation (Infrastructure Monitoring Client)      â”‚ â”‚
â”‚  â”‚  - Memory/CPU impact (5-minute post-action window)           â”‚ â”‚
â”‚  â”‚  - Network stability assessment                              â”‚ â”‚
â”‚  â”‚  - Graceful degradation if unavailable                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         Automated Effectiveness Calculator                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ 1. Traditional Score (success rate)                    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 2. Side Effect Detection (CPU/memory/network)          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 3. Trend Analysis (improving/declining/stable)         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 4. Pattern Recognition (temporal, environmental)       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 5. Anomaly Detection (unexpected behaviors)            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 6. Confidence Calculation (data quality)               â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            AI DECISION LOGIC: shouldCallAI()?                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Trigger 1: P0 failures (~50/day) â†’ YES                 â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Trigger 2: New action types (~10/day) â†’ YES            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Trigger 3: Anomalies detected (~5/day) â†’ YES           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Trigger 4: Oscillations (~5/day) â†’ YES                 â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Default: Routine successes (~10K/day) â†’ NO             â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚ YES (~18K/year)                  â”‚ NO (~3.65M/year)   â”‚
â”‚         â–¼                                   â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ HolmesGPT API    â”‚             â”‚ Store Automated Results   â”‚ â”‚
â”‚  â”‚ (Post-Exec       â”‚             â”‚ (PostgreSQL)              â”‚ â”‚
â”‚  â”‚  Analysis)       â”‚             â”‚ - Basic metrics           â”‚ â”‚
â”‚  â”‚ - Root cause     â”‚             â”‚ - No AI insights          â”‚ â”‚
â”‚  â”‚ - Oscillation    â”‚             â”‚ - Cost: $0                â”‚ â”‚
â”‚  â”‚ - Lessons        â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚         â”‚                                                        â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Combine Automated + AI Results                          â”‚   â”‚
â”‚  â”‚  Store in PostgreSQL + Context API                       â”‚   â”‚
â”‚  â”‚  Cost: ~$0.0387/analysis Ã— 18K = $706/year              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Architectural Features**:
- **Trigger**: Kubernetes Watch API (not HTTP API call)
- **Idempotency**: Database-backed using WorkflowExecution.UID
- **Stabilization**: 5-minute delay for metric stability
- **Hybrid**: 100% automated, 0.49% AI-enhanced
- **Cost Control**: Selective AI analysis saves $14K/year vs always-AI

---

## Assessment Processing Pipeline

### Step-by-Step Flow

#### 1. **Assessment Request** (API Entry Point)

**From Context API Service**:
```http
GET /api/v1/assess/effectiveness/act-abc123
Authorization: Bearer <k8s-serviceaccount-token>
```

**Request Body** (optional parameters):
```json
{
  "action_id": "act-abc123",
  "wait_for_stabilization": true,
  "assessment_interval": "10m"
}
```

#### 2. **Data Availability Check** (10-20ms)

**Query Data Storage** for oldest remediation action:
```go
func (s *EffectivenessMonitorService) checkDataAvailability(ctx context.Context) (int, bool) {
    oldestAction, err := s.dataStorageClient.GetOldestAction(ctx)
    if err != nil {
        return 0, false
    }

    dataWeeks := int(time.Since(oldestAction.CreatedAt).Hours() / (24 * 7))
    sufficient := dataWeeks >= 8 // 8 weeks minimum

    return dataWeeks, sufficient
}
```

**Week 5 Response** (insufficient data):
```json
{
  "assessment_id": "assess-xyz789",
  "status": "insufficient_data",
  "confidence": 0.25,
  "estimated_availability": "2025-11-19T00:00:00Z",
  "message": "Effectiveness assessment requires 8+ weeks of historical data. Current: 0 weeks."
}
```

**Week 13+ Response** (sufficient data) â†’ Continue to next step.

#### 3. **Action History Retrieval** (50-100ms)

**Query Data Storage** for action history (90-day window):
```go
history, err := s.dataStorageClient.GetActionHistory(ctx, "restart-pod", 90*24*time.Hour)

// Returns:
// [
//   {ActionID: "act-001", Status: "success", ExecutedAt: "2025-08-01T10:00:00Z"},
//   {ActionID: "act-002", Status: "success", ExecutedAt: "2025-08-05T14:30:00Z"},
//   {ActionID: "act-003", Status: "failure", ExecutedAt: "2025-08-10T09:15:00Z"},
//   ...
// ]
```

#### 4. **Traditional Effectiveness Calculation** (5-10ms)

```go
func (c *Calculator) CalculateTraditionalScore(history []ActionHistory) float64 {
    successCount := 0
    for _, h := range history {
        if h.Status == "success" {
            successCount++
        }
    }

    if len(history) == 0 {
        return 0.5 // Neutral score
    }

    return float64(successCount) / float64(len(history))
}

// Example: 87 successes out of 100 actions = 0.87 traditional score
```

#### 5. **Environmental Impact Correlation** (100-200ms, graceful degradation)

**Query Infrastructure Monitoring** for metrics after action execution:
```go
metrics, err := s.infraMonitorClient.GetMetricsAfterAction(ctx, "act-abc123", 10*time.Minute)

// Returns:
// {
//   MemoryImprovement: 0.25,  // 25% memory reduction
//   CPUImpact: -0.05,         // 5% CPU increase (negative = adverse)
//   NetworkStability: 0.92,   // 92% network stability
// }
```

**Graceful Degradation** (if Infrastructure Monitoring unavailable):
```go
if err != nil {
    s.logger.Warn("Failed to retrieve environmental metrics, continuing with basic assessment")
    metrics = &EnvironmentalMetrics{} // Default to zero impact
}
```

#### 6. **Side Effect Detection** (5-10ms)

```go
func (c *Calculator) DetectSideEffects(metrics *EnvironmentalMetrics) (bool, string) {
    // Detect negative side effects
    if metrics.CPUImpact < -0.1 || metrics.NetworkStability < 0.7 {
        if metrics.CPUImpact < -0.3 {
            return true, "high" // High severity: >30% CPU increase
        }
        return true, "low" // Low severity: 10-30% CPU increase or network instability
    }
    return false, "none"
}

// Example: CPUImpact = -0.05 (5% increase) â†’ No side effects detected
```

#### 7. **Trend Analysis** (10-20ms)

```go
func (c *Calculator) AnalyzeTrend(history []ActionHistory) string {
    if len(history) < 10 {
        return "insufficient_data"
    }

    // Compare recent (last 5) vs older (previous 5)
    recent := history[len(history)-5:]
    older := history[len(history)-10 : len(history)-5]

    recentSuccess := c.CalculateTraditionalScore(recent)
    olderSuccess := c.CalculateTraditionalScore(older)

    if recentSuccess > olderSuccess+0.1 {
        return "improving" // 10%+ improvement
    } else if recentSuccess < olderSuccess-0.1 {
        return "declining" // 10%+ decline
    }
    return "stable"
}

// Example: Recent = 0.92, Older = 0.78 â†’ "improving"
```

#### 8. **Pattern Recognition** (20-30ms)

```go
func (c *Calculator) GeneratePatternInsights(history []ActionHistory, action *ActionData) []string {
    insights := []string{}

    // Pattern 1: Environment-specific success rate
    prodSuccessRate := c.getEnvironmentSuccessRate(history, "production")
    if prodSuccessRate > 0.8 {
        insights = append(insights, fmt.Sprintf(
            "Similar actions successful in %.0f%% of production cases", prodSuccessRate*100))
    }

    // Pattern 2: Temporal correlation
    if c.hasBusinessHoursCorrelation(history) {
        insights = append(insights, "Effectiveness 12% lower during business hours")
    }

    return insights
}

// Example output:
// [
//   "Similar actions successful in 87% of production cases",
//   "Effectiveness 12% lower during business hours"
// ]
```

#### 9. **Confidence Calculation** (5ms)

```go
func (c *Calculator) CalculateConfidence(history []ActionHistory, dataWeeks int) float64 {
    baseConfidence := 0.5

    // Increase confidence with more data weeks
    if dataWeeks >= 12 {
        baseConfidence = 0.9
    } else if dataWeeks >= 8 {
        baseConfidence = 0.8
    }

    // Increase confidence with more action history
    if len(history) > 100 {
        baseConfidence += 0.05
    }

    if baseConfidence > 0.95 {
        baseConfidence = 0.95 // Cap at 95%
    }

    return baseConfidence
}

// Example: 10 weeks of data + 120 actions in history = 0.85 confidence
```

#### 10. **Assessment Result Persistence** (50-100ms, best-effort)

**Write to Data Storage**:
```go
assessment := &EffectivenessScore{
    AssessmentID:        "assess-xyz789",
    ActionID:            "act-abc123",
    ActionType:          "restart-pod",
    TraditionalScore:    0.87,
    EnvironmentalImpact: EnvironmentalMetrics{
        MemoryImprovement: 0.25,
        CPUImpact:         -0.05,
        NetworkStability:  0.92,
    },
    Confidence:          0.85,
    Status:              "assessed",
    SideEffectsDetected: false,
    SideEffectSeverity:  "none",
    TrendDirection:      "improving",
    PatternInsights:     []string{
        "Similar actions successful in 87% of production cases",
    },
    AssessedAt:          time.Now(),
}

// Best-effort write (log failure, continue)
if err := s.dataStorageClient.PersistAssessment(ctx, assessment); err != nil {
    s.logger.Error("Failed to persist assessment, continuing", zap.Error(err))
}
```

#### 11. **Response** (HTTP 200 OK)

**Week 13+ Full Assessment Response**:
```json
{
  "assessment_id": "assess-xyz789",
  "action_id": "act-abc123",
  "action_type": "restart-pod",
  "traditional_score": 0.87,
  "environmental_impact": {
    "memory_improvement": 0.25,
    "cpu_impact": -0.05,
    "network_stability": 0.92
  },
  "confidence": 0.85,
  "status": "assessed",
  "side_effects_detected": false,
  "side_effect_severity": "none",
  "trend_direction": "improving",
  "pattern_insights": [
    "Similar actions successful in 87% of production cases"
  ],
  "assessed_at": "2025-10-06T10:15:30Z"
}
```

**Total Latency**: 250-500ms (typical), < 5s p95

---

## Key Architectural Decisions

### 1. **V1 Graceful Degradation Strategy**

**Decision**: Deploy service in Week 5 with `insufficient_data` responses, gradually enable features as data accumulates.

**Why**:
- âœ… Early deployment validates integration points
- âœ… Monitoring and observability operational from Day 1
- âœ… Smooth transition to full capability (no "big bang" cutover)
- âœ… User expectations set via clear messaging

**Alternative Rejected**: Wait until Week 13 to deploy (delays validation).

---

### 2. **Infrastructure Monitoring is Non-Critical**

**Decision**: Use circuit breaker pattern with graceful degradation for Infrastructure Monitoring Service.

**Why**:
- âœ… Environmental metrics enhance assessments but aren't required
- âœ… Basic effectiveness scoring works without metrics
- âœ… Prevents cascading failures if Infrastructure Monitoring down
- âœ… Degrades user experience gracefully (no assessment failures)

**Implementation**:
```go
metrics, err := circuitBreaker.Call(ctx, func(ctx context.Context) (*EnvironmentalMetrics, error) {
    return s.infraMonitorClient.GetMetricsAfterAction(ctx, actionID, 10*time.Minute)
})
// If circuit open or call fails â†’ return default zero-impact metrics
```

---

### 3. **Data Storage is Critical Dependency**

**Decision**: Fail assessment requests if Data Storage unavailable.

**Why**:
- âœ… Action history is **required** for effectiveness calculation
- âœ… Cannot provide meaningful assessments without historical data
- âœ… Fail-fast prevents misleading results
- âœ… Clear error messaging guides troubleshooting

**Error Response** (Data Storage unavailable):
```json
{
  "error": "data_storage_unavailable",
  "message": "Cannot retrieve action history from Data Storage Service",
  "retry_after": "60s"
}
```

---

### 4. **Assessment Persistence is Best-Effort**

**Decision**: Log error but continue if assessment persistence fails.

**Why**:
- âœ… Assessment result already returned to client
- âœ… Retrying write could cause request timeout
- âœ… Historical assessments are "nice to have" not critical
- âœ… Monitoring alerts on persistence failures

---

### 5. **8-Week Minimum for High Confidence**

**Decision**: Require 8+ weeks of historical data for confidence â‰¥ 80%.

**Why**:
- âœ… Statistical significance: 8 weeks â‰ˆ 50-200 actions (depending on frequency)
- âœ… Captures seasonal patterns (e.g., business hours vs off-hours)
- âœ… Reduces impact of outliers and anomalies
- âœ… Industry standard for trend analysis

**Confidence Levels**:
- **< 5 weeks**: 30-50% confidence (insufficient data)
- **5-7 weeks**: 50-70% confidence (basic assessment)
- **8-11 weeks**: 70-85% confidence (good assessment)
- **12+ weeks**: 85-95% confidence (excellent assessment)

---

### 6. **Watch RemediationRequest Instead of WorkflowExecution**

**Decision**: EM controller watches RemediationRequest CRD instead of WorkflowExecution CRD.

**Why**:
- âœ… Decouples EM from internal workflow implementation (95% confidence)
- âœ… Future-proof against workflow refactors (92% confidence)
- âœ… Multi-workflow scenarios handled automatically
- âœ… Semantic alignment: Assess "remediation effectiveness" not "workflow execution"
- âœ… API stability: RR is user-facing, stable API vs WE internal implementation

**Implementation**:
- Watch `RemediationRequest.status.overallPhase` for terminal states ("completed", "failed", "timeout")
- All required data available in `RR.status.workflowExecutionStatus` summary
- Can fetch WE details if needed (rare cases)

**Reference**: [DD-EFFECTIVENESS-003](../../../architecture/decisions/DD-EFFECTIVENESS-003-RemediationRequest-Watch-Strategy.md)

---

## V1 Graceful Degradation Strategy

### Deployment Timeline

| Week | Milestone | Capability | User Experience |
|------|-----------|------------|-----------------|
| **Week 5** | Service Deployed | `insufficient_data` responses only | Clear messaging: "Data accumulating, ETA Week 13" |
| **Week 8** | 3 weeks of data | Basic traditional scoring | 40-50% confidence, no trends/patterns |
| **Week 10** | 5 weeks of data | Side effect detection + trends | 60-70% confidence, limited pattern recognition |
| **Week 13** | 8 weeks of data | **Full capability** | 80-95% confidence, complete multi-dimensional assessment |
| **Week 16+** | 11+ weeks of data | Enhanced confidence | 90-95% confidence, mature pattern insights |

### Week 5 Implementation

**Health Check** (Week 5):
```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
# Ready = "service operational" (even if returning insufficient_data)
```

**`/ready` Endpoint** (Week 5):
```go
func (s *EffectivenessMonitorService) readinessHandler(w http.ResponseWriter, r *http.Request) {
    // Check critical dependencies
    if !s.dataStorageClient.Healthy() {
        http.Error(w, "Data Storage unavailable", http.StatusServiceUnavailable)
        return
    }

    // Check data availability (informational only)
    dataWeeks, _ := s.checkDataAvailability(r.Context())

    response := map[string]interface{}{
        "status": "ready",
        "data_weeks": dataWeeks,
        "full_capability": dataWeeks >= 8,
    }

    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(response)
}
```

**Metrics** (Week 5):
```go
var (
    dataAvailabilityWeeks = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "effectiveness_data_availability_weeks",
            Help: "Number of weeks of historical data available",
        },
    )

    insufficientDataResponses = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: "effectiveness_insufficient_data_responses_total",
            Help: "Total number of insufficient_data responses",
        },
    )
)
```

### Week 13+ Full Capability

**All features operational**:
- âœ… Traditional effectiveness scoring
- âœ… Environmental impact correlation
- âœ… Side effect detection
- âœ… Trend analysis (improving/declining/stable)
- âœ… Pattern recognition (temporal, environmental)
- âœ… High confidence (80-95%)

---

## Hybrid Architecture Details

### Decision Logic Implementation

```go
// pkg/monitor/decision_logic.go
package monitor

type EffectivenessMonitorService struct {
    holmesgptClient *HolmesGPTClient
    // ... other clients
}

// shouldCallAI determines if AI analysis adds value beyond automated assessment
func (s *EffectivenessMonitorService) shouldCallAI(
    workflow *WorkflowExecution,
    basicScore float64,
    anomalies []string,
) bool {
    // Trigger 1: P0 failures - Always analyze for learning
    if workflow.Priority == "P0" && !workflow.Success {
        s.metrics.aiTriggerCounter.WithLabelValues("p0_failure").Inc()
        return true
    }

    // Trigger 2: New action types - Build knowledge base
    if workflow.IsNewActionType {
        s.metrics.aiTriggerCounter.WithLabelValues("new_action_type").Inc()
        return true
    }

    // Trigger 3: Anomalies detected - Investigation needed
    if len(anomalies) > 0 {
        s.metrics.aiTriggerCounter.WithLabelValues("anomaly_detected").Inc()
        return true
    }

    // Trigger 4: Oscillation/recurring failures - Pattern analysis
    if workflow.IsRecurringFailure {
        s.metrics.aiTriggerCounter.WithLabelValues("oscillation").Inc()
        return true
    }

    // Default: Routine successes - No AI needed
    s.metrics.aiTriggerCounter.WithLabelValues("routine_skipped").Inc()
    return false
}
```

### Cost Control and Volume Estimates

**Annual Assessment Volume**: 3,650,000 actions/year (~10,000/day)

| Trigger Type | Volume/Day | Volume/Year | AI Calls | Cost/Call | Cost/Year |
|--------------|------------|-------------|----------|-----------|-----------|
| **P0 Failures** | 50 | 18,250 | 18,250 | $0.0387 | $706.28 |
| **New Action Types** | 10 | 3,650 | 3,650 | $0.0387 | $141.26 |
| **Anomalies Detected** | 5 | 1,825 | 1,825 | $0.0387 | $70.63 |
| **Oscillations** | 5 | 1,825 | 1,825 | $0.0387 | $70.63 |
| **Routine Successes** | 10,000 | 3,650,000 | 0 | $0 | $0 |
| **TOTAL** | **10,070** | **3,675,550** | **25,550** | - | **$988.79** |

**Effective AI Usage**: 0.7% of actions analyzed by AI

**Cost Comparison** (Updated with DD-HOLMESGPT-009 token optimization):
- **Always-AI**: 3.65M Ã— $0.0387 = $141,255/year
- **Hybrid**: 25.5K Ã— $0.0387 = $988.79/year
- **Savings**: $140,266/year (99.3% cost reduction)
- **Token Efficiency**: Self-documenting JSON (290 tokens vs 800 verbose)

**Value Delivered**:
- Effectiveness improves from 70% (no AI) to 85-90% (hybrid)
- Critical failures always analyzed for learning
- Routine successes handled efficiently with automation

### Prometheus Metrics for Cost Tracking

```go
// pkg/monitor/metrics.go
package monitor

import "github.com/prometheus/client_golang/prometheus"

var (
    // AI trigger tracking
    aiTriggerCounter = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "effectiveness_ai_trigger_total",
            Help: "Total AI analysis triggers by type",
        },
        []string{"trigger_type"}, // p0_failure, new_action_type, anomaly_detected, oscillation, routine_skipped
    )

    // AI call tracking
    aiCallCounter = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "effectiveness_ai_calls_total",
            Help: "Total HolmesGPT API calls for post-execution analysis",
        },
        []string{"status"}, // success, failure, timeout
    )

    // Cost tracking (actual token-based)
    aiCostCounter = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: "effectiveness_ai_cost_total_dollars",
            Help: "Total cost of AI analysis in dollars ($0.0387/call with self-doc JSON)",
        },
    )

    // AI call duration
    aiCallDuration = prometheus.NewHistogram(
        prometheus.HistogramOpts{
            Name: "effectiveness_ai_call_duration_seconds",
            Help: "Duration of HolmesGPT API calls",
            Buckets: []float64{1, 5, 10, 20, 30, 60},
        },
    )
)

// Track AI call and cost
func (s *EffectivenessMonitorService) trackAICall(duration float64, success bool) {
    status := "success"
    if !success {
        status = "failure"
    }
    aiCallCounter.WithLabelValues(status).Inc()
    aiCostCounter.Add(0.0387) // $0.0387 per call (self-doc JSON)
    aiCallDuration.Observe(duration)
}
```

**Monitoring Queries**:

```promql
# Daily AI analysis cost
sum(increase(effectiveness_ai_cost_total_dollars[24h]))

# AI trigger breakdown (last 7 days)
sum by (trigger_type) (increase(effectiveness_ai_trigger_total[7d]))

# AI call success rate
rate(effectiveness_ai_calls_total{status="success"}[24h])
/
rate(effectiveness_ai_calls_total[24h])

# Average AI call duration (p95)
histogram_quantile(0.95, effectiveness_ai_call_duration_seconds_bucket)
```

---

## System Context Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     External Context                              â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Context API   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  HolmesGPT API  â”‚        â”‚
â”‚  â”‚   Service       â”‚  GET assessment â”‚   Service       â”‚        â”‚
â”‚  â”‚   (Port 8080)   â”‚                 â”‚   (Port 8090)   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚           â”‚                                                       â”‚
â”‚           â”‚ Assessment Requests                                  â”‚
â”‚           â”‚ (HTTP GET /api/v1/assess/effectiveness/:actionID)    â”‚
â”‚           â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Effectiveness Monitor Service (Port 8080)              â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  HTTP API                                                  â”‚ â”‚
â”‚  â”‚  - POST /api/v1/assess/effectiveness                       â”‚ â”‚
â”‚  â”‚  - GET  /api/v1/assess/effectiveness/:actionID             â”‚ â”‚
â”‚  â”‚  - POST /api/v1/assess/batch                               â”‚ â”‚
â”‚  â”‚  - GET  /health, /ready                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Effectiveness Calculator                                  â”‚ â”‚
â”‚  â”‚  - Traditional Score Calculation                           â”‚ â”‚
â”‚  â”‚  - Side Effect Detection                                   â”‚ â”‚
â”‚  â”‚  - Trend Analysis                                          â”‚ â”‚
â”‚  â”‚  - Pattern Recognition                                     â”‚ â”‚
â”‚  â”‚  - Confidence Calculation                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                       â”‚
          â”‚ Action History                        â”‚ Environmental Metrics
          â”‚ (GET /api/v1/audit/actions)           â”‚ (GET /api/v1/metrics/after-action)
          â”‚                                       â”‚
          â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Storage Service   â”‚          â”‚ Infrastructure Monitoring   â”‚
â”‚  (Port 8085)            â”‚          â”‚ Service (Port 8094)         â”‚
â”‚                         â”‚          â”‚                             â”‚
â”‚  - Action history       â”‚          â”‚  - CPU/Memory metrics       â”‚
â”‚  - Assessment storage   â”‚          â”‚  - Network stability        â”‚
â”‚  - PostgreSQL + pgvectorâ”‚          â”‚  - Prometheus queries       â”‚
â”‚                         â”‚          â”‚  - Graceful degradation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Assessment Request Flow                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Context API â†’ Effectiveness Monitor
   GET /api/v1/assess/effectiveness/act-abc123
   Authorization: Bearer <token>

   â†“

2. Effectiveness Monitor â†’ Data Storage
   GET /api/v1/audit/actions/oldest
   (Check data availability: 10 weeks âœ“)

   â†“

3. Effectiveness Monitor â†’ Data Storage
   GET /api/v1/audit/actions?action_type=restart-pod&time_range=90d
   Returns: 120 actions (87 success, 33 failure)

   â†“

4. Calculate Traditional Score
   87 / 120 = 0.725 (72.5% success rate)

   â†“

5. Effectiveness Monitor â†’ Infrastructure Monitoring
   GET /api/v1/metrics/after-action?action_id=act-abc123&window=10m
   Returns: {
     memory_improvement: 0.25,
     cpu_impact: -0.05,
     network_stability: 0.92
   }

   â†“

6. Side Effect Detection
   CPU impact = -5% (minimal) â†’ No side effects

   â†“

7. Trend Analysis
   Recent 5: 0.80, Older 5: 0.68 â†’ "improving"

   â†“

8. Pattern Recognition
   Production success rate: 87% â†’ Pattern insight

   â†“

9. Confidence Calculation
   10 weeks data + 120 actions â†’ 0.85 confidence

   â†“

10. Effectiveness Monitor â†’ Data Storage
    POST /api/v1/audit/effectiveness
    (Persist assessment result - best effort)

    â†“

11. Effectiveness Monitor â†’ Context API
    HTTP 200 OK
    {
      "assessment_id": "assess-xyz789",
      "traditional_score": 0.725,
      "confidence": 0.85,
      "trend_direction": "improving",
      ...
    }
```

---

## Business Requirements Mapping

| Business Requirement | Implementation | Validation |
|---------------------|----------------|------------|
| **BR-INS-001**: Traditional effectiveness assessment | `CalculateTraditionalScore()` | Unit test: success rate calculation |
| **BR-INS-002**: Environmental impact correlation | `GetMetricsAfterAction()` | Integration test: Infrastructure Monitoring query |
| **BR-INS-003**: Long-term trend detection | `AnalyzeTrend()` | Unit test: improving/declining/stable detection |
| **BR-INS-005**: Side effect detection | `DetectSideEffects()` | Unit test: CPU/memory/network severity classification |
| **BR-INS-006**: Advanced pattern recognition | `GeneratePatternInsights()` | Unit test: temporal & environmental patterns |
| **BR-INS-008**: Confidence-adjusted scoring | `CalculateConfidence()` | Unit test: confidence levels by data availability |
| **BR-INS-010**: Multi-dimensional assessment | `AssessEffectiveness()` | E2E test: complete assessment workflow |

**BR Range Allocation**:
- **V1.0 Scope (Level 1)**: BR-INS-001, BR-INS-002, BR-INS-005 (Automated assessment: dual spec hash, health checks, metrics, alert resolution, formula-based scoring, side-effect detection)
- **V1.1 Scope (Level 2)**: BR-INS-003, BR-INS-004, BR-INS-006 to BR-INS-010 (AI-powered analysis: HolmesGPT PostExec, pattern learning, batch processing)
- **Reserved for V2**: BR-INS-011 to BR-INS-100 (Multi-cloud support: AWS CloudWatch, Azure Monitor, Datadog, GCP Monitoring; Advanced ML-based effectiveness prediction)

**Rationale for Limited V1 Scope**: Per DD-017 v2.0, Level 1 (V1.0) provides Day-1 value with no data dependency. Level 2 (V1.1) requires 8+ weeks of Level 1 assessment data for high-confidence AI analysis. V2 will expand to multi-cloud observability sources and ML-based prediction models.

---

## Performance Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Assessment Latency** | < 5s p95 | Prometheus histogram: `effectiveness_assessment_duration_seconds` |
| **Data Storage Query** | < 100ms p95 | Internal metric: `data_storage_query_duration_seconds` |
| **Infrastructure Monitoring Query** | < 200ms p95 | Internal metric: `infrastructure_monitoring_query_duration_seconds` |
| **Confidence Threshold** | â‰¥ 80% | With 8+ weeks of data |
| **Data Availability** | 8+ weeks | For full capability |

---

**Document Maintainer**: Kubernaut Documentation Team
**Last Updated**: October 6, 2025
**Status**: âœ… Complete Specification

