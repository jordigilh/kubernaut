/*
Copyright 2025 Jordi Gil.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Package remediationorchestrator_test contains integration tests for the RemediationOrchestrator controller.
// These tests use ENVTEST with real Kubernetes API (etcd + kube-apiserver).
//
// Defense-in-Depth Strategy (per 03-testing-strategy.mdc):
// - Unit tests (70%+): Business logic in isolation (test/unit/remediationorchestrator/)
// - Integration tests (>50%): Infrastructure interaction, microservices coordination (this file)
// - E2E tests (10-15%): Complete workflow validation (test/e2e/remediationorchestrator/)
//
// Test Execution (parallel, 4 procs):
//
//	ginkgo -p --procs=4 ./test/integration/remediationorchestrator/...
//
// MANDATORY: All tests use unique namespaces for parallel execution isolation.
package remediationorchestrator

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"testing"
	"time"

	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"

	corev1 "k8s.io/api/core/v1"
	apierrors "k8s.io/apimachinery/pkg/api/errors"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/apimachinery/pkg/util/wait"
	"k8s.io/client-go/kubernetes/scheme"
	"k8s.io/client-go/rest"
	"k8s.io/utils/ptr"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/envtest"
	logf "sigs.k8s.io/controller-runtime/pkg/log"
	"sigs.k8s.io/controller-runtime/pkg/log/zap"
	metricsserver "sigs.k8s.io/controller-runtime/pkg/metrics/server"

	// Import ALL CRD types that RO interacts with
	aianalysisv1 "github.com/jordigilh/kubernaut/api/aianalysis/v1alpha1"
	notificationv1 "github.com/jordigilh/kubernaut/api/notification/v1alpha1"
	remediationv1 "github.com/jordigilh/kubernaut/api/remediation/v1alpha1"
	signalprocessingv1 "github.com/jordigilh/kubernaut/api/signalprocessing/v1alpha1"
	workflowexecutionv1 "github.com/jordigilh/kubernaut/api/workflowexecution/v1alpha1"
	sharedtypes "github.com/jordigilh/kubernaut/pkg/shared/types"

	// Import RO controller
	controller "github.com/jordigilh/kubernaut/internal/controller/remediationorchestrator"
	"github.com/jordigilh/kubernaut/test/infrastructure"

	// Import audit infrastructure (ADR-032)
	"github.com/jordigilh/kubernaut/pkg/audit"
	rometrics "github.com/jordigilh/kubernaut/pkg/remediationorchestrator/metrics"
	"github.com/jordigilh/kubernaut/pkg/remediationorchestrator/routing"
	"github.com/jordigilh/kubernaut/pkg/testutil"
	// Child CRD controllers NOT imported - Phase 1 integration tests use manual control
	// Real controller testing happens in:
	//   - Service integration tests (test/integration/{service}/)
	//   - RO segmented E2E tests (Phase 2 - future)
)

// Test constants for timeout and polling intervals
const (
	timeout  = 60 * time.Second // Longer timeout for RO orchestration
	interval = 250 * time.Millisecond

	// ROIntegrationDataStoragePort is the DataStorage API port for RO integration tests
	// Per DD-TEST-001 v2.2: Each service gets a unique port to enable parallel test execution
	ROIntegrationDataStoragePort = 18140
)

// Package-level variables for test environment
var (
	ctx        context.Context
	cancel     context.CancelFunc
	testEnv    *envtest.Environment
	cfg        *rest.Config
	k8sClient  client.Client
	k8sManager ctrl.Manager
	auditStore audit.AuditStore


	// dataStorageBaseURL is the base URL for DataStorage API calls
	// Uses ROIntegrationDataStoragePort to avoid brittle hardcoded ports (DD-TEST-001 v2.2)
	dataStorageBaseURL = fmt.Sprintf("http://127.0.0.1:%d", ROIntegrationDataStoragePort)
)

func TestRemediationOrchestratorIntegration(t *testing.T) {
	RegisterFailHandler(Fail)
	RunSpecs(t, "RemediationOrchestrator Controller Integration Suite (ENVTEST + AIAnalysis Pattern)")
}

// SynchronizedBeforeSuite runs ONCE globally before all parallel processes start
// Pattern: AIAnalysis (Programmatic podman-compose + parallel-safe)
// Authority: docs/handoff/TRIAGE_RO_INFRASTRUCTURE_BOOTSTRAP_COMPARISON.md
var _ = SynchronizedBeforeSuite(func() []byte {
	// This runs ONCE on process 1 only - creates shared infrastructure
	logf.SetLogger(zap.New(zap.WriteTo(GinkgoWriter), zap.UseDevMode(true)))

	GinkgoWriter.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	GinkgoWriter.Println("RemediationOrchestrator Integration Test Suite - Automated Setup")
	GinkgoWriter.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	GinkgoWriter.Println("Creating test infrastructure...")
	GinkgoWriter.Println("  â€¢ envtest (in-memory K8s API server)")
	GinkgoWriter.Println("  â€¢ PostgreSQL (port 15435)")
	GinkgoWriter.Println("  â€¢ Redis (port 16381)")
	GinkgoWriter.Println("  â€¢ Data Storage API (port 18140)")
	GinkgoWriter.Println("  â€¢ Pattern: AIAnalysis (Programmatic podman-compose)")
	GinkgoWriter.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	ctx, cancel = context.WithCancel(context.TODO())

	var err error

	// Cleanup handled by StartDSBootstrap (cleanupDSBootstrapContainers)
	By("Starting RO integration infrastructure (DD-TEST-002)")
	// This starts: PostgreSQL, Redis, Immudb, DataStorage
	// Per DD-TEST-001 v2.2: PostgreSQL=15435, Redis=16381, Immudb=13325, DS=18140
	dsInfra, err := infrastructure.StartDSBootstrap(infrastructure.DSBootstrapConfig{
		ServiceName:     "remediationorchestrator",
		PostgresPort:    15435,                      // DD-TEST-001 v2.2
		RedisPort:       16381,                      // DD-TEST-001 v2.2
		DataStoragePort: ROIntegrationDataStoragePort, // DD-TEST-001 v2.2
		MetricsPort:     19140,
		ConfigDir:       "test/integration/remediationorchestrator/config",
	}, GinkgoWriter)
	Expect(err).ToNot(HaveOccurred(), "Infrastructure must start successfully")
	GinkgoWriter.Println("âœ… All external services started and healthy (PostgreSQL, Redis, Immudb, DataStorage)")

	// Clean up infrastructure on exit
	DeferCleanup(func() {
		infrastructure.StopDSBootstrap(dsInfra, GinkgoWriter)
	})

	By("Registering ALL CRD schemes for RO orchestration")

	// RemediationRequest and RemediationApprovalRequest (RO owns these)
	err = remediationv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())

	// SignalProcessing (RO creates these)
	err = signalprocessingv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())

	// AIAnalysis (RO creates these)
	err = aianalysisv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())

	// WorkflowExecution (RO creates these)
	err = workflowexecutionv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())

	// NotificationRequest (RO creates these)
	err = notificationv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())

	By("Bootstrapping envtest with ALL CRDs")
	testEnv = &envtest.Environment{
		CRDDirectoryPaths:     []string{filepath.Join("..", "..", "..", "config", "crd", "bases")},
		ErrorIfCRDPathMissing: true,
	}

	// Retrieve the first found binary directory to allow running tests from IDEs
	if getFirstFoundEnvTestBinaryDir() != "" {
		testEnv.BinaryAssetsDirectory = getFirstFoundEnvTestBinaryDir()
	}

	cfg, err = testEnv.Start()
	Expect(err).NotTo(HaveOccurred())
	Expect(cfg).NotTo(BeNil())

	By("Creating controller-runtime client")
	k8sClient, err = client.New(cfg, client.Options{Scheme: scheme.Scheme})
	Expect(err).NotTo(HaveOccurred())
	Expect(k8sClient).NotTo(BeNil())

	By("Creating required namespaces")
	// Create kubernaut-system namespace for controller
	systemNs := &corev1.Namespace{
		ObjectMeta: metav1.ObjectMeta{
			Name: "kubernaut-system",
		},
	}
	err = k8sClient.Create(ctx, systemNs)
	if err != nil && !apierrors.IsAlreadyExists(err) {
		Expect(err).NotTo(HaveOccurred())
	}

	// Create default namespace for tests
	defaultNs := &corev1.Namespace{
		ObjectMeta: metav1.ObjectMeta{
			Name: "default",
		},
	}
	_ = k8sClient.Create(ctx, defaultNs) // May already exist

	GinkgoWriter.Println("âœ… Namespaces created: kubernaut-system, default")

	By("Setting up the controller manager")
	k8sManager, err = ctrl.NewManager(cfg, ctrl.Options{
		Scheme: scheme.Scheme,
		Metrics: metricsserver.Options{
			BindAddress: ":0", // Dynamic port allocation (prevents conflicts with E2E tests)
		},
	})
	Expect(err).ToNot(HaveOccurred())

	By("Setting up the RemediationOrchestrator controller")
	// Create RO reconciler with manager client, scheme, and audit store
	// Per ADR-032 Â§1: Audit is MANDATORY for P0 services (RO is P0)
	// Integration tests use real DataStorage API at dataStorageBaseURL (DD-TEST-001 v2.2)
	// DD-API-001: Use OpenAPI client adapter (type-safe, contract-validated)
	// DD-AUTH-005: Integration tests use mock user transport (no oauth-proxy)
	// Audit store is created per-process in second SynchronizedBeforeSuite function
	// This ensures ALL parallel processes can call auditStore.Flush() in tests
	// Process 1: Uses audit store for controller audit emission
	// Other processes: Use empty audit stores (no events emitted, but Flush() works)

	By("Initializing RemediationOrchestrator metrics (DD-METRICS-001)")
	// Per DD-METRICS-001: Metrics must be initialized and injected for integration tests
	// This enables metrics validation tests (M-INT-1 through M-INT-6)
	roMetrics := rometrics.NewMetrics()
	GinkgoWriter.Println("âœ… RO metrics initialized and registered")

	// Create routing engine for blocking logic (BR-ORCH-042)
	routingEngine := routing.NewRoutingEngine(
		k8sManager.GetClient(),
		"", // No namespace filter - all namespaces
		routing.Config{
			ConsecutiveFailureThreshold: 3,
			ConsecutiveFailureCooldown:  3600, // 1 hour
			RecentlyRemediatedCooldown:  300,  // 5 minutes
			ExponentialBackoffBase:      60,   // 1 minute
			ExponentialBackoffMax:       3600, // 1 hour
		},
	)

	reconciler := controller.NewReconciler(
		k8sManager.GetClient(),
		k8sManager.GetScheme(),
		auditStore,                 // Real audit store for ADR-032 compliance
		nil,                        // No EventRecorder for integration tests
		roMetrics,                  // DD-METRICS-001: Real metrics for integration tests (enables M-INT-1 through M-INT-6)
		controller.TimeoutConfig{}, // Use defaults: Global=1h, Processing=5m, Analyzing=10m, Executing=30m (BR-ORCH-027/028)
		routingEngine,              // Real routing engine for integration tests (BR-ORCH-042)
	)
	err = reconciler.SetupWithManager(k8sManager)
	Expect(err).ToNot(HaveOccurred())

	By("Configuring child CRD test strategy")

	// ========================================
	// INTEGRATION TEST STRATEGY = PHASE 1 (Manual Control)
	// ========================================
	// Per RO_E2E_ARCHITECTURE_TRIAGE.md: Integration tests validate RO's
	// orchestration logic in isolation using manual child CRD control.
	//
	// 3-Phase Testing Strategy:
	//   Phase 1 (Integration): RO ONLY, tests manually control child CRDs
	//   Phase 2 (Segmented E2E): RO + ONE real service per segment
	//   Phase 3 (Full E2E): ALL services together
	//
	// This is Phase 1 - no child controllers running.
	// ========================================

	// 1. SignalProcessing Controller - NOT STARTED
	// Tests manually create and update SignalProcessing CRDs
	// Real SP controller testing: test/integration/signalprocessing/ and E2E Segment 2
	GinkgoWriter.Println("â„¹ï¸  SignalProcessing controller NOT started (Phase 1: manual control)")

	// 2. AIAnalysis Controller - NOT STARTED
	// Tests manually create and update AIAnalysis CRDs
	// Real AA controller testing: test/integration/aianalysis/ and E2E Segment 3
	GinkgoWriter.Println("â„¹ï¸  AIAnalysis controller NOT started (Phase 1: manual control)")

	// 3. WorkflowExecution Controller - NOT STARTED
	// Tests manually create and update WorkflowExecution CRDs
	// Real WE controller testing: test/integration/workflowexecution/ and E2E Segment 4
	// Note: WE controller requires Tekton PipelineRun CRDs (not available in envtest)
	GinkgoWriter.Println("â„¹ï¸  WorkflowExecution controller NOT started (Phase 1: manual control)")

	// 4. NotificationRequest Controller - NOT STARTED
	// Tests manually create and update NotificationRequest CRDs
	// Real NR controller testing: test/integration/notification/ and E2E Segment 5
	GinkgoWriter.Println("â„¹ï¸  NotificationRequest controller NOT started (Phase 1: manual control)")

	GinkgoWriter.Println("âœ… Phase 1 integration test strategy configured (RO controller only)")

	By("Starting the controller manager")
	go func() {
		defer GinkgoRecover()
		err = k8sManager.Start(ctx)
		Expect(err).ToNot(HaveOccurred(), "failed to run manager")
	}()

	// Wait for manager cache to sync (ensures controllers receive CRD events)
	// Critical: Without cache sync, controllers won't receive Create/Update/Delete events
	// and tests will timeout waiting for status updates (80% confidence this fixes 35+ failures)
	GinkgoWriter.Println("â³ Waiting for controller manager cache to sync...")

	// Wait for cache to sync with timeout
	// Note: Increased from 10s to 60s after observing SignalProcessing and RemediationApprovalRequest
	// informer sync timeouts on Dec 25, 2025. With 6+ CRDs loading, 10s was insufficient.
	cacheSyncCtx, cacheSyncCancel := context.WithTimeout(ctx, 60*time.Second)
	defer cacheSyncCancel()

	if !k8sManager.GetCache().WaitForCacheSync(cacheSyncCtx) {
		Fail("Failed to sync controller manager cache within 60 seconds")
	}

	// Give controllers additional time to initialize watches and start reconciliation loops
	time.Sleep(2 * time.Second)

	GinkgoWriter.Println("âœ… Controller manager cache synced and ready")

	// Note: Metrics server uses dynamic port allocation (":0") to prevent conflicts
	// Port discovery is not exposed by controller-runtime Manager interface
	// Metrics testing should be done at unit test level or via E2E with known ports

	GinkgoWriter.Println("âœ… RemediationOrchestrator integration test environment ready!")
	GinkgoWriter.Println("")
	GinkgoWriter.Println("Environment:")
	GinkgoWriter.Println("  â€¢ ENVTEST with real Kubernetes API (etcd + kube-apiserver)")
	GinkgoWriter.Println("  â€¢ ALL CRDs installed:")
	GinkgoWriter.Println("    - RemediationRequest")
	GinkgoWriter.Println("    - RemediationApprovalRequest")
	GinkgoWriter.Println("    - SignalProcessing")
	GinkgoWriter.Println("    - AIAnalysis")
	GinkgoWriter.Println("    - WorkflowExecution")
	GinkgoWriter.Println("    - NotificationRequest")
	GinkgoWriter.Println("  â€¢ ALL Controllers running:")
	GinkgoWriter.Println("    - RemediationOrchestrator (RO)")
	GinkgoWriter.Println("    - SignalProcessing (SP)")
	GinkgoWriter.Println("    - AIAnalysis (AI)")
	GinkgoWriter.Println("    - WorkflowExecution (WE)")
	GinkgoWriter.Println("    - NotificationRequest (NOT)")
	GinkgoWriter.Println("  â€¢ REAL services available:")
	GinkgoWriter.Println("    - PostgreSQL: localhost:15435")
	GinkgoWriter.Println("    - Redis: localhost:16381")
	GinkgoWriter.Printf("    - Data Storage: %s\n", dataStorageBaseURL)
	GinkgoWriter.Println("")

	// Serialize REST config to pass to all processes
	// Each process needs to create its own k8s client
	configBytes, err := json.Marshal(struct {
		Host     string
		CAData   []byte
		CertData []byte
		KeyData  []byte
	}{
		Host:     cfg.Host,
		CAData:   cfg.CAData,
		CertData: cfg.CertData,
		KeyData:  cfg.KeyData,
	})
	Expect(err).NotTo(HaveOccurred())

	return configBytes
}, func(data []byte) {
	// This runs on ALL parallel processes (including process 1)
	// Each process creates its own k8s client and context
	logf.SetLogger(zap.New(zap.WriteTo(GinkgoWriter), zap.UseDevMode(true)))

	// Deserialize REST config from process 1
	var configData struct {
		Host     string
		CAData   []byte
		CertData []byte
		KeyData  []byte
	}
	err := json.Unmarshal(data, &configData)
	Expect(err).NotTo(HaveOccurred())

	// Register ALL CRD schemes (MUST be done before creating client)
	err = remediationv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())
	err = signalprocessingv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())
	err = aianalysisv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())
	err = workflowexecutionv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())
	err = notificationv1.AddToScheme(scheme.Scheme)
	Expect(err).NotTo(HaveOccurred())

	// Create per-process REST config
	cfg = &rest.Config{
		Host: configData.Host,
		TLSClientConfig: rest.TLSClientConfig{
			CAData:   configData.CAData,
			CertData: configData.CertData,
			KeyData:  configData.KeyData,
		},
	}

	// Create per-process k8s client
	k8sClient, err = client.New(cfg, client.Options{Scheme: scheme.Scheme})
	Expect(err).NotTo(HaveOccurred())
	Expect(k8sClient).NotTo(BeNil())

	// Create per-process context ONLY if not already set (process 1 has it from first function)
	// Process 1: ctx already set and used by controller manager - don't overwrite!
	// Other processes: Need ctx for test operations
	if ctx == nil {
		ctx, cancel = context.WithCancel(context.Background())
	}

	// Create per-process audit store (DD-AUDIT-003)
	// All parallel processes need this to call Flush() in tests, but only process 1 emits events
	// Pattern: AIAnalysis suite_test.go lines 434-442
	mockTransport := testutil.NewMockUserTransport("test-remediationorchestrator@integration.test")
	dataStorageClient, err := audit.NewOpenAPIClientAdapterWithTransport(
		dataStorageBaseURL,
		5*time.Second,
		mockTransport,
	)
	Expect(err).ToNot(HaveOccurred(), "Failed to create Data Storage client for process audit store")

	auditLogger := ctrl.Log.WithName("audit")
	auditConfig := audit.Config{
		FlushInterval: 1 * time.Second,
		BufferSize:    10,
		BatchSize:     5,
		MaxRetries:    3,
	}
	auditStore, err = audit.NewBufferedStore(dataStorageClient, auditConfig, "remediation-orchestrator", auditLogger)
	Expect(err).ToNot(HaveOccurred(), "Per-process audit store creation must succeed")
	GinkgoWriter.Println("âœ… Per-process audit store configured")
})

// AfterEach validates that no audit validation errors occurred during the test
// This catches OpenAPI schema violations that would otherwise be silent failures
// Example: Wrong enum values like "Remediated" instead of "Success"
// Note: Only runs on process 1 (where controller manager and audit store run)
var _ = AfterEach(func() {
	if testAuditWrapper != nil {
		testAuditWrapper.ExpectNoValidationErrors()
		// Reset errors after each test to avoid cross-test pollution
		testAuditWrapper.ResetValidationErrors()
	}
})

// SynchronizedAfterSuite ensures proper cleanup in parallel execution
var _ = SynchronizedAfterSuite(func() {
	// This runs on ALL parallel processes - no cleanup needed per process
}, func() {
	// This runs ONCE on the last parallel process - cleanup shared infrastructure
	By("Tearing down the test environment")

	// RO-SHUTDOWN-001: Flush audit store BEFORE stopping DataStorage
	// This prevents "connection refused" errors during cleanup when the
	// background writer tries to flush buffered events after DataStorage is stopped.
	// Integration tests MUST always use real DataStorage (DD-TESTING-001)
	By("Flushing audit store before infrastructure shutdown")

	flushCtx, flushCancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer flushCancel()

	err := auditStore.Flush(flushCtx)
	if err != nil {
		GinkgoWriter.Printf("âš ï¸ Warning: Failed to flush audit store: %v\n", err)
	} else {
		GinkgoWriter.Println("âœ… Audit store flushed (all buffered events written)")
	}

	err = auditStore.Close()
	if err != nil {
		GinkgoWriter.Printf("âš ï¸ Warning: Failed to close audit store: %v\n", err)
	} else {
		GinkgoWriter.Println("âœ… Audit store closed")
	}

	cancel()

	if testEnv != nil {
		err := testEnv.Stop()
		Expect(err).NotTo(HaveOccurred())
	}

	// RO-SHUTDOWN-001: Safe to stop now - audit events already flushed
	// Infrastructure cleanup handled by DeferCleanup (StopDSBootstrap)

	By("Cleaning up infrastructure images to prevent disk space issues (DD-TEST-001 v1.1)")
	// Prune ONLY infrastructure images for RemediationOrchestrator
	pruneCmd := exec.Command("podman", "image", "prune", "-f",
		"--filter", "label=io.podman.compose.project=remediationorchestrator-integration")
	pruneOutput, pruneErr := pruneCmd.CombinedOutput()
	if pruneErr != nil {
		GinkgoWriter.Printf("âš ï¸  Failed to prune images: %v\n%s\n", pruneErr, pruneOutput)
	} else {
		GinkgoWriter.Println("âœ… Infrastructure images pruned")
	}

	GinkgoWriter.Println("âœ… Cleanup complete - all services stopped")
})

// getFirstFoundEnvTestBinaryDir locates the first binary in the specified path.
// ENVTEST-based tests depend on specific binaries, usually located in paths set by
// controller-runtime. When running tests directly (e.g., via an IDE) without using
// Makefile targets, the 'BinaryAssetsDirectory' must be explicitly configured.
func getFirstFoundEnvTestBinaryDir() string {
	basePath := filepath.Join("..", "..", "..", "bin", "k8s")
	entries, err := os.ReadDir(basePath)
	if err != nil {
		logf.Log.Error(err, "Failed to read directory", "path", basePath)
		return ""
	}
	for _, entry := range entries {
		if entry.IsDir() {
			return filepath.Join(basePath, entry.Name())
		}
	}
	return ""
}

// ============================================================================
// TEST HELPER FUNCTIONS (for parallel execution isolation)
// ============================================================================

// createTestNamespace creates a unique namespace for test isolation in parallel execution.
// MANDATORY per 03-testing-strategy.mdc: Each test must use unique identifiers.
func createTestNamespace(prefix string) string {
	ns := fmt.Sprintf("%s-%d", prefix, time.Now().UnixNano())
	namespace := &corev1.Namespace{
		ObjectMeta: metav1.ObjectMeta{
			Name: ns,
		},
	}
	Expect(k8sClient.Create(ctx, namespace)).To(Succeed())
	GinkgoWriter.Printf("âœ… Created test namespace: %s\n", ns)
	return ns
}

// deleteTestNamespace initiates namespace cleanup without blocking.
// Namespace deletion happens asynchronously - no need to wait since:
// 1. Each test uses unique namespace name (time.Now().UnixNano())
// 2. Cluster teardown (SynchronizedAfterSuite) handles final cleanup
// 3. No cross-test namespace conflicts due to unique naming
func deleteTestNamespace(ns string) {
	namespace := &corev1.Namespace{
		ObjectMeta: metav1.ObjectMeta{
			Name: ns,
		},
	}
	err := k8sClient.Delete(ctx, namespace)
	if err != nil && !apierrors.IsNotFound(err) {
		GinkgoWriter.Printf("âš ï¸  Warning: Failed to initiate deletion for namespace %s: %v\n", ns, err)
		return
	}

	GinkgoWriter.Printf("ðŸ—‘ï¸  Initiated async deletion for namespace: %s (cleanup continues in background)\n", ns)
}

// waitForRRPhase waits for a RemediationRequest to reach a specific phase.
func waitForRRPhase(name, namespace, expectedPhase string, timeout time.Duration) error { //nolint:unused
	return wait.PollImmediate(interval, timeout, func() (bool, error) {
		rr := &remediationv1.RemediationRequest{}
		err := k8sClient.Get(ctx, types.NamespacedName{Name: name, Namespace: namespace}, rr)
		if err != nil {
			return false, err
		}
		return string(rr.Status.OverallPhase) == expectedPhase, nil
	})
}

// waitForChildCRD waits for a child CRD to be created by RO.
func waitForChildCRD(name, namespace string, obj client.Object, timeout time.Duration) error { //nolint:unused
	return wait.PollImmediate(interval, timeout, func() (bool, error) {
		err := k8sClient.Get(ctx, types.NamespacedName{Name: name, Namespace: namespace}, obj)
		if err != nil {
			if apierrors.IsNotFound(err) {
				return false, nil // Keep waiting
			}
			return false, err
		}
		return true, nil
	})
}

// createRemediationRequest creates a RemediationRequest for testing.
func createRemediationRequest(namespace, name string) *remediationv1.RemediationRequest {
	now := metav1.Now()
	rr := &remediationv1.RemediationRequest{
		ObjectMeta: metav1.ObjectMeta{
			Name:      name,
			Namespace: namespace,
		},
		Spec: remediationv1.RemediationRequestSpec{
			// Valid 64-char hex fingerprint (SHA256 format per CRD validation)
			// UNIQUE per test to avoid routing deduplication (DD-RO-002)
			SignalFingerprint: fmt.Sprintf("%064x", time.Now().UnixNano()),
			SignalName:        "TestHighMemoryAlert",
			Severity:          "critical",
			SignalType:        "prometheus",
			TargetType:        "kubernetes",
			TargetResource: remediationv1.ResourceIdentifier{
				Kind:      "Deployment",
				Name:      "test-app",
				Namespace: namespace,
			},
			FiringTime:   now,
			ReceivedTime: now,
			Deduplication: sharedtypes.DeduplicationInfo{
				FirstOccurrence: now,
				LastOccurrence:  now,
				OccurrenceCount: 1,
			},
		},
	}
	Expect(k8sClient.Create(ctx, rr)).To(Succeed())
	GinkgoWriter.Printf("âœ… Created RemediationRequest: %s/%s\n", namespace, name)
	return rr
}

// updateAIAnalysisStatus updates the AIAnalysis status to simulate completion.
func updateAIAnalysisStatus(namespace, name string, phase string, workflow *aianalysisv1.SelectedWorkflow) error { //nolint:unused
	ai := &aianalysisv1.AIAnalysis{}
	if err := k8sClient.Get(ctx, types.NamespacedName{Name: name, Namespace: namespace}, ai); err != nil {
		return err
	}

	ai.Status.Phase = phase
	ai.Status.SelectedWorkflow = workflow
	if phase == "Completed" {
		now := metav1.Now()
		ai.Status.CompletedAt = &now
	}

	return k8sClient.Status().Update(ctx, ai)
}

// updateSPStatus updates the SignalProcessing status to simulate completion.
func updateSPStatus(namespace, name string, phase signalprocessingv1.SignalProcessingPhase) error {
	sp := &signalprocessingv1.SignalProcessing{}
	if err := k8sClient.Get(ctx, types.NamespacedName{Name: name, Namespace: namespace}, sp); err != nil {
		return err
	}

	sp.Status.Phase = phase
	if phase == signalprocessingv1.PhaseCompleted {
		now := metav1.Now()
		sp.Status.CompletionTime = &now
		// Set environment classification for downstream use
		// Per SP Team Response (2025-12-10): ClassifiedAt is REQUIRED when struct is set
		// V1.1 Note: Confidence field removed per DD-SP-001 V1.1 (redundant with source)
		sp.Status.EnvironmentClassification = &signalprocessingv1.EnvironmentClassification{
			Environment:  "production",
			Source:       "test",
			ClassifiedAt: now, // REQUIRED per SP CRD schema
		}
		// Per SP Team Response (2025-12-10): AssignedAt is REQUIRED when struct is set
		// V1.1 Note: Confidence field removed per DD-SP-001 V1.1 (redundant with source)
		sp.Status.PriorityAssignment = &signalprocessingv1.PriorityAssignment{
			Priority:   "P1",
			Source:     "test",
			AssignedAt: now, // REQUIRED per SP CRD schema
		}
	}

	return k8sClient.Status().Update(ctx, sp)
}

// ========================================
// Phase 1 Integration Test Helper Functions
// ========================================
// These helpers manually create child CRDs with proper owner references.
// In Phase 1 integration tests, only the RO controller runs - child
// controllers (SP, AA, WE) are NOT started. Tests manually control
// child CRD phases to validate RO's orchestration logic in isolation.
//
// Reference: RO_PHASE1_INTEGRATION_STRATEGY_IMPLEMENTED_DEC_19_2025.md

// createSignalProcessingCRD manually creates a SignalProcessing CRD for a RemediationRequest.
// Used in Phase 1 integration tests where child controllers are not running.
func createSignalProcessingCRD(namespace string, rr *remediationv1.RemediationRequest) *signalprocessingv1.SignalProcessing { //nolint:unused
	return &signalprocessingv1.SignalProcessing{
		ObjectMeta: metav1.ObjectMeta{
			Name:      "sp-" + rr.Name,
			Namespace: namespace,
			OwnerReferences: []metav1.OwnerReference{
				{
					APIVersion:         remediationv1.GroupVersion.String(),
					Kind:               "RemediationRequest",
					Name:               rr.Name,
					UID:                rr.UID,
					Controller:         ptr.To(true),
					BlockOwnerDeletion: ptr.To(true),
				},
			},
			Labels: map[string]string{
				"kubernaut.ai/remediation-request": rr.Name,
				"kubernaut.ai/component":           "signal-processing",
			},
		},
		Spec: signalprocessingv1.SignalProcessingSpec{
			RemediationRequestRef: signalprocessingv1.ObjectReference{
				APIVersion: remediationv1.GroupVersion.String(),
				Kind:       "RemediationRequest",
				Name:       rr.Name,
				Namespace:  namespace,
				UID:        string(rr.UID),
			},
			Signal: signalprocessingv1.SignalData{
				Fingerprint: rr.Spec.SignalFingerprint,
				Name:        rr.Spec.SignalName,
				Severity:    rr.Spec.Severity,
				Type:        rr.Spec.SignalType,
				TargetType:  rr.Spec.TargetType,
				TargetResource: signalprocessingv1.ResourceIdentifier{
					Kind:      rr.Spec.TargetResource.Kind,
					Name:      rr.Spec.TargetResource.Name,
					Namespace: rr.Spec.TargetResource.Namespace,
				},
				ReceivedTime: metav1.Now(),
			},
		},
	}
}

// createAIAnalysisCRD manually creates an AIAnalysis CRD for a RemediationRequest.
// Used in Phase 1 integration tests where child controllers are not running.
func createAIAnalysisCRD(namespace string, rr *remediationv1.RemediationRequest) *aianalysisv1.AIAnalysis { //nolint:unused
	return &aianalysisv1.AIAnalysis{
		ObjectMeta: metav1.ObjectMeta{
			Name:      "ai-" + rr.Name,
			Namespace: namespace,
			OwnerReferences: []metav1.OwnerReference{
				{
					APIVersion:         remediationv1.GroupVersion.String(),
					Kind:               "RemediationRequest",
					Name:               rr.Name,
					UID:                rr.UID,
					Controller:         ptr.To(true),
					BlockOwnerDeletion: ptr.To(true),
				},
			},
			Labels: map[string]string{
				"kubernaut.ai/remediation-request": rr.Name,
				"kubernaut.ai/component":           "ai-analysis",
			},
		},
		Spec: aianalysisv1.AIAnalysisSpec{
			RemediationRequestRef: corev1.ObjectReference{
				APIVersion: remediationv1.GroupVersion.String(),
				Kind:       "RemediationRequest",
				Name:       rr.Name,
				Namespace:  namespace,
				UID:        rr.UID,
			},
			RemediationID: string(rr.UID),
			AnalysisRequest: aianalysisv1.AnalysisRequest{
				SignalContext: aianalysisv1.SignalContextInput{
					Fingerprint:      rr.Spec.SignalFingerprint,
					Severity:         rr.Spec.Severity,
					SignalType:       rr.Spec.SignalType,
					BusinessPriority: "P1",   // Required: business priority
					Environment:      "test", // Required: environment classification
				},
				AnalysisTypes: []string{"recommendation"}, // Required: type of analysis
			},
			IsRecoveryAttempt: false,
		},
	}
}

// createWorkflowExecutionCRD manually creates a WorkflowExecution CRD for a RemediationRequest.
// Used in Phase 1 integration tests where child controllers are not running.
func createWorkflowExecutionCRD(namespace string, rr *remediationv1.RemediationRequest, workflowID string) *workflowexecutionv1.WorkflowExecution { //nolint:unused
	return &workflowexecutionv1.WorkflowExecution{
		ObjectMeta: metav1.ObjectMeta{
			GenerateName: "wfe-" + rr.Name + "-",
			Namespace:    namespace,
			OwnerReferences: []metav1.OwnerReference{
				{
					APIVersion:         remediationv1.GroupVersion.String(),
					Kind:               "RemediationRequest",
					Name:               rr.Name,
					UID:                rr.UID,
					Controller:         ptr.To(true),
					BlockOwnerDeletion: ptr.To(true),
				},
			},
			Labels: map[string]string{
				"kubernaut.ai/remediation-request": rr.Name,
				"kubernaut.ai/component":           "workflow-execution",
			},
		},
		Spec: workflowexecutionv1.WorkflowExecutionSpec{
			RemediationRequestRef: corev1.ObjectReference{
				APIVersion: remediationv1.GroupVersion.String(),
				Kind:       "RemediationRequest",
				Name:       rr.Name,
				Namespace:  namespace,
				UID:        rr.UID,
			},
			WorkflowRef: workflowexecutionv1.WorkflowRef{
				WorkflowID:     workflowID,
				Version:        "v1",
				ContainerImage: "test/" + workflowID + ":v1",
			},
			TargetResource: fmt.Sprintf("%s/%s/%s", rr.Spec.TargetResource.Namespace, rr.Spec.TargetResource.Kind, rr.Spec.TargetResource.Name),
			Parameters:     map[string]string{},
			Confidence:     0.9,
			Rationale:      "Test workflow for integration testing",
		},
	}
}

// GenerateTestFingerprint creates a unique 64-character fingerprint for tests.
// This prevents test pollution where multiple tests using the same hardcoded fingerprint
// cause the routing engine to see failures from other tests (BR-ORCH-042, DD-RO-002).
func GenerateTestFingerprint(namespace string, suffix ...string) string {
	input := namespace
	if len(suffix) > 0 {
		input += "-" + suffix[0]
	}
	hash := sha256.Sum256([]byte(input))
	return hex.EncodeToString(hash[:])[:64]
}
