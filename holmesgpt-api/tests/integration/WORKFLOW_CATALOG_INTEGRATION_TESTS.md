# Workflow Catalog Integration Tests

**Business Requirement**: BR-STORAGE-013 - Semantic Search for Remediation Workflows
**Design Decisions**: DD-WORKFLOW-002, DD-STORAGE-008, DD-WORKFLOW-004, DD-TEST-001

---

## ğŸ¯ **Overview**

Comprehensive integration tests for the Workflow Catalog toolset with real Data Storage Service, PostgreSQL, pgvector, and Embedding Service.

### **What These Tests Validate:**

1. âœ… **End-to-End Workflow Search** - Complete search flow with semantic similarity
2. âœ… **Hybrid Scoring** - Label boost/penalty calculations (DD-WORKFLOW-004)
3. âœ… **Empty Results Handling** - Graceful handling when no workflows match
4. âœ… **Filter Validation** - Mandatory and optional label filtering (DD-LLM-001)
5. âœ… **Top-K Limiting** - Result count validation
6. âœ… **Error Handling** - Service unavailable scenarios

---

## ğŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HolmesGPT API Workflow Catalog Toolset (Python)            â”‚
â”‚ - Tests in: test_workflow_catalog_data_storage_integration.py â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ HTTP POST /api/v1/workflows/search
                        â”‚ Port 18090 (DD-TEST-001)
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Storage Service (Go)                                   â”‚
â”‚ - Two-phase semantic search                                 â”‚
â”‚ - Hybrid weighted scoring                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                               â”‚
        â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL 16    â”‚          â”‚ Embedding Serviceâ”‚
â”‚ + pgvector       â”‚          â”‚ (Python)         â”‚
â”‚ Port: 15433      â”‚          â”‚ Port: 18000      â”‚
â”‚ 5 test workflows â”‚          â”‚ all-MiniLM-L6-v2 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ **Prerequisites**

### **Required:**
- Docker or Podman installed and running
- Python 3.8+ with pytest
- 4GB+ RAM available for containers
- Ports available: 15433, 16380, 18000, 18090

### **Optional:**
- `curl` for manual API testing
- `psql` for database inspection

---

## ğŸš€ **Quick Start**

### **Infrastructure Management (Pure Python - Refactored Dec 26 2025)**

Infrastructure is now managed **automatically by pytest fixtures** in `conftest.py`. This provides:
- âœ… **Consistency**: Same pattern as Go services (framework manages infrastructure)
- âœ… **Simplicity**: No external shell scripts needed
- âœ… **Automatic Cleanup**: Infrastructure tears down after test session
- âœ… **Better Debugging**: Python errors propagate cleanly to pytest

### **Run Integration Tests**

```bash
cd /path/to/kubernaut
make test-integration-holmesgpt
```

**Or directly with pytest:**
```bash
cd holmesgpt-api
python3 -m pytest tests/integration/test_workflow_catalog_data_storage_integration.py -v
```

**What happens automatically:**
1. âœ… Pytest fixtures clean up stale containers (if any)
2. âœ… Start PostgreSQL, Redis, and Data Storage Service
3. âœ… Wait for services to be healthy
4. âœ… Run integration tests
5. âœ… Automatically teardown infrastructure and prune images

**Expected output:**
```
ğŸš€ Starting HAPI integration infrastructure...
   Using: podman-compose
âœ… Containers started
â³ Waiting for services to be healthy...
âœ… All services healthy

tests/integration/test_workflow_catalog_data_storage_integration.py::TestWorkflowCatalogEndToEnd::test_semantic_search_with_exact_match_br_storage_013 PASSED
tests/integration/test_workflow_catalog_data_storage_integration.py::TestWorkflowCatalogEndToEnd::test_hybrid_scoring_with_label_boost_dd_workflow_004 PASSED
tests/integration/test_workflow_catalog_data_storage_integration.py::TestWorkflowCatalogEndToEnd::test_empty_results_handling_br_hapi_250 PASSED
tests/integration/test_workflow_catalog_data_storage_integration.py::TestWorkflowCatalogEndToEnd::test_filter_validation_dd_llm_001 PASSED
tests/integration/test_workflow_catalog_data_storage_integration.py::TestWorkflowCatalogEndToEnd::test_top_k_limiting_br_hapi_250 PASSED
tests/integration/test_workflow_catalog_data_storage_integration.py::TestWorkflowCatalogEndToEnd::test_error_handling_service_unavailable_br_storage_013 PASSED

======================== 6 passed ========================

ğŸ›‘ Stopping HAPI integration infrastructure...
âœ… Infrastructure stopped
ğŸ§¹ Pruning infrastructure images...
âœ… Infrastructure images pruned
```

---

## ğŸ§ª **Test Data**

The integration tests use 5 pre-configured workflows:

| Workflow ID | Signal Type | Severity | Resource Mgmt | Success Rate |
|-------------|-------------|----------|---------------|--------------|
| `oomkill-increase-memory-limits` | OOMKilled | critical | gitops (argocd) | 85% |
| `oomkill-scale-down-replicas` | OOMKilled | high | manual | 80% |
| `crashloop-fix-configuration` | CrashLoopBackOff | high | gitops (flux) | 75% |
| `node-not-ready-drain-and-reboot` | NodeNotReady | critical | manual | 90% |
| `image-pull-backoff-fix-credentials` | ImagePullBackOff | high | gitops (argocd) | 88% |

### **Test Data Schema (DD-STORAGE-008):**

```json
{
  "workflow_id": "oomkill-increase-memory-limits",
  "version": "1.0.0",
  "title": "OOMKill Remediation - Increase Memory Limits",
  "description": "Increases memory limits for pods...",
  "labels": {
    "signal-type": "OOMKilled",
    "severity": "critical",
    "resource-management": "gitops",
    "gitops-tool": "argocd",
    "environment": "production",
    "business-category": "infrastructure",
    "priority": "p0",
    "risk-tolerance": "low"
  },
  "parameters": {...},
  "steps": [...],
  "estimated_duration": "10 minutes",
  "success_rate": 0.85,
  "embedding": [768-dimensional vector],
  "enabled": true
}
```

---

## ğŸ”§ **Manual Testing**

### **Check Service Health:**

```bash
# Data Storage Service
curl http://localhost:18090/health

# Embedding Service
curl http://localhost:18000/health
```

### **Query Database Directly:**

```bash
docker exec -it kubernaut-postgres-integration psql -U kubernaut -d kubernaut_test

# List workflows
SELECT workflow_id, version, title, labels->>'signal-type'
FROM workflow_catalog;

# Check embeddings
SELECT workflow_id, array_length(embedding, 1) as embedding_dim
FROM workflow_catalog;
```

### **Test Data Storage API:**

```bash
curl -X POST http://localhost:18090/api/v1/workflows/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "OOMKilled critical",
    "filters": {
      "signal-type": "OOMKilled",
      "severity": "critical"
    },
    "top_k": 5,
    "min_similarity": 0.7
  }' | jq
```

---

## ğŸ“Š **Port Allocation (DD-TEST-001)**

Integration tests use dedicated port ranges to avoid conflicts:

| Service | Internal Port | External Port | Purpose |
|---------|---------------|---------------|---------|
| PostgreSQL | 5432 | 15433 | Database with pgvector |
| Redis | 6379 | 16380 | Caching |
| Embedding Service | 8000 | 18000 | Embedding generation |
| Data Storage Service | 8080 | 18090 | Workflow search API |

---

## ğŸ› **Troubleshooting**

### **Services Won't Start:**

```bash
# Check if ports are in use
lsof -i :15433
lsof -i :16380
lsof -i :18000
lsof -i :18090

# View container logs
docker-compose -f docker-compose.workflow-catalog.yml logs -f
```

### **Tests Fail with Connection Error:**

```bash
# Verify services are running
docker ps | grep kubernaut

# Check service health
curl http://localhost:18090/health
curl http://localhost:18000/health
```

### **No Test Data Found:**

```bash
# Check database
docker exec kubernaut-postgres-integration psql -U kubernaut -d kubernaut_test -c "SELECT COUNT(*) FROM workflow_catalog;"

# Re-run init script
docker exec kubernaut-postgres-integration psql -U kubernaut -d kubernaut_test -f /docker-entrypoint-initdb.d/init-db.sql
```

### **Embedding Generation Slow:**

First-time embedding generation can take 30-60 seconds as the model downloads and initializes. Subsequent searches use cached embeddings.

---

## ğŸ“ **File Structure**

```
holmesgpt-api/tests/integration/
â”œâ”€â”€ conftest.py                                        # Pytest fixtures (infrastructure management)
â”œâ”€â”€ test_workflow_catalog_data_storage_integration.py  # Integration tests
â”œâ”€â”€ docker-compose.workflow-catalog.yml                # Docker services config
â”œâ”€â”€ data-storage-integration.yaml                      # Data Storage config
â”œâ”€â”€ init-db.sql                                        # Database schema
â”œâ”€â”€ fixtures/                                          # Test data fixtures
â”‚   â””â”€â”€ workflow_fixtures.py                           # Workflow bootstrap data
â””â”€â”€ WORKFLOW_CATALOG_INTEGRATION_TESTS.md             # This file
```

---

## ğŸ“ **Design Decisions**

- **DD-WORKFLOW-002 v2.0**: MCP Workflow Catalog Architecture
- **DD-LLM-001**: MCP Workflow Search Parameter Taxonomy
- **DD-STORAGE-008**: Workflow Catalog Schema
- **DD-WORKFLOW-004**: Hybrid Weighted Label Scoring
- **DD-TEST-001**: Port Allocation Strategy

---

## âœ… **Success Criteria**

Integration tests are considered successful when:

- âœ… All 6 tests pass
- âœ… Services start within 60 seconds
- âœ… Test data is bootstrapped (5 workflows)
- âœ… Semantic search returns relevant results
- âœ… Hybrid scoring calculations are correct
- âœ… Empty results handled gracefully
- âœ… Filters applied correctly
- âœ… Top-k limiting works
- âœ… Error handling is robust

---

## ğŸš€ **CI/CD Integration**

### **GitHub Actions Example:**

```yaml
name: Integration Tests

on: [push, pull_request]

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Podman
        run: |
          sudo apt-get update
          sudo apt-get install -y podman podman-compose

      - name: Install dependencies
        run: |
          cd holmesgpt-api
          pip install -r requirements.txt
          pip install -r requirements-test.txt

      - name: Run integration tests
        run: |
          cd kubernaut
          make test-integration-holmesgpt
        # Note: Infrastructure setup/teardown handled automatically by pytest fixtures
```

---

## ğŸ“Š **Performance Benchmarks**

Expected performance (on modern laptop):

| Metric | Target | Typical |
|--------|--------|---------|
| Service startup | < 60s | ~45s |
| First search (with embedding gen) | < 10s | ~5s |
| Subsequent searches | < 2s | ~500ms |
| Test suite execution | < 30s | ~20s |

---

## ğŸ‰ **Summary**

These integration tests provide comprehensive validation of the Workflow Catalog toolset with real services, ensuring production-ready quality and reliability.

**Confidence**: 95%
**Coverage**: 6 critical test scenarios
**Automation**: Fully automated setup/teardown

