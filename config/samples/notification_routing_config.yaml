# Notification Routing Configuration - Spec-Field-Based Routing
#
# BR-NOT-065: Channel Routing Based on Spec Fields
# BR-NOT-066: Alertmanager-Compatible Configuration Format
# DD-WE-004: WorkflowExecution Exponential Backoff Skip Reasons
# BR-HAPI-200: Investigation Outcome Reporting
#
# Issue #91: Routing now uses spec fields + metadata instead of labels.
# Match keys correspond to spec field names (type, severity, phase,
# review-source, priority) and spec.metadata keys (skip-reason,
# investigation-outcome, environment, etc.).
#
# Use as a ConfigMap for the Notification Controller.
#
# Usage:
#   kubectl create configmap notification-routing-config \
#     --from-file=routing.yaml=notification_routing_config.yaml \
#     -n kubernaut-system
#
# Cross-Team References:
#   - NOTICE_WE_EXPONENTIAL_BACKOFF_DD_WE_004.md (Q7, Q8)
#   - NOTICE_INVESTIGATION_INCONCLUSIVE_BR_HAPI_200.md
#   - Spec fields set by RemediationOrchestrator (mandatory per BR-NOT-065)

# Global routing configuration (Alertmanager-compatible format)
route:
  # Group notifications by these attributes to reduce alert noise
  group_by:
    - environment
    - skip-reason
    - investigation-outcome
    - remediation-request

  # Wait time before sending first notification for a group
  group_wait: 30s

  # Time to wait before sending notification about new alerts in a group
  group_interval: 5m

  # Time to wait before re-sending a notification
  repeat_interval: 4h

  # Child routes - evaluated in order, first match wins
  routes:
    # =================================================================
    # CRITICAL: PreviousExecutionFailed (DD-WE-004)
    # =================================================================
    # Workflow ran and FAILED during execution.
    # Cluster state is UNKNOWN - manual intervention required.
    # Route to PagerDuty for immediate 24/7 alerting.
    #
    - match:
        skip-reason: PreviousExecutionFailed
      receiver: pagerduty-oncall-critical
      group_wait: 0s  # Send immediately
      repeat_interval: 15m  # Remind every 15 minutes

    # =================================================================
    # HIGH: ExhaustedRetries (DD-WE-004)
    # =================================================================
    # 5+ pre-execution failures - infrastructure issues.
    # Cluster state is KNOWN (unchanged) - team awareness required.
    # Route to Slack #ops for team awareness.
    #
    - match:
        skip-reason: ExhaustedRetries
      receiver: slack-ops-high
      group_wait: 1m
      repeat_interval: 1h

    # =================================================================
    # LOW: Temporary Conditions (DD-WE-004)
    # =================================================================
    # ResourceBusy: Another WFE is running on target (auto-resolves)
    # RecentlyRemediated: Cooldown/backoff period active (auto-resolves)
    # Route to console only (bulk notifications per BR-ORCH-034).
    #
    - match:
        skip-reason: ResourceBusy
      receiver: console-only-bulk
      group_wait: 5m
      group_interval: 30m

    - match:
        skip-reason: RecentlyRemediated
      receiver: console-only-bulk
      group_wait: 5m
      group_interval: 30m

    # =================================================================
    # SKIP: Resolved (BR-HAPI-200)
    # =================================================================
    # Alert self-resolved during HolmesGPT investigation.
    # No human action required - prevent alert fatigue.
    # Route to silent receiver (no delivery).
    #
    - match:
        investigation-outcome: resolved
      receiver: silent-noop
      repeat_interval: 168h  # 1 week (effectively disable repeats)

    # =================================================================
    # OPS: Investigation Inconclusive (BR-HAPI-200)
    # =================================================================
    # HolmesGPT could not determine root cause.
    # Human review required to understand the alert.
    # Route to Slack #ops for triage.
    #
    - match:
        investigation-outcome: inconclusive
      receiver: slack-ops-inconclusive
      group_wait: 1m
      repeat_interval: 2h

    # =================================================================
    # Production Critical (any notification type)
    # =================================================================
    # Catch-all for production environment critical notifications
    # that don't match specific skip-reason rules.
    #
    - match:
        environment: production
        severity: critical
      receiver: pagerduty-oncall-critical

    # =================================================================
    # Production High (escalation type)
    # =================================================================
    # Escalation notifications in production go to Slack ops.
    #
    - match:
        environment: production
        type: escalation
      receiver: slack-ops-high

    # =================================================================
    # Staging/Development (low priority)
    # =================================================================
    # Non-production notifications go to Slack #dev
    #
    - match:
        environment: staging
      receiver: slack-dev-low

    - match:
        environment: development
      receiver: slack-dev-low

    - match:
        environment: test
      receiver: slack-dev-low

  # Default fallback receiver (when no routes match)
  receiver: slack-default

# Receiver definitions
receivers:
  # ===================================================================
  # SILENT: No delivery (BR-HAPI-200 resolved alerts)
  # ===================================================================
  - name: silent-noop

  # ===================================================================
  # OPS: Slack for inconclusive investigations (BR-HAPI-200)
  # ===================================================================
  - name: slack-ops-inconclusive
    slack_configs:
      - channel: '#kubernaut-ops-triage'

  # ===================================================================
  # CRITICAL: PagerDuty for 24/7 on-call alerting
  # ===================================================================
  - name: pagerduty-oncall-critical
    pagerduty_configs:
      - service_key: ${PAGERDUTY_CRITICAL_SERVICE_KEY}
        severity: critical

  # ===================================================================
  # HIGH: Slack #ops for team awareness
  # ===================================================================
  - name: slack-ops-high
    slack_configs:
      - channel: '#kubernaut-ops'

  # ===================================================================
  # LOW: Console only for bulk notifications
  # ===================================================================
  - name: console-only-bulk
    console_configs:
      - enabled: true

  # ===================================================================
  # MEDIUM: Slack for dev environments
  # ===================================================================
  - name: slack-dev-low
    slack_configs:
      - channel: '#kubernaut-dev'

  # ===================================================================
  # DEFAULT: Slack fallback
  # ===================================================================
  - name: slack-default
    slack_configs:
      - channel: '#kubernaut-alerts'
