# Vector Database Configuration Examples
# This file demonstrates different vector database configurations for AI-driven pattern recognition

# Example 1: PostgreSQL with pgvector (Recommended for production)
app:
  name: "kubernaut"
  version: "1.0.0"

database:
  enabled: true
  host: "localhost"
  port: "5432"
  database: "prometheus_alerts"
  username: "alerts_user"
  password: "secure_password"
  sslMode: "require"

# Vector Database Configuration
vectordb:
  enabled: true
  backend: "postgresql"  # Use PostgreSQL with pgvector extension

  embedding_service:
    service: "local"     # Use local embedding generation (no external dependencies)
    dimension: 384       # Dimension for sentence-transformers/all-MiniLM-L6-v2
    model: "all-MiniLM-L6-v2"

  postgresql:
    use_main_db: true    # Use same database as main application
    index_lists: 100     # IVFFlat index parameter (good for up to 100K vectors)

  cache:
    enabled: true
    ttl: "1h"           # Cache embeddings for 1 hour
    max_size: 5000      # Maximum cached embeddings
    cache_type: "memory"

# SLM Configuration (required for AI-driven features)
slm:
  endpoint: "http://localhost:8080"
  model: "granite-3.0-8b-instruct"
  provider: "localai"
  timeout: "60s"
  temperature: 0.1
  max_tokens: 2000

# Example effectiveness configuration with vector features
monitoring:
  effectiveness:
    enabled: true
    vector_similarity_threshold: 0.7  # Minimum similarity for pattern matching
    pattern_discovery_enabled: true   # Enable automatic pattern discovery
    ai_insights_enabled: true         # Enable AI-powered insights
    batch_processing: true            # Process patterns in batches for efficiency

---

# Example 2: Development/Testing with Memory Backend
app:
  name: "kubernaut-dev"

vectordb:
  enabled: true
  backend: "memory"     # In-memory storage (data lost on restart)

  embedding_service:
    service: "local"
    dimension: 384

  cache:
    enabled: false      # No need for cache with memory backend

slm:
  endpoint: "http://localhost:11434"
  model: "llama2"
  provider: "ollama"

---

# Example 3: Disabled Vector Features (Fallback Mode)
app:
  name: "kubernaut-basic"

vectordb:
  enabled: false        # Disable vector database features

# System will work without AI pattern recognition but with basic functionality

---

# Example 4: Future Pinecone Configuration (Not implemented yet)
# vectordb:
#   enabled: true
#   backend: "pinecone"
#
#   embedding_service:
#     service: "openai"
#     dimension: 1536
#     model: "text-embedding-ada-002"
#     api_key: "${OPENAI_API_KEY}"
#
#   pinecone:
#     api_key: "${PINECONE_API_KEY}"
#     environment: "us-west1-gcp"
#     index_name: "prometheus-alerts"
#     namespace: "production"

# Environment Variables for Secure Configuration:
# - OPENAI_API_KEY: OpenAI API key for embedding generation
# - PINECONE_API_KEY: Pinecone API key for vector database
# - DATABASE_PASSWORD: Database password
# - SLM_API_KEY: SLM service API key
