---
alwaysApply: true
globs: "**/*,pkg/ai/**/*,test/**/*ai*"
description: "Core development methodology: principles, TDD phases, and AI-specific patterns"
---
# Core Development Methodology

## ðŸš¨ **MANDATORY PRINCIPLES**

### Critical Decision Process
**MANDATORY**: Ask for input on ALL critical decisions including:
- Architecture changes and design patterns
- New dependencies or external integrations
- Performance trade-offs and optimization decisions
- Security implementations and access controls
- Refactoring that affects system complexity

**Format**: Provide recommendation with detailed justification when asking for input.

### Business Requirements Mandate
**MANDATORY**: Every code change must be backed by at least ONE business requirement (BR-[CATEGORY]-[NUMBER] format, e.g., BR-WORKFLOW-001, BR-AI-056).
- All tests must map to specific business requirements
- All implementation code must serve documented business needs
- No speculative or "nice to have" code without business backing
- Business requirements dictate functionality; technical patterns enable business logic

### Standard Business Requirement Categories
**Format**: `BR-[CATEGORY]-[NUMBER]` where NUMBER is zero-padded 3 digits (001, 002, etc.)

| Category | Purpose | Examples |
|----------|---------|----------|
| **WORKFLOW** | Core workflow orchestration and automation | BR-WORKFLOW-001, BR-WORKFLOW-002 |
| **AI** | AI/ML functionality and intelligence features | BR-AI-001, BR-AI-056 |
| **INTEGRATION** | Cross-component and external service integration | BR-INTEGRATION-001, BR-INTEGRATION-002 |
| **SECURITY** | Security features and access controls | BR-SECURITY-001, BR-SECURITY-002 |
| **PLATFORM** | Kubernetes and infrastructure platform features | BR-PLATFORM-001, BR-PLATFORM-002 |
| **API** | API endpoints and external interfaces | BR-API-001, BR-API-002 |
| **STORAGE** | Data persistence and storage features | BR-STORAGE-001, BR-STORAGE-002 |
| **MONITORING** | Observability, metrics, and monitoring | BR-MONITORING-001, BR-MONITORING-002 |
| **SAFETY** | Safety frameworks and validation | BR-SAFETY-001, BR-SAFETY-002 |
| **PERFORMANCE** | Performance optimization and scalability | BR-PERFORMANCE-001, BR-PERFORMANCE-002 |

### Business Requirement Validation
```bash
# Validate BR format
# Business requirement validation during APDC Analysis phase

# Check BR category is valid
echo "BR-WORKFLOW-001" | grep -E "^BR-(WORKFLOW|AI|INTEGRATION|SECURITY|PLATFORM|API|STORAGE|MONITORING|SAFETY|PERFORMANCE)-[0-9]{3}$"

# Verify BR documentation exists
find docs/requirements/ -name "*BR-[CATEGORY]-[NUMBER]*" -type f
```

## ðŸ§ª **APDC-Enhanced TDD Methodology - MANDATORY SEQUENCE**

### Analysis-Plan-Do-Check (APDC) Framework Integration
**PRINCIPLE**: Systematic development through structured phases that enhance TDD methodology

#### APDC Phase Overview
| Phase | Duration | Purpose | TDD Integration |
|-------|----------|---------|-----------------|
| **Analysis** | 5-15 min | Comprehensive context understanding | Enhances Discovery phase |
| **Plan** | 10-20 min | Detailed implementation strategy | Structures RED-GREEN-REFACTOR approach |
| **Do** | Variable | Controlled implementation execution | Executes TDD phases with validation |
| **Check** | 5-10 min | Comprehensive result validation | Extends TDD validation with business verification |

### Enhanced TDD Workflow - REQUIRED
1. **ANALYSIS**: Comprehensive context and impact assessment
2. **PLAN**: Detailed implementation strategy with TDD phase mapping
3. **DO-RED**: Write unit tests defining business contract (aim for 70%+ coverage)
4. **DO-GREEN**: Define business interfaces and minimal implementation
5. **DO-REFACTOR**: Enhance existing code with sophisticated logic
6. **CHECK**: Comprehensive validation and confidence assessment
7. **NEVER**: Use `Skip()` to avoid test failures or bypass APDC phases

### Defense-in-Depth Testing Requirements
**MANDATORY**: Follow pyramid testing strategy from [03-testing-strategy.mdc](mdc:.cursor/rules/03-testing-strategy.mdc):
- **Unit Tests**: 70%+ coverage using real business logic with external mocks only
- **Integration Tests**: <20% coverage for component interactions requiring infrastructure
- **E2E Tests**: <10% coverage for critical user journeys only

## ðŸ” **APDC Phase Specifications - MANDATORY SEQUENCE**

### Analysis Phase - COMPREHENSIVE CONTEXT UNDERSTANDING
**Duration**: 5-15 minutes
**Purpose**: Systematic evaluation before any implementation
**Prevention**: Systematic evaluation checklist before implementation

## ðŸš« **IRONCLAD ANALYSIS PHASE - BLOCKING REQUIREMENTS**

#### **MANDATORY ANALYSIS QUESTIONS (ALL REQUIRED)**:
1. **Business Context** - Does this solve a documented business requirement (BR-[CATEGORY]-[NUMBER])?
2. **Technical Context** - What existing implementations already solve similar problems?
3. **Integration Context** - How will this integrate with existing main applications?
4. **Complexity Assessment** - Is this the simplest approach that meets the business need?

#### **ðŸš« BLOCKING REQUIREMENT - AI MUST EXECUTE BEFORE ANY CODE**:

<function_calls>
<invoke name="Task">
<parameter name="subagent_type">general-purpose</parameter>
<parameter name="description">Comprehensive existing implementation analysis</parameter>
<parameter name="prompt">Search the entire codebase for existing implementations similar to [USER_REQUIREMENT]. Find components in pkg/, integration patterns in cmd/, and established approaches.</parameter>
</invoke>
</function_calls>

<function_calls>
<invoke name="Grep">
<parameter name="pattern">[ComponentType]</parameter>
<parameter name="path">pkg/</parameter>
<parameter name="output_mode">files_with_matches</parameter>
</invoke>
</function_calls>

<function_calls>
<invoke name="Grep">
<parameter name="pattern">[ComponentType]</parameter>
<parameter name="path">cmd/</parameter>
<parameter name="output_mode">content</parameter>
</invoke>
</function_calls>

```
âœ… ANALYSIS PHASE CHECKPOINT:
- [ ] Business requirement (BR-XXX-XXX) identified and validated âœ…/âŒ
- [ ] Existing implementation search executed âœ…/âŒ
- [ ] Technical context fully documented âœ…/âŒ
- [ ] Integration patterns discovered âœ…/âŒ
- [ ] Complexity assessment completed âœ…/âŒ

âŒ STOP: Cannot proceed to PLAN phase until ALL checkboxes are âœ…
```

**ðŸš« MANDATORY USER APPROVAL GATE - ANALYSIS PHASE:**
```
ðŸŽ¯ ANALYSIS PHASE SUMMARY:
Business Requirement: [BR-XXX-XXX with justification]
Existing Solutions: [N components found with file paths]
Integration Points: [M main app patterns discovered]
Complexity Level: [SIMPLE/MEDIUM/COMPLEX with evidence]
Recommended Approach: [enhance existing/create new with justification]

â“ **MANDATORY APPROVAL**: Do you approve this analysis and approach? (YES/NO)
```

#### Analysis Deliverables - MANDATORY (Tool-Verified)
1. **Business Context**: BR-[CATEGORY]-[NUMBER] alignment and business value assessment
2. **Technical Context**: Existing implementations, dependencies, integration points (from tool execution)
3. **Impact Assessment**: Files affected, cascade effects, performance implications
4. **Risk Evaluation**: Complexity level, potential breaking changes, mitigation needs

**RULE VIOLATION DETECTION**:
If ANY checkbox is âŒ â†’ "ðŸš¨ ANALYSIS PHASE VIOLATION: Implementation attempted without complete analysis - DEVELOPMENT STOPPED"
If NO user approval â†’ "ðŸš¨ ANALYSIS APPROVAL VIOLATION: Plan phase attempted without user approval - DEVELOPMENT STOPPED"

### Plan Phase - DETAILED IMPLEMENTATION STRATEGY
**Duration**: 10-20 minutes
**Purpose**: Structured approach to implementation with clear success criteria
**Prevention**: Strategic planning before implementation to avoid rework

## ðŸš« **IRONCLAD PLAN PHASE - BLOCKING REQUIREMENTS**

#### **MANDATORY PLAN ELEMENTS (ALL REQUIRED)**:
1. **TDD Strategy** - Which interfaces will you enhance vs create? Where will tests live?
2. **Integration Plan** - Which main app files will instantiate your component?
3. **Success Definition** - What business outcome proves this works?
4. **Risk Mitigation** - What's the simplest implementation that could work?
5. **Timeline** - RED (10-15min) â†’ GREEN (15-20min) â†’ REFACTOR (20-30min)

```
âœ… PLAN PHASE CHECKPOINT:
- [ ] TDD strategy defined with specific interfaces âœ…/âŒ
- [ ] Integration plan specifies exact cmd/ files âœ…/âŒ
- [ ] Success criteria are measurable and testable âœ…/âŒ
- [ ] Risk mitigation strategies documented âœ…/âŒ
- [ ] Timeline realistic with phase breakdown âœ…/âŒ

âŒ STOP: Cannot proceed to DO phase until ALL checkboxes are âœ…
```

**ðŸš« MANDATORY USER APPROVAL GATE - PLAN PHASE:**
```
ðŸŽ¯ PLAN PHASE SUMMARY:
TDD Strategy: [enhance [ExistingInterface] vs create new, tests in [TestLocation]]
Integration Plan: [specific files: cmd/app1/main.go, cmd/app2/main.go]
Success Definition: [BR-XXX-XXX outcome: specific measurable behavior]
Risk Mitigation: [identified risks with specific mitigation strategies]
Timeline: [RED: Xmin â†’ GREEN: Ymin â†’ REFACTOR: Zmin]

â“ **MANDATORY APPROVAL**: Do you approve this implementation plan? (YES/NO)
```

#### Plan Deliverables - MANDATORY (User-Approved)
1. **Implementation Strategy**: TDD phase breakdown with specific actions
2. **Timeline Estimation**: Realistic duration for each phase
3. **Success Criteria**: Measurable outcomes and validation checkpoints
4. **Risk Mitigation**: Specific strategies for identified risks
5. **Rollback Plan**: Recovery procedures if implementation fails

**RULE VIOLATION DETECTION**:
If ANY checkbox is âŒ â†’ "ðŸš¨ PLAN PHASE VIOLATION: DO phase attempted without complete planning - DEVELOPMENT STOPPED"
If NO user approval â†’ "ðŸš¨ PLAN APPROVAL VIOLATION: DO phase attempted without user approval - DEVELOPMENT STOPPED"

### Do Phase - CONTROLLED TDD EXECUTION
**Duration**: Variable (based on complexity)
**Purpose**: Systematic implementation following TDD methodology with continuous validation
**Validation**: Continuous checkpoint validation throughout execution

#### Enhanced TDD Phase Decision Matrix
| Phase | Duration | Action | APDC Integration | Validation Tool |
|-------|----------|--------|------------------|----------------|
| **DO-DISCOVERY** | 5-10 min | Execute planned component research | Analysis-guided search | `codebase_search "existing [Component] implementations"` |
| **DO-RED** | 10-15 min | Write failing tests per plan | Plan-structured test creation | Built-in validation through TDD |
| **DO-GREEN** | 15-20 min | Minimal implementation + integration | Plan-guided implementation | Built-in validation through integration |
| **DO-REFACTOR** | 20-30 min | Enhance existing code per plan | Plan-structured enhancement | Built-in validation through enhancement |

### Check Phase - COMPREHENSIVE RESULT VALIDATION
**Duration**: 5-10 minutes
**Purpose**: Systematic verification of implementation quality and business alignment
**Prevention**: Built-in quality through systematic implementation approach

#### Check Phase - BUILT-IN QUALITY VERIFICATION
**Verify quality was built-in during implementation:**

1. **Business Alignment** - Does the implementation solve the planned BR-[CATEGORY]-[NUMBER]?
2. **Integration Success** - Is the component instantiated in the planned main app files?
3. **Test Coverage** - Do tests validate the business behavior, not just technical function?
4. **Simplicity** - Is this the simplest implementation that meets the business need?
5. **Documentation** - Is the business purpose clear to future developers?

#### Check Deliverables - MANDATORY
1. **Business Verification**: Confirmation that BR-[CATEGORY]-[NUMBER] requirements are met
2. **Technical Validation**: Build success, test passage, lint compliance
3. **Integration Confirmation**: Main application integration verified
4. **Performance Assessment**: Impact on system performance evaluated
5. **Confidence Rating**: 60-100% confidence with detailed justification

#### Discovery Phase - MANDATORY
```bash
# Component research before creation
codebase_search "existing [ComponentType] implementations in pkg/"
grep -r "[Component]" cmd/ pkg/workflow/ --include="*.go"

# Decision point: enhance vs create (requires justification)
```

#### TDD RED Phase - MANDATORY
```bash
# Import existing business interfaces
# Call existing methods with expected signatures
# Validation: Tests MUST fail initially
go test ./path/to/test.go 2>&1 | grep "FAIL" || echo "âŒ Tests not failing"
```

#### TDD GREEN Phase - MANDATORY
```bash
# Minimal implementation + MANDATORY integration
# Component MUST appear in cmd/ applications
grep -r "NewComponent" cmd/ --include="*.go" || echo "âŒ Missing integration"
```

#### TDD REFACTOR Phase - MANDATORY
```bash
# Enhance existing code only (NO new types/methods/files)
# Integration MUST be preserved
git diff --cached | grep "^+type.*struct" && echo "âŒ New types forbidden in REFACTOR"
```

## ðŸ¤– **AI/ML Specific TDD - COMPREHENSIVE METHODOLOGY**

### AI TDD Phases

#### AI Discovery Phase (5-10 min)
**Action**: Use APDC Analysis phase discovery patterns
**Rule**: Search existing AI interfaces before creating new
**Mandatory Checks**:
```bash
# Check existing AI interfaces
grep -r "Client.*interface" pkg/ai/ --include="*.go"
# Check main app AI usage
grep -r "AI\|LLM\|Holmes" cmd/ --include="*.go"
# Decision point: enhance existing vs create new AI component
```

#### AI RED Phase (15-20 min)
**Rule**: Import existing AI interfaces (`pkg/ai/llm.Client`)
**Forbidden**: Creating new AI interfaces
**Validation**: Built-in through TDD RED phase design
**AI-Specific RED Pattern**:
```go
// âœ… CORRECT AI RED: Uses existing AI interface
var _ = Describe("AI Context Optimization", func() {
    var (
        llmClient llm.Client  // Existing interface
        ctx       context.Context
    )

    BeforeEach(func() {
        llmClient = testutil.NewMockLLMClient() // Existing factory
        ctx = context.Background()
    })

    It("should optimize context using AI analysis", func() {
        // Call existing AI interface method
        analysis, err := llmClient.AnalyzeContext(ctx, "test content")
        Expect(err).ToNot(HaveOccurred())
        Expect(analysis.Quality).To(BeNumerically(">", 0.8))
    })
})
```

#### AI GREEN Phase (20-25 min)
**Rule**: Enhance existing AI client (e.g., `ClientImpl`)
**Integration**: Add to main app (`cmd/*/main.go`)
**Forbidden**: New AI service files
**Validation**: Built-in through GREEN phase integration requirement
**AI-Specific GREEN Pattern**:
```go
// âœ… CORRECT AI GREEN: Enhance existing AI client
// In pkg/ai/llm/client.go
type Client interface {
    // ... existing methods ...
    AnalyzeContext(ctx context.Context, content string) (*ContextAnalysis, error) // ADD TO EXISTING
}

type ClientImpl struct {
    // ... existing fields ...
}

func (c *ClientImpl) AnalyzeContext(ctx context.Context, content string) (*ContextAnalysis, error) {
    // Minimal implementation to pass tests
    return &ContextAnalysis{Quality: 0.8}, nil
}
```

#### AI REFACTOR Phase (25-35 min)
**Rule**: Enhance same AI methods tests call
**REFACTOR NEVER MEANS**: Create new parallel/additional AI code
**Forbidden**: New AI types, files, interfaces
**Validation**: Built-in through REFACTOR phase enhancement focus
**AI-Specific REFACTOR Focus**:
```go
// âœ… CORRECT AI REFACTOR: Enhance existing method
func (c *ClientImpl) AnalyzeContext(ctx context.Context, content string) (*ContextAnalysis, error) {
    // Enhanced implementation with sophisticated logic
    tokens := c.tokenizer.Tokenize(content)
    embeddings := c.embeddingGenerator.Generate(tokens)
    quality := c.qualityAnalyzer.CalculateQuality(embeddings)

    return &ContextAnalysis{
        Quality: quality,
        TokenCount: len(tokens),
        OptimizationSuggestions: c.generateSuggestions(embeddings),
    }, nil
}
```

### AI Integration Conflict Resolution
**When AI rules conflict with general TDD**:
1. **AI Discovery** overrides general component discovery (AI-specific search patterns)
2. **AI Interface Reuse** overrides new interface creation (use `pkg/ai/llm.Client`)
3. **AI Client Enhancement** overrides new service creation (enhance existing clients)
4. **AI REFACTOR** focuses on method enhancement, not structural changes

### AI Integration Pattern
```go
// cmd/kubernaut/main.go
llmClient := llm.NewClient(config.LLM)
workflowEngine.SetLLMClient(llmClient)
processor := processor.New(llmClient, deps...)
```

### AI Mock Usage Decision Matrix
| Component | Action |
|-----------|--------|
| **External AI APIs** (HolmesGPT, OpenAI) | MOCK |
| **AI Business Logic** (analysis algorithms) | REAL |
| **Error Simulation** | MOCK |
| **Performance Testing** | MOCK |

## ðŸ’» **Code Quality Standards**

### Error Handling - MANDATORY
- **ALWAYS** handle errors, never ignore them
- **ALWAYS** add log entry for every error
- Use structured error types from [internal/errors/](mdc:internal/errors/)

### Type System Guidelines
- **AVOID** using `any` or `interface{}` unless absolutely necessary
- **ALWAYS** use structured field values with specific types
- **AVOID** local type definitions to resolve import cycles
- Use shared types from [pkg/shared/types/](mdc:pkg/shared/types/) instead

### Code Integration Requirements
- **MANDATORY**: Integrate all new business code with main code
- Remove any code not backed by business requirements
- Ensure seamless integration with existing architecture

## ðŸš¨ **MANDATORY REAL-TIME INTEGRATION CHECKPOINTS**

### **CHECKPOINT 1: Before Creating ANY New Type**
**TRIGGER**: About to type `type NewComponent struct` or `func NewComponent`
**MANDATORY ACTION**:
```bash
# HALT: Run this command BEFORE creating new type
grep -r "NewComponent\|ComponentName" cmd/ pkg/workflow/ pkg/processor/ pkg/api/
# RULE: If ZERO results, ask "Why isn't this enhancing existing code?"
```

### **CHECKPOINT 2: During TDD GREEN Phase**
**TRIGGER**: Tests are passing (GREEN phase complete)
**MANDATORY ACTION**:
```bash
# HALT: Verify integration BEFORE proceeding to REFACTOR
find cmd/ -name "*.go" -exec grep -l "YourNewComponent" {} \;
# RULE: Must show at least ONE main application file, or STOP and integrate
```

### **CHECKPOINT 3: After ANY Sophisticated Enhancement**
**TRIGGER**: Adding complex algorithms, ML features, or sophisticated logic
**MANDATORY ACTION**:
```bash
# HALT: Check main app instantiation
grep -r "New.*Optimizer\|New.*Engine\|New.*Builder" cmd/ --include="*.go"
# RULE: New sophisticated code MUST appear in main application startup
```

### **AUTOMATIC VIOLATION DETECTION**
Add to pre-commit hook:
```bash
#!/bin/bash
# Auto-detect orphaned business code
SOPHISTICATED_TYPES=$(grep -r "type.*Optimizer\|type.*Engine\|type.*Analyzer" pkg/ --include="*.go" | grep -v "_test.go")
for type_def in $SOPHISTICATED_TYPES; do
    TYPE_NAME=$(echo $type_def | grep -o "type [A-Za-z]*" | cut -d' ' -f2)
    MAIN_USAGE=$(grep -r "$TYPE_NAME" cmd/ --include="*.go" | wc -l)
    if [ "$MAIN_USAGE" -eq 0 ]; then
        echo "âŒ VIOLATION: Sophisticated type $TYPE_NAME not integrated in main applications"
        exit 1
    fi
done
```

## ðŸ“‹ **Anti-Patterns - FORBIDDEN**

### TDD Phase Violations
- **Discovery Skip**: Creating without searching existing â†’ Use `codebase_search` first
- **RED Skip**: Implementation without failing tests â†’ Write tests first
- **GREEN Complexity**: Sophisticated logic in GREEN â†’ Keep minimal, enhance in REFACTOR
- **REFACTOR Creation**: New types in REFACTOR â†’ Enhance existing only
- **Integration Delay**: Component not integrated in GREEN â†’ MANDATORY integration

### AI-Specific Anti-Patterns
- Creating parallel AI components during REFACTOR
- AI components only used in tests
- Hardcoded AI endpoints
- AI-only testing without business validation

### Testing Anti-Patterns
- **NULL-TESTING**: Weak assertions (not nil, > 0, empty checks)
- **IMPLEMENTATION TESTING**: Testing how instead of what business outcome
- **MOCK OVERUSE**: In integration tests - use real components when possible

## ðŸŽ¯ **Completion Requirements**

### Post-Development Checklist - MANDATORY
After completing any development task:

1. **Build Validation**: Code builds without errors from changes made
2. **Lint Compliance**: No new lint errors (unusedparam, unusedfunc, etc.)
3. **Business Integration**: Provide confidence assessment of business code integration
4. **Enhancement Proposals**: Suggest improvements with â‰¥60% confidence level

### Confidence Assessment Format - REQUIRED
Provide BOTH:
- **Simple Percentage**: 60-100% confidence rating
- **Detailed Justification**: Including risks, assumptions, and validation approach

Example:
```
Confidence Assessment: 85%
Justification: Implementation follows established patterns in pkg/workflow/engine/
and integrates cleanly with existing HolmesGPT client. Risk: Minor performance
impact on high-alert scenarios. Validation: Unit tests cover 90% of edge cases.
```

## ðŸ”§ **APDC-Enhanced Validation Commands**

### APDC Prevention Framework
**Built-in quality through systematic approach:**

**Analysis Prevention**: Start with clear business context and existing code understanding
**Plan Prevention**: Design integration and success criteria before coding
**Do Prevention**: Follow TDD phases with mandatory integration in GREEN
**Check Prevention**: Verify planned outcomes were achieved through implementation

### APDC Success Indicators
**Quality indicators built into the development process:**

**Analysis Success**: Clear business requirement mapped, existing solutions understood
**Plan Success**: Integration points identified, TDD phases planned with realistic timeline
**Do Success**: Tests written first, component integrated in GREEN, sophisticated logic in REFACTOR
**Check Success**: Business requirement solved, code integrated, quality built-in

### AI-Specific APDC Prevention
**AI development prevention through APDC integration:**

**AI Analysis**: Search existing AI interfaces before planning new ones
**AI Plan**: Plan to enhance existing AI clients rather than create new ones
**AI Do**: Follow TDD with existing interface reuse and main app integration
**AI Check**: Verify AI business value delivered through existing interface patterns

## âš¡ **APDC-Enhanced Quick Reference Checklist**

### Before any code submission - APDC Compliance:

#### Analysis Phase Completion:
- [ ] Business requirement mapped and analyzed (BR-[CATEGORY]-[NUMBER])
- [ ] Technical impact assessment completed
- [ ] Integration points identified and validated
- [ ] Risk and complexity evaluation documented

#### Plan Phase Completion:
- [ ] Implementation strategy defined with TDD phase mapping
- [ ] Timeline estimation and resource planning completed
- [ ] Success criteria established with measurable outcomes
- [ ] Risk mitigation strategies documented
- [ ] User approval received for implementation plan

#### Do Phase Completion:
- [ ] APDC-enhanced TDD workflow followed (Analysis â†’ Plan â†’ DO-RED â†’ DO-GREEN â†’ DO-REFACTOR)
- [ ] All tests written first, then implementation
- [ ] All errors handled and logged
- [ ] No lint or compilation errors
- [ ] Code integrated with main business logic
- [ ] Continuous validation checkpoints passed

#### Check Phase Completion:
- [ ] Business requirement fulfillment verified
- [ ] Integration testing validation completed
- [ ] Performance impact assessed
- [ ] Rule compliance confirmed
- [ ] Confidence assessment provided (60-100% with justification)
- [ ] Critical decisions escalated if needed
- [ ] AI components follow AI-specific APDC phases (if applicable)

### APDC Methodology Compliance:
- [ ] All four APDC phases executed in sequence
- [ ] Phase deliverables completed and documented
- [ ] Validation tools executed for each phase
- [ ] Business alignment maintained throughout process

## ðŸ”— **Integration Points**

This rule establishes mandatory methodology that controls:
- [01-project-structure.mdc](mdc:.cursor/rules/01-project-structure.mdc) - Architecture navigation
- [02-technical-implementation.mdc](mdc:.cursor/rules/02-technical-implementation.mdc) - Technical patterns
- [03-testing-strategy.mdc](mdc:.cursor/rules/03-testing-strategy.mdc) - Testing framework
- [05-kubernetes-safety.mdc](mdc:.cursor/rules/05-kubernetes-safety.mdc) - Safety patterns

**PRIORITY LEVEL**: 1 - FOUNDATIONAL (per [13-conflict-resolution-matrix.mdc](mdc:.cursor/rules/13-conflict-resolution-matrix.mdc))

**Authority**: APDC methodology framework - all other rules operate within this structure