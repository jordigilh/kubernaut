# Data Storage Service V1.0 MVP - Audit Trail & Playbook Catalog Triage

**Date**: November 13, 2025
**Status**: üö® **CRITICAL - MAJOR INCONSISTENCIES FOUND**
**Authority**: ADR-034 (Unified Audit Table), DD-CONTEXT-005 (Minimal LLM Response Schema)
**Scope**: V1.0 MVP foundations for both audit trail AND playbook catalog

---

## üéØ **Executive Summary**

**Critical Finding**: Data Storage Service documentation and implementation have **MAJOR inconsistencies** with authoritative architecture decisions (ADR-034, DD-CONTEXT-005).

**Impact**:
- ‚ùå **notification_audit** table exists (migration 010) but conflicts with ADR-034 unified audit table
- ‚ùå **No playbook_catalog** table exists (required by DD-CONTEXT-005)
- ‚ùå Implementation plan focuses on wrong features (audit embeddings vs playbook embeddings)
- ‚ùå Business requirements misaligned with V1.0 MVP scope

**Action Required**: **IMMEDIATE** - Align all documentation and implementation with ADR-034 and DD-CONTEXT-005.

**Confidence**: 98% (based on authoritative ADR-034 and DD-CONTEXT-005)

---

## üìã **Table of Contents**

1. [Audit Trail Inconsistencies](#audit-trail-inconsistencies)
2. [Playbook Catalog Gaps](#playbook-catalog-gaps)
3. [Implementation Plan Misalignment](#implementation-plan-misalignment)
4. [Migration Strategy](#migration-strategy)
5. [Corrective Actions](#corrective-actions)

---

## üö® **AUDIT TRAIL INCONSISTENCIES**

### **Issue #1: notification_audit Table Conflicts with ADR-034**

**Authoritative Source**: ADR-034 (Unified Audit Table Design)

**What ADR-034 Says**:
```sql
CREATE TABLE audit_events (
    event_id UUID PRIMARY KEY,
    event_type VARCHAR(100) NOT NULL,        -- 'gateway.signal.received'
    event_category VARCHAR(50) NOT NULL,     -- 'signal', 'remediation', 'workflow'
    event_action VARCHAR(50) NOT NULL,       -- 'received', 'processed', 'executed'
    event_outcome VARCHAR(20) NOT NULL,      -- 'success', 'failure', 'pending'
    actor_type VARCHAR(50) NOT NULL,
    actor_id VARCHAR(255) NOT NULL,
    resource_type VARCHAR(100) NOT NULL,
    resource_id VARCHAR(255) NOT NULL,
    correlation_id VARCHAR(255) NOT NULL,
    event_data JSONB NOT NULL,
    ...
) PARTITION BY RANGE (event_date);
```

**What Exists**: `notification_audit` table (migration 010)
```sql
CREATE TABLE notification_audit (
    id BIGSERIAL PRIMARY KEY,
    remediation_id VARCHAR(255) NOT NULL,
    notification_id VARCHAR(255) NOT NULL UNIQUE,
    recipient VARCHAR(255) NOT NULL,
    channel VARCHAR(50) NOT NULL,
    message_summary TEXT NOT NULL,
    status VARCHAR(50) NOT NULL,
    sent_at TIMESTAMP WITH TIME ZONE NOT NULL,
    ...
);
```

**Conflict**:
- ‚ùå **Separate table** (notification_audit) vs **unified table** (audit_events)
- ‚ùå **Notification-specific columns** vs **generic event structure**
- ‚ùå **BIGSERIAL ID** vs **UUID event_id**
- ‚ùå **No JSONB event_data** (inflexible schema)

**Impact**:
- Cannot store other audit types (remediation, AI analysis, workflow) in notification_audit table
- Violates ADR-034 extensibility requirement (zero schema changes for new services)
- Inconsistent with industry standard event sourcing pattern

---

### **Issue #2: Existing Code References notification_audit**

**Files Affected**:
1. `pkg/datastorage/models/notification_audit.go` - Model definition
2. `pkg/datastorage/repository/notification_audit_repository.go` - Repository
3. `pkg/datastorage/server/audit_handlers.go` - REST API handlers
4. `pkg/datastorage/validation/notification_audit_validator.go` - Validation
5. `pkg/datastorage/dlq/client.go` - DLQ client
6. `pkg/datastorage/schema/SCHEMA_VALIDATION.md` - Schema docs

**Conflict**: All code assumes `notification_audit` table, but ADR-034 mandates `audit_events` table.

**Action Required**: Migrate all code to use `audit_events` table with ADR-034 schema.

---

### **Issue #3: DLQ Client Assumes notification_audit**

**Current Implementation** (`pkg/datastorage/dlq/client.go`):
```go
func (c *Client) EnqueueNotificationAudit(ctx context.Context, audit *models.NotificationAudit, originalError error) error {
    // Serializes NotificationAudit struct
    payloadJSON, err := json.Marshal(audit)

    // Adds to Redis Stream: audit:dlq:notification
    streamKey := "audit:dlq:notification"
    ...
}
```

**ADR-034 Requirement**: Generic DLQ for all audit types
```go
func (c *Client) EnqueueAuditEvent(ctx context.Context, event *audit.AuditEvent, originalError error) error {
    // Serializes generic AuditEvent
    eventJSON, err := json.Marshal(event)

    // Adds to Redis Stream: audit:dlq:events (unified stream)
    streamKey := "audit:dlq:events"
    ...
}
```

**Action Required**: Refactor DLQ client to use `audit.AuditEvent` (from `pkg/audit/` shared library per DD-AUDIT-002).

---

### **Issue #4: REST API Endpoints Misaligned**

**Current Endpoints**:
```
POST /api/v1/audits/notification  # notification_audit specific
```

**ADR-034 Requirement**:
```
POST /api/v1/audit-events         # Unified endpoint for ALL audit types
GET  /api/v1/audit-events         # Query endpoint with filters
```

**Action Required**: Replace notification-specific endpoint with unified audit-events endpoint.

---

## üìã **PLAYBOOK CATALOG GAPS**

### **Issue #5: No playbook_catalog Table Exists**

**Authoritative Source**: DD-CONTEXT-005 (Minimal LLM Response Schema)

**What DD-CONTEXT-005 Requires**:
- Playbook catalog storage for semantic search
- Playbook metadata: `playbook_id`, `version`, `description`, `labels`
- Semantic search capability for incident matching
- Label-based filtering (environment, priority, risk_tolerance, business_category)

**What Exists**: ‚ùå **NOTHING** - No playbook_catalog table, no schema, no models

**Required Schema** (from DD-CONTEXT-005 + implementation plan):
```sql
CREATE TABLE playbook_catalog (
    playbook_id VARCHAR(255) NOT NULL,
    version VARCHAR(50) NOT NULL,
    name VARCHAR(255) NOT NULL,
    description TEXT NOT NULL,
    content TEXT NOT NULL,              -- Full playbook YAML/JSON
    labels JSONB NOT NULL,              -- For label matching
    embedding vector(384),              -- For semantic search
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    PRIMARY KEY (playbook_id, version)
);

CREATE INDEX idx_playbook_catalog_labels ON playbook_catalog USING GIN (labels);
CREATE INDEX idx_playbook_catalog_embedding ON playbook_catalog USING hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64);
```

**Action Required**: Create `playbook_catalog` table with pgvector support.

---

### **Issue #6: No Playbook REST API Endpoints**

**DD-CONTEXT-005 Requirement**:
```
POST /api/v1/playbooks                          # Create/update playbook
GET  /api/v1/playbooks/search?query={text}&labels={filters}  # Semantic search
```

**What Exists**: ‚ùå **NOTHING** - No playbook endpoints

**Action Required**: Implement playbook REST API endpoints.

---

### **Issue #7: Embedding Generation Focused on Wrong Target**

**Current Implementation Plan** (`DATA_STORAGE_AUDIT_SEMANTIC_SEARCH_PLAN.md`):
- ‚úÖ **CORRECTED** (v1.1): Now focuses on playbook catalog embeddings
- ‚ùå **OLD** (v1.0): Incorrectly focused on audit record embeddings

**DD-CONTEXT-005 Requirement**: Playbook catalog embeddings for semantic search

**Current Status**: Implementation plan corrected, but **NO CODE EXISTS** for playbook embeddings.

**Action Required**: Implement playbook embedding generation (Python service + Go HTTP client).

---

### **Issue #8: Dual-Write Coordinator Targets Wrong Entity**

**Current Implementation** (`pkg/datastorage/dualwrite/coordinator.go`):
```go
func (c *Coordinator) Write(ctx context.Context, audit *models.RemediationAudit, embedding []float32) (*WriteResult, error) {
    // Writes RemediationAudit with embedding
    ...
}
```

**Problem**: Dual-write is for **playbook catalog** (with embeddings), not **audit records** (no embeddings in V1.0).

**Correct Architecture**:
```go
func (c *Coordinator) WritePlaybook(ctx context.Context, playbook *models.Playbook, embedding []float32) (*WriteResult, error) {
    // Writes Playbook to PostgreSQL with embedding
    ...
}
```

**Action Required**: Refactor dual-write coordinator to write playbook catalog records, not audit records.

---

## üìä **IMPLEMENTATION PLAN MISALIGNMENT**

### **Issue #9: Implementation Plan Versions Inconsistent**

**Files Found**:
- `IMPLEMENTATION_PLAN_V4.8.md` - References notification_audit
- `IMPLEMENTATION_PLAN_V4.9.md` - References notification_audit
- `IMPLEMENTATION_PLAN_V5.3.md` - References ADR-033 multi-dimensional tracking
- `IMPLEMENTATION_PLAN_V5.5.md` - References ADR-033 multi-dimensional tracking
- `DATA_STORAGE_AUDIT_SEMANTIC_SEARCH_PLAN.md` (v1.1) - **CORRECTED** to playbook catalog

**Conflict**: Multiple implementation plan versions with conflicting requirements.

**Action Required**: Create **ONE authoritative V1.0 MVP implementation plan** aligned with ADR-034 and DD-CONTEXT-005.

---

### **Issue #10: Business Requirements Misaligned**

**Current BR-STORAGE-012** (`BUSINESS_REQUIREMENTS.md` v1.1):
```
‚úÖ CORRECTED: Generate embeddings from playbook catalog content
```

**Status**: ‚úÖ **ALIGNED** with DD-CONTEXT-005

**Current BR-STORAGE-009** (`BUSINESS_REQUIREMENTS.md` v1.1):
```
‚è∏Ô∏è DEFERRED TO V1.1: Cache playbook embeddings (no caching in V1.0)
```

**Status**: ‚úÖ **ALIGNED** with DD-STORAGE-006 (no-cache decision)

**Action Required**: ‚úÖ **NO ACTION** - Business requirements already corrected in v1.1.

---

## üîß **MIGRATION STRATEGY**

### **Phase 1: Drop notification_audit Table (No Backwards Compatibility)**

**User Decision**: "C, we don't support backwards compatibility since we haven't yet finished Development"

**Action**:
1. Create migration: `migrations/011_drop_notification_audit.sql`
```sql
-- Drop notification_audit table (no backwards compatibility)
DROP TABLE IF EXISTS notification_audit CASCADE;
```

2. Remove all code referencing `notification_audit`:
   - `pkg/datastorage/models/notification_audit.go` - DELETE
   - `pkg/datastorage/repository/notification_audit_repository.go` - DELETE
   - `pkg/datastorage/validation/notification_audit_validator.go` - DELETE
   - `pkg/datastorage/schema/SCHEMA_VALIDATION.md` - UPDATE (remove notification_audit references)

**Confidence**: 100% (user explicitly approved no backwards compatibility)

---

### **Phase 2: Implement ADR-034 Unified Audit Table**

**Action**:
1. Create migration: `migrations/012_unified_audit_events.sql`
```sql
CREATE TABLE audit_events (
    -- Event Identity
    event_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    event_version VARCHAR(10) NOT NULL DEFAULT '1.0',

    -- Temporal Information
    event_timestamp TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    event_date DATE NOT NULL GENERATED ALWAYS AS (event_timestamp::DATE) STORED,

    -- Event Classification
    event_type VARCHAR(100) NOT NULL,
    event_category VARCHAR(50) NOT NULL,
    event_action VARCHAR(50) NOT NULL,
    event_outcome VARCHAR(20) NOT NULL,

    -- Actor Information (Who)
    actor_type VARCHAR(50) NOT NULL,
    actor_id VARCHAR(255) NOT NULL,
    actor_ip INET,

    -- Resource Information (What)
    resource_type VARCHAR(100) NOT NULL,
    resource_id VARCHAR(255) NOT NULL,
    resource_name VARCHAR(255),

    -- Context Information (Where/Why)
    correlation_id VARCHAR(255) NOT NULL,
    parent_event_id UUID,
    trace_id VARCHAR(255),
    span_id VARCHAR(255),

    -- Kubernetes Context
    namespace VARCHAR(253),
    cluster_name VARCHAR(255),

    -- Event Payload (JSONB - flexible, queryable)
    event_data JSONB NOT NULL,
    event_metadata JSONB,

    -- Audit Metadata
    severity VARCHAR(20),
    duration_ms INTEGER,
    error_code VARCHAR(50),
    error_message TEXT,

    -- Compliance
    retention_days INTEGER DEFAULT 2555,     -- 7 years (SOC 2 / ISO 27001)
    is_sensitive BOOLEAN DEFAULT FALSE,

    -- Indexes
    INDEX idx_event_timestamp (event_timestamp DESC),
    INDEX idx_correlation_id (correlation_id, event_timestamp DESC),
    INDEX idx_resource (resource_type, resource_id, event_timestamp DESC),
    INDEX idx_event_type (event_type, event_timestamp DESC),
    INDEX idx_actor (actor_type, actor_id, event_timestamp DESC),
    INDEX idx_outcome (event_outcome, event_timestamp DESC),
    INDEX idx_event_data_gin (event_data) USING GIN,
    INDEX idx_parent_event (parent_event_id) WHERE parent_event_id IS NOT NULL
) PARTITION BY RANGE (event_date);

-- Create initial partition (current month)
CREATE TABLE audit_events_2025_11 PARTITION OF audit_events
    FOR VALUES FROM ('2025-11-01') TO ('2025-12-01');
```

2. Implement `pkg/audit/` shared library (DD-AUDIT-002):
   - `pkg/audit/store.go` - BufferedAuditStore implementation
   - `pkg/audit/event.go` - AuditEvent type
   - `pkg/audit/event_data.go` - CommonEnvelope helpers
   - `pkg/audit/config.go` - Configuration
   - `pkg/audit/metrics.go` - Prometheus metrics

3. Update Data Storage Service:
   - `pkg/datastorage/server/audit_events_handlers.go` - NEW (unified audit endpoint)
   - `pkg/datastorage/repository/audit_events_repository.go` - NEW
   - `pkg/datastorage/models/audit_event.go` - NEW

**Effort**: 16 hours (2 days)

---

### **Phase 3: Implement Playbook Catalog**

**Action**:
1. Create migration: `migrations/013_playbook_catalog.sql`
```sql
CREATE TABLE playbook_catalog (
    playbook_id VARCHAR(255) NOT NULL,
    version VARCHAR(50) NOT NULL,
    name VARCHAR(255) NOT NULL,
    description TEXT NOT NULL,
    content TEXT NOT NULL,
    labels JSONB NOT NULL,
    embedding vector(384),
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    PRIMARY KEY (playbook_id, version)
);

CREATE INDEX idx_playbook_catalog_labels ON playbook_catalog USING GIN (labels);
CREATE INDEX idx_playbook_catalog_embedding ON playbook_catalog USING hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64);
```

2. Implement playbook models and repository:
   - `pkg/datastorage/models/playbook.go` - NEW
   - `pkg/datastorage/repository/playbook_repository.go` - NEW

3. Implement playbook REST API:
   - `pkg/datastorage/server/playbook_handlers.go` - NEW
   - `POST /api/v1/playbooks` - Create/update playbook
   - `GET /api/v1/playbooks/search` - Semantic search

4. Implement embedding generation:
   - Python embedding service (separate deployment)
   - `pkg/datastorage/embedding/client.go` - HTTP client to Python service
   - `pkg/datastorage/embedding/playbook_pipeline.go` - Playbook embedding pipeline

5. Refactor dual-write coordinator:
   - `pkg/datastorage/dualwrite/coordinator.go` - Update to write playbooks (not audits)

**Effort**: 16 hours (2 days)

---

## ‚úÖ **CORRECTIVE ACTIONS**

### **Immediate Actions** (Day 1, 8 hours)

1. ‚úÖ **Create Migration to Drop notification_audit**
   - File: `migrations/011_drop_notification_audit.sql`
   - Content: `DROP TABLE IF EXISTS notification_audit CASCADE;`

2. ‚úÖ **Delete notification_audit Code**
   - Delete: `pkg/datastorage/models/notification_audit.go`
   - Delete: `pkg/datastorage/repository/notification_audit_repository.go`
   - Delete: `pkg/datastorage/validation/notification_audit_validator.go`
   - Delete: `pkg/datastorage/server/audit_handlers.go` (replace with unified audit_events_handlers.go)

3. ‚úÖ **Create ADR-034 Unified Audit Table Migration**
   - File: `migrations/012_unified_audit_events.sql`
   - Content: ADR-034 schema (see Phase 2 above)

4. ‚úÖ **Update DLQ Client**
   - File: `pkg/datastorage/dlq/client.go`
   - Change: `EnqueueNotificationAudit()` ‚Üí `EnqueueAuditEvent()`
   - Use: `audit.AuditEvent` (from `pkg/audit/` shared library)

---

### **Short-Term Actions** (Days 2-3, 16 hours)

5. ‚úÖ **Implement pkg/audit/ Shared Library** (DD-AUDIT-002)
   - `pkg/audit/store.go` - BufferedAuditStore
   - `pkg/audit/event.go` - AuditEvent type
   - `pkg/audit/event_data.go` - CommonEnvelope helpers
   - `pkg/audit/config.go` - Configuration
   - `pkg/audit/metrics.go` - Prometheus metrics

6. ‚úÖ **Implement Unified Audit REST API**
   - `pkg/datastorage/server/audit_events_handlers.go` - NEW
   - `POST /api/v1/audit-events` - Write audit event
   - `GET /api/v1/audit-events` - Query audit events

7. ‚úÖ **Create Playbook Catalog Migration**
   - File: `migrations/013_playbook_catalog.sql`
   - Content: playbook_catalog table with pgvector (see Phase 3 above)

8. ‚úÖ **Implement Playbook Models and Repository**
   - `pkg/datastorage/models/playbook.go` - NEW
   - `pkg/datastorage/repository/playbook_repository.go` - NEW

---

### **Medium-Term Actions** (Days 4-5, 16 hours)

9. ‚úÖ **Implement Playbook REST API**
   - `pkg/datastorage/server/playbook_handlers.go` - NEW
   - `POST /api/v1/playbooks` - Create/update playbook
   - `GET /api/v1/playbooks/search` - Semantic search

10. ‚úÖ **Implement Embedding Generation**
    - Python embedding service (separate deployment)
    - `pkg/datastorage/embedding/client.go` - HTTP client
    - `pkg/datastorage/embedding/playbook_pipeline.go` - Pipeline

11. ‚úÖ **Refactor Dual-Write Coordinator**
    - `pkg/datastorage/dualwrite/coordinator.go` - Update for playbooks

12. ‚úÖ **Integration Tests**
    - `test/integration/datastorage/audit_events_test.go` - NEW
    - `test/integration/datastorage/playbook_catalog_test.go` - NEW

---

### **Documentation Actions** (Day 6, 8 hours)

13. ‚úÖ **Create Authoritative V1.0 MVP Implementation Plan**
    - File: `docs/services/stateless/data-storage/implementation/V1.0-MVP-IMPLEMENTATION-PLAN.md`
    - Content: Unified plan for audit trail + playbook catalog foundations

14. ‚úÖ **Archive Old Implementation Plans**
    - Move: `IMPLEMENTATION_PLAN_V4.*.md` ‚Üí `archive/`
    - Move: `IMPLEMENTATION_PLAN_V5.*.md` ‚Üí `archive/`

15. ‚úÖ **Update README.md**
    - File: `docs/services/stateless/data-storage/README.md`
    - Content: V1.0 MVP scope (audit trail + playbook catalog)

16. ‚úÖ **Update BUSINESS_REQUIREMENTS.md**
    - File: `docs/services/stateless/data-storage/BUSINESS_REQUIREMENTS.md`
    - Action: ‚úÖ **ALREADY DONE** (v1.1 corrected BR-STORAGE-012 and BR-STORAGE-009)

---

## üìä **Summary of Inconsistencies**

| # | Issue | Severity | Affected Files | Action Required |
|---|-------|----------|----------------|-----------------|
| 1 | notification_audit conflicts with ADR-034 | üî¥ CRITICAL | Migration 010, 6 code files | Drop table, delete code |
| 2 | No audit_events table | üî¥ CRITICAL | N/A | Create migration 012 |
| 3 | DLQ client assumes notification_audit | üü° HIGH | `dlq/client.go` | Refactor to use audit.AuditEvent |
| 4 | REST API endpoints misaligned | üü° HIGH | `server/audit_handlers.go` | Replace with unified endpoint |
| 5 | No playbook_catalog table | üî¥ CRITICAL | N/A | Create migration 013 |
| 6 | No playbook REST API | üî¥ CRITICAL | N/A | Implement playbook handlers |
| 7 | Embedding generation targets wrong entity | üü° HIGH | `embedding/` | Refactor for playbooks |
| 8 | Dual-write coordinator targets wrong entity | üü° HIGH | `dualwrite/coordinator.go` | Refactor for playbooks |
| 9 | Multiple conflicting implementation plans | üü° HIGH | 5+ plan files | Create ONE authoritative plan |
| 10 | Business requirements misaligned | ‚úÖ RESOLVED | `BUSINESS_REQUIREMENTS.md` | ‚úÖ Already corrected in v1.1 |

**Total Issues**: 10 (9 requiring action, 1 resolved)

**Total Effort**: 48 hours (6 days)

---

## üéØ **V1.0 MVP Scope (Authoritative)**

Based on ADR-034 and DD-CONTEXT-005:

### **Audit Trail Foundation** (ADR-034)
1. ‚úÖ Unified `audit_events` table (ADR-034 schema)
2. ‚úÖ `POST /api/v1/audit-events` write endpoint
3. ‚úÖ `GET /api/v1/audit-events` query endpoint
4. ‚úÖ `pkg/audit/` shared library (async buffered writes)
5. ‚úÖ DLQ for audit write failures (Redis Streams)
6. ‚ùå No audit embeddings (deferred to V2.0 RAR)

### **Playbook Catalog Foundation** (DD-CONTEXT-005)
1. ‚úÖ `playbook_catalog` table (with pgvector embedding column)
2. ‚úÖ `POST /api/v1/playbooks` endpoint (create/update)
3. ‚úÖ `GET /api/v1/playbooks/search` endpoint (semantic search)
4. ‚úÖ Playbook embedding generation (Python service + Go HTTP client)
5. ‚ùå **NO caching in V1.0** (deferred to V1.1 per DD-STORAGE-006)

---

## üìã **Next Steps**

1. **User Approval**: Review this triage and approve corrective actions
2. **Execute Phase 1**: Drop notification_audit, create audit_events (Day 1)
3. **Execute Phase 2**: Implement pkg/audit/ shared library (Days 2-3)
4. **Execute Phase 3**: Implement playbook catalog (Days 4-5)
5. **Documentation**: Create authoritative V1.0 MVP plan (Day 6)

---

**Document Version**: 1.0
**Last Updated**: November 13, 2025
**Status**: üö® **CRITICAL - AWAITING USER APPROVAL**
**Overall Confidence**: **98%** (based on authoritative ADR-034 and DD-CONTEXT-005)

